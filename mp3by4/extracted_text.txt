Skip to content
Courses
Tutorials
Data Science
Python Tutorial
R Tutorial
Machine Learning
Data Science using Python
Data Science using R
Data Science Packages
Data Visualization
Data Analysis
Deep Learning
NLP Tutorial
Computer Vision
Interview Corner
Machine Learning Interview Question
Deep Learning Interview Question
NLP Interview Question
Python Interview Questions
Top 50 R Interview Questions
ML Frameworks
Practice

D

Courses
Tutorials
Data Science
Python Tutorial
R Tutorial
Machine Learning
Data Science using Python
Data Science using R
Data Science Packages
Data Visualization
Data Analysis
Deep Learning
NLP Tutorial
Computer Vision
Interview Corner
Machine Learning Interview Question
Deep Learning Interview Question
NLP Interview Question
Python Interview Questions
Top 50 R Interview Questions
ML Frameworks
Practice

D

D

D

AI ML DS
Data Science
Data Analysis
Data Visualization
Machine Learning
Deep Learning
NLP
Computer Vision
Artificial Intelligence
AI ML DS Interview Series
AI ML DS Projects series
Data Engineering
Web Scrapping

Share Your Experiences
100+ Machine Learning Projects with Source Code [2024]
Classification Projects
Regression Projects
Computer Vision Projects
OCR of Handwritten digits | OpenCV
Cartooning an Image using OpenCV - Python
Count number of Object using Python-OpenCV
Count number of Faces using Python - OpenCV
Text Detection and Extraction using OpenCV and OCR
FaceMask Detection using TensorFlow in Python
Dog Breed Classification using Transfer Learning
Flower Recognition Using Convolutional Neural Network
Emojify using Face Recognition with Machine Learning
Cat & Dog Classification using Convolutional Neural Network in Python
Traffic Signs Recognition using CNN and Keras in Python
Lung Cancer Detection using Convolutional Neural Network (CNN)
Lung Cancer Detection Using Transfer Learning
Pneumonia Detection using Deep Learning
Detecting Covid-19 with Chest X-ray
Skin Cancer Detection using TensorFlow
Age Detection using Deep Learning in OpenCV
Face and Hand Landmarks Detection using Python - Mediapipe, OpenCV
Detecting COVID-19 From Chest X-Ray Images using CNN
Image Segmentation Using TensorFlow
License Plate Recognition with OpenCV and Tesseract OCR
Detect and Recognize Car License Plate from a video in real time
Residual Networks (ResNet) - Deep Learning
Natural Language Processing Projects
Clustering Projects
Recommender System Project
Machine Learning & Data Science
Course
Residual Networks (ResNet) – Deep Learning
Last Updated : 10 Jan, 2023
Generative Summary
Now you can generate the summary of any article of your choice.
Got it

After the first CNN-based architecture (AlexNet) that win the ImageNet 2012 competition, Every subsequent winning architecture uses more layers in a deep neural network to reduce the error rate. This works for less number of layers, but when we increase the number of layers, there is a common problem in deep learning associated with that called the Vanishing/Exploding gradient. This causes the gradient to become 0 or too large. Thus when we increases number of layers, the training and test error rate also increases. 

Comparison of 20-layer vs 56-layer architecture

In the above plot, we can observe that a 56-layer CNN gives more error rate on both training and testing dataset than a 20-layer CNN architecture. After analyzing more on error rate the authors were able to reach conclusion that it is caused by vanishing/exploding gradient. 
ResNet, which was proposed in 2015 by researchers at Microsoft Research introduced a new architecture called Residual Network. 

Residual Network: In order to solve the problem of the vanishing/exploding gradient, this architecture introduced the concept called Residual Blocks. In this network, we use a technique called skip connections. The skip connection connects activations of a  layer to further layers by skipping some layers in between. This forms a residual block. Resnets are made by stacking these residual blocks together. 
The approach behind this network is instead of layers learning the underlying mapping, we allow the network to fit the residual mapping. So, instead of say H(x), initial mapping, let the network fit, 

F(x) := H(x) - x which gives H(x) := F(x) + x. 

Skip (Shortcut) connection

The advantage of adding this type of skip connection is that if any layer hurt the performance of architecture then it will be skipped by regularization. So, this results in training a very deep neural network without the problems caused by vanishing/exploding gradient.  The authors of the paper experimented on 100-1000 layers of the CIFAR-10 dataset. 
There is a similar approach called “highway networks”, these networks also use skip connection. Similar to LSTM these skip connections also use parametric gates. These gates determine how much information passes through the skip connection. This architecture however has not provided accuracy better than ResNet architecture. 

Network Architecture: This network uses a 34-layer plain network architecture inspired by VGG-19 in which then the shortcut connection is added. These shortcut connections then convert the architecture into a residual network.  

ResNet -34 architecture

Implementation: Using the Tensorflow and Keras API, we can design ResNet architecture (including Residual Blocks) from scratch. Below is the implementation of different ResNet architecture. For this implementation, we use the CIFAR-10 dataset. This dataset contains 60, 000 32×32 color images in 10 different classes (airplanes, cars, birds, cats, deer, dogs, frogs, horses, ships, and trucks), etc. This dataset can be assessed from keras.datasets API function. 

Step 1: First, we import the keras module and its APIs. These APIs help in building the architecture of the ResNet model.

Code: Importing libraries 

# Import Keras modules and its important APIs
import keras
from keras.layers import Dense, Conv2D, BatchNormalization, Activation
from keras.layers import AveragePooling2D, Input, Flatten
from keras.optimizers import Adam
from keras.callbacks import ModelCheckpoint, LearningRateScheduler
from keras.callbacks import ReduceLROnPlateau
from keras.preprocessing.image import ImageDataGenerator
from keras.regularizers import l2
from keras import backend as K
from keras.models import Model
from keras.datasets import cifar10
import numpy as np
import os

Step 2: Now, We set different hyper parameters that are required for ResNet architecture. We also did some preprocessing on our dataset to prepare it for training.

Code: Setting Training Hyperparameters  

python3

# Setting Training Hyperparameters 
batch_size = 32  # original ResNet paper uses batch_size = 128 for training 
epochs = 200
data_augmentation = True
num_classes = 10

# Data Preprocessing  
subtract_pixel_mean = True
n = 3

# Select ResNet Version 
version = 1

# Computed depth of  
if version == 1: 
    depth = n * 6 + 2
elif version == 2: 
    depth = n * 9 + 2

# Model name, depth and version 
model_type = 'ResNet % dv % d' % (depth, version) 

# Load the CIFAR-10 data. 
(x_train, y_train), (x_test, y_test) = cifar10.load_data() 

# Input image dimensions. 
input_shape = x_train.shape[1:] 

# Normalize data. 
x_train = x_train.astype('float32') / 255
x_test = x_test.astype('float32') / 255

# If subtract pixel mean is enabled 
if subtract_pixel_mean: 
    x_train_mean = np.mean(x_train, axis = 0) 
    x_train -= x_train_mean 
    x_test -= x_train_mean 

# Print Training and Test Samples  
print('x_train shape:', x_train.shape) 
print(x_train.shape[0], 'train samples') 
print(x_test.shape[0], 'test samples') 
print('y_train shape:', y_train.shape) 

# Convert class vectors to binary class matrices. 
y_train = keras.utils.to_categorical(y_train, num_classes) 
y_test = keras.utils.to_categorical(y_test, num_classes) 

Step 3: In this step, we set the learning rate according to the number of epochs. As the number of epochs the learning rate must be decreased to ensure better learning.

Code: Setting LR for different numbers of Epochs 

python3

# Setting LR for different number of Epochs 
def lr_schedule(epoch): 
    lr = 1e-3
    if epoch > 180: 
        lr *= 0.5e-3
    elif epoch > 160: 
        lr *= 1e-3
    elif epoch > 120: 
        lr *= 1e-2
    elif epoch > 80: 
        lr *= 1e-1
    print('Learning rate: ', lr) 
    return lr 

Step 4: Define basic ResNet building block that can be used for defining the ResNet V1 and V2 architecture.

Code: Basic ResNet Building Block 

python3

# Basic ResNet Building Block 

def resnet_layer(inputs, 
                 num_filters=16, 
                 kernel_size=3, 
                 strides=1, 
                 activation='relu', 
                 batch_normalization=True, 
    conv=Conv2D(num_filters, 
                  kernel_size=kernel_size, 
                  strides=strides, 
                  padding='same', 
                  kernel_initializer='he_normal', 
                  kernel_regularizer=l2(1e-4)) 

    x=inputs 
    if conv_first: 
        x = conv(x) 
        if batch_normalization: 
            x = BatchNormalization()(x) 
        if activation is not None: 
            x = Activation(activation)(x) 
    else: 
        if batch_normalization: 
            x = BatchNormalization()(x) 
        if activation is not None: 
            x = Activation(activation)(x) 
        x = conv(x) 
    return x 

Step 5: Define ResNet V1 architecture that is based on the ResNet building block we defined above:

Code: ResNet V1 architecture 

python3

def resnet_v1(input_shape, depth, num_classes=10): 

    if (depth - 2) % 6 != 0: 
        raise ValueError('depth should be 6n + 2 (eg 20, 32, 44 in [a])') 
    # Start model definition. 
    num_filters = 16
    num_res_blocks = int((depth - 2) / 6) 

    inputs = Input(shape=input_shape) 
    x = resnet_layer(inputs=inputs) 
    # Instantiate the stack of residual units 
    for stack in range(3): 
        for res_block in range(num_res_blocks): 
            strides = 1
            if stack & gt 
            0 and res_block == 0:  # first layer but not first stack 
                strides = 2  # downsample 
            y = resnet_layer(inputs=x, 
                             num_filters=num_filters, 
                             strides=strides) 
            y = resnet_layer(inputs=y, 
                             num_filters=num_filters, 
                             activation=None) 
            if stack & gt 
            0 and res_block == 0:  # first layer but not first stack 
                # linear projection residual shortcut connection to match 
                # changed dims 
                x = resnet_layer(inputs=x, 
                                 num_filters=num_filters, 
                                 kernel_size=1, 
                                 strides=strides, 
                                 activation=None, 
                                 batch_normalization=False) 
            x = keras.layers.add([x, y]) 
            x = Activation('relu')(x) 
        num_filters *= 2

    # Add classifier on top. 
    # v1 does not use BN after last shortcut connection-ReLU 
    x = AveragePooling2D(pool_size=8)(x) 
    y = Flatten()(x) 
    outputs = Dense(num_classes, 
                    activation='softmax', 
                    kernel_initializer='he_normal')(y) 

    # Instantiate model. 
    model = Model(inputs=inputs, outputs=outputs) 
    return model 

Step 6: Define ResNet V2 architecture that is based on the ResNet building block we defined above:

Code: ResNet V2 architecture 

python3

# ResNet V2 architecture 
def resnet_v2(input_shape, depth, num_classes=10): 
    if (depth - 2) % 9 != 0: 
        raise ValueError('depth should be 9n + 2 (eg 56 or 110 in [b])') 
    # Start model definition. 
    num_filters_in = 16
    num_res_blocks = int((depth - 2) / 9) 

    inputs = Input(shape=input_shape) 
    # v2 performs Conv2D with BN-ReLU on input before splitting into 2 paths 
    x = resnet_layer(inputs=inputs, 
                     num_filters=num_filters_in, 
                     conv_first=True) 

    # Instantiate the stack of residual units 
    for stage in range(3): 
        for res_block in range(num_res_blocks): 
            activation = 'relu'
            batch_normalization = True
            strides = 1
            if stage == 0: 
                num_filters_out = num_filters_in * 4
                if res_block == 0:  # first layer and first stage 
                    activation = None
                    batch_normalization = False
            else: 
                num_filters_out = num_filters_in * 2
                if res_block == 0:  # first layer but not first stage 
                    strides = 2    # downsample 

            # bottleneck residual unit 
            y = resnet_layer(inputs=x, 
                             num_filters=num_filters_in, 
                             kernel_size=1, 
                             strides=strides, 
                             activation=activation, 
                             batch_normalization=batch_normalization, 
                             conv_first=False) 
            y = resnet_layer(inputs=y, 
                             num_filters=num_filters_in, 
                             conv_first=False) 
            y = resnet_layer(inputs=y, 
                             num_filters=num_filters_out, 
                             kernel_size=1, 
                             conv_first=False) 
            if res_block == 0: 
                # linear projection residual shortcut connection to match 
                # changed dims 
                x = resnet_layer(inputs=x, 
                                 num_filters=num_filters_out, 
                                 kernel_size=1, 
                                 strides=strides, 
                                 activation=None, 
                                 batch_normalization=False) 
            x = keras.layers.add([x, y]) 

        num_filters_in = num_filters_out 

    # Add classifier on top. 
    # v2 has BN-ReLU before Pooling 
    x = BatchNormalization()(x) 
    x = Activation('relu')(x) 
    x = AveragePooling2D(pool_size=8)(x) 
    y = Flatten()(x) 
    outputs = Dense(num_classes, 
                    activation='softmax', 
                    kernel_initializer='he_normal')(y) 

    # Instantiate model. 
    model = Model(inputs=inputs, outputs=outputs) 
    return model 

Step 7: The code below is used to train and test the ResNet v1 and v2 architecture we defined above:

Code: Main function 

python3

# Main function  
if version == 2: 
    model = resnet_v2(input_shape = input_shape, depth = depth) 
else: 
    model = resnet_v1(input_shape = input_shape, depth = depth) 

model.compile(loss ='categorical_crossentropy', 
              optimizer = Adam(learning_rate = lr_schedule(0)), 
              metrics =['accuracy']) 
model.summary() 
print(model_type) 

# Prepare model saving directory. 
save_dir = os.path.join(os.getcwd(), 'saved_models') 
model_name = 'cifar10_% s_model.{epoch:03d}.h5' % model_type 
if not os.path.isdir(save_dir): 
    os.makedirs(save_dir) 
filepath = os.path.join(save_dir, model_name) 

# Prepare callbacks for model saving and for learning rate adjustment. 
checkpoint = ModelCheckpoint(filepath = filepath, 
                             monitor ='val_acc', 
                             verbose = 1, 
                             save_best_only = True) 

lr_scheduler = LearningRateScheduler(lr_schedule) 

lr_reducer = ReduceLROnPlateau(factor = np.sqrt(0.1), 
                               cooldown = 0, 
                               patience = 5, 
                               min_lr = 0.5e-6) 

callbacks = [checkpoint, lr_reducer, lr_scheduler] 

# Run training, with or without data augmentation. 
if not data_augmentation: 
    print('Not using data augmentation.') 
    model.fit(x_train, y_train, 
              batch_size = batch_size, 
              epochs = epochs, 
              validation_data =(x_test, y_test), 
              shuffle = True, 
              callbacks = callbacks) 
else: 
    print('Using real-time data augmentation.') 
    # This will do preprocessing and realtime data augmentation: 
    datagen = ImageDataGenerator( 
        # set input mean to 0 over the dataset 
        featurewise_center = False, 
        # set each sample mean to 0 
        samplewise_center = False, 
        # divide inputs by std of dataset 
        featurewise_std_normalization = False, 
        # divide each input by its std 
        samplewise_std_normalization = False, 
        # apply ZCA whitening 
        zca_whitening = False, 
        # epsilon for ZCA whitening 
        zca_epsilon = 1e-06, 
        # randomly rotate images in the range (deg 0 to 180) 
        rotation_range = 0, 
        # randomly shift images horizontally 
        width_shift_range = 0.1, 
        # randomly shift images vertically 
        height_shift_range = 0.1, 
        # set range for random shear 
        shear_range = 0., 
        # set range for random zoom 
        zoom_range = 0., 
        # set range for random channel shifts 
        channel_shift_range = 0., 
        # set mode for filling points outside the input boundaries 
        fill_mode ='nearest', 
        # value used for fill_mode = "constant" 
        cval = 0., 
        # randomly flip images 
        horizontal_flip = True, 
        # randomly flip images 
        vertical_flip = False, 
        # set rescaling factor (applied before any other transformation) 
        rescale = None, 
        # set function that will be applied on each input 
        preprocessing_function = None, 
        # image data format, either "channels_first" or "channels_last" 
        data_format = None, 
        # fraction of images reserved for validation (strictly between 0 and 1) 
        validation_split = 0.0) 

    # Compute quantities required for featurewise normalization 
    # (std, mean, and principal components if ZCA whitening is applied). 
    datagen.fit(x_train) 

    # Fit the model on the batches generated by datagen.flow(). 
    model.fit_generator(datagen.flow(x_train, y_train, batch_size = batch_size), 
                        validation_data =(x_test, y_test), 
                        epochs = epochs, verbose = 1, workers = 4, 
                        callbacks = callbacks) 

# Score trained model. 
scores = model.evaluate(x_test, y_test, verbose = 1) 
print('Test loss:', scores[0]) 
print('Test accuracy:', scores[1])

Results & Conclusion: 
On the ImageNet dataset,  the authors uses a 152-layers ResNet, which is 8 times more deep than VGG19 but still have less parameters. An ensemble of these ResNets generated an error of only 3.7% on ImageNet test set, the result which won ILSVRC 2015 competition. On COCO object detection dataset, it also generates a 28% relative improvement due to its very deep representation. 

Error-rate on ResNet Architecture

The result above shows that shortcut connections would be able to solve the problem caused by increasing the layers because as we increase layers from 18 to 34 the error rate on ImageNet Validation Set also decreases unlike the plain network.

top-1 and top-5 Error rate on ImageNet Validation Set.

Below are the results on ImageNet Test Set. The 3.57% top-5 error rate of ResNet was the lowest and thus ResNet architecture came first in ImageNet classification challenge in 2015.

Are you passionate about data and looking to make one giant leap into your career? Our Data Science Course will help you change your game and, most importantly, allow students, professionals, and working adults to tide over into the data science immersion. Master state-of-the-art methodologies, powerful tools, and industry best practices, hands-on projects, and real-world applications. Become the executive head of industries related to Data Analysis, Machine Learning, and Data Visualization with these growing skills. Ready to Transform Your Future? Enroll Now to Be a Data Science Expert!

P

pawangfg
12
Previous Article
Detect and Recognize Car License Plate from a video in real time
Next Article
Twitter Sentiment Analysis using Python
Read More
Video | Residual Networks (ResNet) - Deep Learning
Similar Reads
Introduction to Residual Networks
Recent years have seen tremendous progress in the field of Image Processing and Recognition. Deep Neural Networks are becoming deeper and more complex. It has been proved that adding more layers to a Neural Network can make it more robust for image-related tasks. But it can also cause them to lose accuracy. That's where Residual Networks come into
3 min read
Deep Belief Network (DBN) in Deep Learning
Discover data creation with Deep Belief Networks (DBNs), cutting-edge generative models that make use of deep architecture. This article walks you through the concepts of DBNs, how they work, and how to implement them using practical coding. What is a Deep Belief Network?Deep Belief Networks (DBNs) are sophisticated artificial neural networks used
9 min read
Deep Boltzmann Machines (DBMs) in Deep Learning
In this article, we will discuss the Deep Boltzmann Machines concepts and their applications in the real-world scenario. What are Deep Boltzmann Machines (DBMs)?Deep Boltzmann Machines (DBMs) are a kind of artificial neural network that belongs to the family of generative models. They are designed to discover intricate structures within large datas
10 min read
Unveiling the Power of Fastai: A Deep Dive into the Versatile Deep Learning Library
Fastai is a powerful deep-learning library designed for researchers and practitioners. It offers high-level abstractions, PyTorch integration, and application-specific APIs, making it both adaptable and accessible for a wide range of deep learning tasks. In this article, we'll delve into the intricacies of Fastai, a powerful deep-learning library.
9 min read
Spiking Neural Networks in Deep Learning
Spiking Neural Networks (SNNs) represent a novel approach in artificial neural networks, inspired by the biological processes of the human brain. Unlike traditional artificial neural networks (ANNs) that rely on continuous signal processing, SNNs operate on discrete events called "spikes." The aim of this article is to provide an in-depth understan
10 min read
Introduction to Multi-Task Learning(MTL) for Deep Learning
Multi-Task Learning (MTL) is a type of machine learning technique where a model is trained to perform multiple tasks simultaneously. In deep learning, MTL refers to training a neural network to perform multiple tasks by sharing some of the network's layers and parameters across tasks. In MTL, the goal is to improve the generalization performance of
6 min read
Artificial intelligence vs Machine Learning vs Deep Learning
Nowadays many misconceptions are there related to the words machine learning, deep learning, and artificial intelligence (AI), most people think all these things are the same whenever they hear the word AI, they directly relate that word to machine learning or vice versa, well yes, these things are related to each other but not the same. Let's see
4 min read
Need of Data Structures and Algorithms for Deep Learning and Machine Learning
Deep Learning is a field that is heavily based on Mathematics and you need to have a good understanding of Data Structures and Algorithms to solve the mathematical problems optimally. Data Structures and Algorithms can be used to determine how a problem is represented internally or how the actual storage pattern works &amp; what is happening under
6 min read
Difference Between Artificial Intelligence vs Machine Learning vs Deep Learning
Artificial Intelligence is basically the mechanism to incorporate human intelligence into machines through a set of rules(algorithm). AI is a combination of two words: "Artificial" meaning something made by humans or non-natural things and "Intelligence" meaning the ability to understand or think accordingly. Another definition could be that "AI is
14 min read
Difference Between Machine Learning and Deep Learning
If you are interested in building your career in the IT industry then you must have come across the term Data Science which is a booming field in terms of technologies and job availability as well. In this article, we will explore the Difference between Machine Learning and Deep Learning, two major fields within Data Science. Understanding these di
8 min read
Article Tags :
AI-ML-DS
Deep Learning
Machine Learning
AI-ML-DS With Python
+1 More
Practice Tags :
Machine Learning
python
288k+ interested Geeks
Data Structures & Algorithms in Python - Self Paced
Explore
203k+ interested Geeks
Python Full Course Online - Complete Beginner to Advanced
Explore
312k+ interested Geeks
Complete Machine Learning & Data Science Program
Explore

Open In App

Share Your Experiences
100+ Machine Learning Projects with Source Code [2024]
Classification Projects
Regression Projects
Computer Vision Projects
OCR of Handwritten digits | OpenCV
Cartooning an Image using OpenCV - Python
Count number of Object using Python-OpenCV
Count number of Faces using Python - OpenCV
Text Detection and Extraction using OpenCV and OCR
FaceMask Detection using TensorFlow in Python
Dog Breed Classification using Transfer Learning
Flower Recognition Using Convolutional Neural Network
Emojify using Face Recognition with Machine Learning
Cat & Dog Classification using Convolutional Neural Network in Python
Traffic Signs Recognition using CNN and Keras in Python
Lung Cancer Detection using Convolutional Neural Network (CNN)
Lung Cancer Detection Using Transfer Learning
Pneumonia Detection using Deep Learning
Detecting Covid-19 with Chest X-ray
Skin Cancer Detection using TensorFlow
Age Detection using Deep Learning in OpenCV
Face and Hand Landmarks Detection using Python - Mediapipe, OpenCV
Detecting COVID-19 From Chest X-Ray Images using CNN
Image Segmentation Using TensorFlow
License Plate Recognition with OpenCV and Tesseract OCR
Detect and Recognize Car License Plate from a video in real time
Residual Networks (ResNet) - Deep Learning
Natural Language Processing Projects
Clustering Projects
Recommender System Project
Machine Learning & Data Science
Course
Residual Networks (ResNet) – Deep Learning
Last Updated : 10 Jan, 2023
Generative Summary
Now you can generate the summary of any article of your choice.
Got it

After the first CNN-based architecture (AlexNet) that win the ImageNet 2012 competition, Every subsequent winning architecture uses more layers in a deep neural network to reduce the error rate. This works for less number of layers, but when we increase the number of layers, there is a common problem in deep learning associated with that called the Vanishing/Exploding gradient. This causes the gradient to become 0 or too large. Thus when we increases number of layers, the training and test error rate also increases. 

Comparison of 20-layer vs 56-layer architecture

In the above plot, we can observe that a 56-layer CNN gives more error rate on both training and testing dataset than a 20-layer CNN architecture. After analyzing more on error rate the authors were able to reach conclusion that it is caused by vanishing/exploding gradient. 
ResNet, which was proposed in 2015 by researchers at Microsoft Research introduced a new architecture called Residual Network. 

Residual Network: In order to solve the problem of the vanishing/exploding gradient, this architecture introduced the concept called Residual Blocks. In this network, we use a technique called skip connections. The skip connection connects activations of a  layer to further layers by skipping some layers in between. This forms a residual block. Resnets are made by stacking these residual blocks together. 
The approach behind this network is instead of layers learning the underlying mapping, we allow the network to fit the residual mapping. So, instead of say H(x), initial mapping, let the network fit, 

F(x) := H(x) - x which gives H(x) := F(x) + x. 

Skip (Shortcut) connection

The advantage of adding this type of skip connection is that if any layer hurt the performance of architecture then it will be skipped by regularization. So, this results in training a very deep neural network without the problems caused by vanishing/exploding gradient.  The authors of the paper experimented on 100-1000 layers of the CIFAR-10 dataset. 
There is a similar approach called “highway networks”, these networks also use skip connection. Similar to LSTM these skip connections also use parametric gates. These gates determine how much information passes through the skip connection. This architecture however has not provided accuracy better than ResNet architecture. 

Network Architecture: This network uses a 34-layer plain network architecture inspired by VGG-19 in which then the shortcut connection is added. These shortcut connections then convert the architecture into a residual network.  

ResNet -34 architecture

Implementation: Using the Tensorflow and Keras API, we can design ResNet architecture (including Residual Blocks) from scratch. Below is the implementation of different ResNet architecture. For this implementation, we use the CIFAR-10 dataset. This dataset contains 60, 000 32×32 color images in 10 different classes (airplanes, cars, birds, cats, deer, dogs, frogs, horses, ships, and trucks), etc. This dataset can be assessed from keras.datasets API function. 

Step 1: First, we import the keras module and its APIs. These APIs help in building the architecture of the ResNet model.

Code: Importing libraries 

# Import Keras modules and its important APIs
import keras
from keras.layers import Dense, Conv2D, BatchNormalization, Activation
from keras.layers import AveragePooling2D, Input, Flatten
from keras.optimizers import Adam
from keras.callbacks import ModelCheckpoint, LearningRateScheduler
from keras.callbacks import ReduceLROnPlateau
from keras.preprocessing.image import ImageDataGenerator
from keras.regularizers import l2
from keras import backend as K
from keras.models import Model
from keras.datasets import cifar10
import numpy as np
import os

Step 2: Now, We set different hyper parameters that are required for ResNet architecture. We also did some preprocessing on our dataset to prepare it for training.

Code: Setting Training Hyperparameters  

python3

# Setting Training Hyperparameters 
batch_size = 32  # original ResNet paper uses batch_size = 128 for training 
epochs = 200
data_augmentation = True
num_classes = 10

# Data Preprocessing  
subtract_pixel_mean = True
n = 3

# Select ResNet Version 
version = 1

# Computed depth of  
if version == 1: 
    depth = n * 6 + 2
elif version == 2: 
    depth = n * 9 + 2

# Model name, depth and version 
model_type = 'ResNet % dv % d' % (depth, version) 

# Load the CIFAR-10 data. 
(x_train, y_train), (x_test, y_test) = cifar10.load_data() 

# Input image dimensions. 
input_shape = x_train.shape[1:] 

# Normalize data. 
x_train = x_train.astype('float32') / 255
x_test = x_test.astype('float32') / 255

# If subtract pixel mean is enabled 
if subtract_pixel_mean: 
    x_train_mean = np.mean(x_train, axis = 0) 
    x_train -= x_train_mean 
    x_test -= x_train_mean 

# Print Training and Test Samples  
print('x_train shape:', x_train.shape) 
print(x_train.shape[0], 'train samples') 
print(x_test.shape[0], 'test samples') 
print('y_train shape:', y_train.shape) 

# Convert class vectors to binary class matrices. 
y_train = keras.utils.to_categorical(y_train, num_classes) 
y_test = keras.utils.to_categorical(y_test, num_classes) 

Step 3: In this step, we set the learning rate according to the number of epochs. As the number of epochs the learning rate must be decreased to ensure better learning.

Code: Setting LR for different numbers of Epochs 

python3

# Setting LR for different number of Epochs 
def lr_schedule(epoch): 
    lr = 1e-3
    if epoch > 180: 
        lr *= 0.5e-3
    elif epoch > 160: 
        lr *= 1e-3
    elif epoch > 120: 
        lr *= 1e-2
    elif epoch > 80: 
        lr *= 1e-1
    print('Learning rate: ', lr) 
    return lr 

Step 4: Define basic ResNet building block that can be used for defining the ResNet V1 and V2 architecture.

Code: Basic ResNet Building Block 

python3

# Basic ResNet Building Block 

def resnet_layer(inputs, 
                 num_filters=16, 
                 kernel_size=3, 
                 strides=1, 
                 activation='relu', 
                 batch_normalization=True, 
    conv=Conv2D(num_filters, 
                  kernel_size=kernel_size, 
                  strides=strides, 
                  padding='same', 
                  kernel_initializer='he_normal', 
                  kernel_regularizer=l2(1e-4)) 

    x=inputs 
    if conv_first: 
        x = conv(x) 
        if batch_normalization: 
            x = BatchNormalization()(x) 
        if activation is not None: 
            x = Activation(activation)(x) 
    else: 
        if batch_normalization: 
            x = BatchNormalization()(x) 
        if activation is not None: 
            x = Activation(activation)(x) 
        x = conv(x) 
    return x 

Step 5: Define ResNet V1 architecture that is based on the ResNet building block we defined above:

Code: ResNet V1 architecture 

python3

def resnet_v1(input_shape, depth, num_classes=10): 

    if (depth - 2) % 6 != 0: 
        raise ValueError('depth should be 6n + 2 (eg 20, 32, 44 in [a])') 
    # Start model definition. 
    num_filters = 16
    num_res_blocks = int((depth - 2) / 6) 

    inputs = Input(shape=input_shape) 
    x = resnet_layer(inputs=inputs) 
    # Instantiate the stack of residual units 
    for stack in range(3): 
        for res_block in range(num_res_blocks): 
            strides = 1
            if stack & gt 
            0 and res_block == 0:  # first layer but not first stack 
                strides = 2  # downsample 
            y = resnet_layer(inputs=x, 
                             num_filters=num_filters, 
                             strides=strides) 
            y = resnet_layer(inputs=y, 
                             num_filters=num_filters, 
                             activation=None) 
            if stack & gt 
            0 and res_block == 0:  # first layer but not first stack 
                # linear projection residual shortcut connection to match 
                # changed dims 
                x = resnet_layer(inputs=x, 
                                 num_filters=num_filters, 
                                 kernel_size=1, 
                                 strides=strides, 
                                 activation=None, 
                                 batch_normalization=False) 
            x = keras.layers.add([x, y]) 
            x = Activation('relu')(x) 
        num_filters *= 2

    # Add classifier on top. 
    # v1 does not use BN after last shortcut connection-ReLU 
    x = AveragePooling2D(pool_size=8)(x) 
    y = Flatten()(x) 
    outputs = Dense(num_classes, 
                    activation='softmax', 
                    kernel_initializer='he_normal')(y) 

    # Instantiate model. 
    model = Model(inputs=inputs, outputs=outputs) 
    return model 

Step 6: Define ResNet V2 architecture that is based on the ResNet building block we defined above:

Code: ResNet V2 architecture 

python3

# ResNet V2 architecture 
def resnet_v2(input_shape, depth, num_classes=10): 
    if (depth - 2) % 9 != 0: 
        raise ValueError('depth should be 9n + 2 (eg 56 or 110 in [b])') 
    # Start model definition. 
    num_filters_in = 16
    num_res_blocks = int((depth - 2) / 9) 

    inputs = Input(shape=input_shape) 
    # v2 performs Conv2D with BN-ReLU on input before splitting into 2 paths 
    x = resnet_layer(inputs=inputs, 
                     num_filters=num_filters_in, 
                     conv_first=True) 

    # Instantiate the stack of residual units 
    for stage in range(3): 
        for res_block in range(num_res_blocks): 
            activation = 'relu'
            batch_normalization = True
            strides = 1
            if stage == 0: 
                num_filters_out = num_filters_in * 4
                if res_block == 0:  # first layer and first stage 
                    activation = None
                    batch_normalization = False
            else: 
                num_filters_out = num_filters_in * 2
                if res_block == 0:  # first layer but not first stage 
                    strides = 2    # downsample 

            # bottleneck residual unit 
            y = resnet_layer(inputs=x, 
                             num_filters=num_filters_in, 
                             kernel_size=1, 
                             strides=strides, 
                             activation=activation, 
                             batch_normalization=batch_normalization, 
                             conv_first=False) 
            y = resnet_layer(inputs=y, 
                             num_filters=num_filters_in, 
                             conv_first=False) 
            y = resnet_layer(inputs=y, 
                             num_filters=num_filters_out, 
                             kernel_size=1, 
                             conv_first=False) 
            if res_block == 0: 
                # linear projection residual shortcut connection to match 
                # changed dims 
                x = resnet_layer(inputs=x, 
                                 num_filters=num_filters_out, 
                                 kernel_size=1, 
                                 strides=strides, 
                                 activation=None, 
                                 batch_normalization=False) 
            x = keras.layers.add([x, y]) 

        num_filters_in = num_filters_out 

    # Add classifier on top. 
    # v2 has BN-ReLU before Pooling 
    x = BatchNormalization()(x) 
    x = Activation('relu')(x) 
    x = AveragePooling2D(pool_size=8)(x) 
    y = Flatten()(x) 
    outputs = Dense(num_classes, 
                    activation='softmax', 
                    kernel_initializer='he_normal')(y) 

    # Instantiate model. 
    model = Model(inputs=inputs, outputs=outputs) 
    return model 

Step 7: The code below is used to train and test the ResNet v1 and v2 architecture we defined above:

Code: Main function 

python3

# Main function  
if version == 2: 
    model = resnet_v2(input_shape = input_shape, depth = depth) 
else: 
    model = resnet_v1(input_shape = input_shape, depth = depth) 

model.compile(loss ='categorical_crossentropy', 
              optimizer = Adam(learning_rate = lr_schedule(0)), 
              metrics =['accuracy']) 
model.summary() 
print(model_type) 

# Prepare model saving directory. 
save_dir = os.path.join(os.getcwd(), 'saved_models') 
model_name = 'cifar10_% s_model.{epoch:03d}.h5' % model_type 
if not os.path.isdir(save_dir): 
    os.makedirs(save_dir) 
filepath = os.path.join(save_dir, model_name) 

# Prepare callbacks for model saving and for learning rate adjustment. 
checkpoint = ModelCheckpoint(filepath = filepath, 
                             monitor ='val_acc', 
                             verbose = 1, 
                             save_best_only = True) 

lr_scheduler = LearningRateScheduler(lr_schedule) 

lr_reducer = ReduceLROnPlateau(factor = np.sqrt(0.1), 
                               cooldown = 0, 
                               patience = 5, 
                               min_lr = 0.5e-6) 

callbacks = [checkpoint, lr_reducer, lr_scheduler] 

# Run training, with or without data augmentation. 
if not data_augmentation: 
    print('Not using data augmentation.') 
    model.fit(x_train, y_train, 
              batch_size = batch_size, 
              epochs = epochs, 
              validation_data =(x_test, y_test), 
              shuffle = True, 
              callbacks = callbacks) 
else: 
    print('Using real-time data augmentation.') 
    # This will do preprocessing and realtime data augmentation: 
    datagen = ImageDataGenerator( 
        # set input mean to 0 over the dataset 
        featurewise_center = False, 
        # set each sample mean to 0 
        samplewise_center = False, 
        # divide inputs by std of dataset 
        featurewise_std_normalization = False, 
        # divide each input by its std 
        samplewise_std_normalization = False, 
        # apply ZCA whitening 
        zca_whitening = False, 
        # epsilon for ZCA whitening 
        zca_epsilon = 1e-06, 
        # randomly rotate images in the range (deg 0 to 180) 
        rotation_range = 0, 
        # randomly shift images horizontally 
        width_shift_range = 0.1, 
        # randomly shift images vertically 
        height_shift_range = 0.1, 
        # set range for random shear 
        shear_range = 0., 
        # set range for random zoom 
        zoom_range = 0., 
        # set range for random channel shifts 
        channel_shift_range = 0., 
        # set mode for filling points outside the input boundaries 
        fill_mode ='nearest', 
        # value used for fill_mode = "constant" 
        cval = 0., 
        # randomly flip images 
        horizontal_flip = True, 
        # randomly flip images 
        vertical_flip = False, 
        # set rescaling factor (applied before any other transformation) 
        rescale = None, 
        # set function that will be applied on each input 
        preprocessing_function = None, 
        # image data format, either "channels_first" or "channels_last" 
        data_format = None, 
        # fraction of images reserved for validation (strictly between 0 and 1) 
        validation_split = 0.0) 

    # Compute quantities required for featurewise normalization 
    # (std, mean, and principal components if ZCA whitening is applied). 
    datagen.fit(x_train) 

    # Fit the model on the batches generated by datagen.flow(). 
    model.fit_generator(datagen.flow(x_train, y_train, batch_size = batch_size), 
                        validation_data =(x_test, y_test), 
                        epochs = epochs, verbose = 1, workers = 4, 
                        callbacks = callbacks) 

# Score trained model. 
scores = model.evaluate(x_test, y_test, verbose = 1) 
print('Test loss:', scores[0]) 
print('Test accuracy:', scores[1])

Results & Conclusion: 
On the ImageNet dataset,  the authors uses a 152-layers ResNet, which is 8 times more deep than VGG19 but still have less parameters. An ensemble of these ResNets generated an error of only 3.7% on ImageNet test set, the result which won ILSVRC 2015 competition. On COCO object detection dataset, it also generates a 28% relative improvement due to its very deep representation. 

Error-rate on ResNet Architecture

The result above shows that shortcut connections would be able to solve the problem caused by increasing the layers because as we increase layers from 18 to 34 the error rate on ImageNet Validation Set also decreases unlike the plain network.

top-1 and top-5 Error rate on ImageNet Validation Set.

Below are the results on ImageNet Test Set. The 3.57% top-5 error rate of ResNet was the lowest and thus ResNet architecture came first in ImageNet classification challenge in 2015.

Are you passionate about data and looking to make one giant leap into your career? Our Data Science Course will help you change your game and, most importantly, allow students, professionals, and working adults to tide over into the data science immersion. Master state-of-the-art methodologies, powerful tools, and industry best practices, hands-on projects, and real-world applications. Become the executive head of industries related to Data Analysis, Machine Learning, and Data Visualization with these growing skills. Ready to Transform Your Future? Enroll Now to Be a Data Science Expert!

P

pawangfg
12
Previous Article
Detect and Recognize Car License Plate from a video in real time
Next Article
Twitter Sentiment Analysis using Python
Read More
Video | Residual Networks (ResNet) - Deep Learning
Similar Reads
Introduction to Residual Networks
Recent years have seen tremendous progress in the field of Image Processing and Recognition. Deep Neural Networks are becoming deeper and more complex. It has been proved that adding more layers to a Neural Network can make it more robust for image-related tasks. But it can also cause them to lose accuracy. That's where Residual Networks come into
3 min read
Deep Belief Network (DBN) in Deep Learning
Discover data creation with Deep Belief Networks (DBNs), cutting-edge generative models that make use of deep architecture. This article walks you through the concepts of DBNs, how they work, and how to implement them using practical coding. What is a Deep Belief Network?Deep Belief Networks (DBNs) are sophisticated artificial neural networks used
9 min read
Deep Boltzmann Machines (DBMs) in Deep Learning
In this article, we will discuss the Deep Boltzmann Machines concepts and their applications in the real-world scenario. What are Deep Boltzmann Machines (DBMs)?Deep Boltzmann Machines (DBMs) are a kind of artificial neural network that belongs to the family of generative models. They are designed to discover intricate structures within large datas
10 min read
Unveiling the Power of Fastai: A Deep Dive into the Versatile Deep Learning Library
Fastai is a powerful deep-learning library designed for researchers and practitioners. It offers high-level abstractions, PyTorch integration, and application-specific APIs, making it both adaptable and accessible for a wide range of deep learning tasks. In this article, we'll delve into the intricacies of Fastai, a powerful deep-learning library.
9 min read
Spiking Neural Networks in Deep Learning
Spiking Neural Networks (SNNs) represent a novel approach in artificial neural networks, inspired by the biological processes of the human brain. Unlike traditional artificial neural networks (ANNs) that rely on continuous signal processing, SNNs operate on discrete events called "spikes." The aim of this article is to provide an in-depth understan
10 min read
Introduction to Multi-Task Learning(MTL) for Deep Learning
Multi-Task Learning (MTL) is a type of machine learning technique where a model is trained to perform multiple tasks simultaneously. In deep learning, MTL refers to training a neural network to perform multiple tasks by sharing some of the network's layers and parameters across tasks. In MTL, the goal is to improve the generalization performance of
6 min read
Artificial intelligence vs Machine Learning vs Deep Learning
Nowadays many misconceptions are there related to the words machine learning, deep learning, and artificial intelligence (AI), most people think all these things are the same whenever they hear the word AI, they directly relate that word to machine learning or vice versa, well yes, these things are related to each other but not the same. Let's see
4 min read
Need of Data Structures and Algorithms for Deep Learning and Machine Learning
Deep Learning is a field that is heavily based on Mathematics and you need to have a good understanding of Data Structures and Algorithms to solve the mathematical problems optimally. Data Structures and Algorithms can be used to determine how a problem is represented internally or how the actual storage pattern works &amp; what is happening under
6 min read
Difference Between Artificial Intelligence vs Machine Learning vs Deep Learning
Artificial Intelligence is basically the mechanism to incorporate human intelligence into machines through a set of rules(algorithm). AI is a combination of two words: "Artificial" meaning something made by humans or non-natural things and "Intelligence" meaning the ability to understand or think accordingly. Another definition could be that "AI is
14 min read
Difference Between Machine Learning and Deep Learning
If you are interested in building your career in the IT industry then you must have come across the term Data Science which is a booming field in terms of technologies and job availability as well. In this article, we will explore the Difference between Machine Learning and Deep Learning, two major fields within Data Science. Understanding these di
8 min read
Article Tags :
AI-ML-DS
Deep Learning
Machine Learning
AI-ML-DS With Python
+1 More
Practice Tags :
Machine Learning
python
288k+ interested Geeks
Data Structures & Algorithms in Python - Self Paced
Explore
203k+ interested Geeks
Python Full Course Online - Complete Beginner to Advanced
Explore
312k+ interested Geeks
Complete Machine Learning & Data Science Program
Explore

Share Your Experiences
100+ Machine Learning Projects with Source Code [2024]
Classification Projects
Regression Projects
Computer Vision Projects
OCR of Handwritten digits | OpenCV
Cartooning an Image using OpenCV - Python
Count number of Object using Python-OpenCV
Count number of Faces using Python - OpenCV
Text Detection and Extraction using OpenCV and OCR
FaceMask Detection using TensorFlow in Python
Dog Breed Classification using Transfer Learning
Flower Recognition Using Convolutional Neural Network
Emojify using Face Recognition with Machine Learning
Cat & Dog Classification using Convolutional Neural Network in Python
Traffic Signs Recognition using CNN and Keras in Python
Lung Cancer Detection using Convolutional Neural Network (CNN)
Lung Cancer Detection Using Transfer Learning
Pneumonia Detection using Deep Learning
Detecting Covid-19 with Chest X-ray
Skin Cancer Detection using TensorFlow
Age Detection using Deep Learning in OpenCV
Face and Hand Landmarks Detection using Python - Mediapipe, OpenCV
Detecting COVID-19 From Chest X-Ray Images using CNN
Image Segmentation Using TensorFlow
License Plate Recognition with OpenCV and Tesseract OCR
Detect and Recognize Car License Plate from a video in real time
Residual Networks (ResNet) - Deep Learning
Natural Language Processing Projects
Clustering Projects
Recommender System Project
Machine Learning & Data Science
Course
Residual Networks (ResNet) – Deep Learning
Last Updated : 10 Jan, 2023
Generative Summary
Now you can generate the summary of any article of your choice.
Got it

After the first CNN-based architecture (AlexNet) that win the ImageNet 2012 competition, Every subsequent winning architecture uses more layers in a deep neural network to reduce the error rate. This works for less number of layers, but when we increase the number of layers, there is a common problem in deep learning associated with that called the Vanishing/Exploding gradient. This causes the gradient to become 0 or too large. Thus when we increases number of layers, the training and test error rate also increases. 

Comparison of 20-layer vs 56-layer architecture

In the above plot, we can observe that a 56-layer CNN gives more error rate on both training and testing dataset than a 20-layer CNN architecture. After analyzing more on error rate the authors were able to reach conclusion that it is caused by vanishing/exploding gradient. 
ResNet, which was proposed in 2015 by researchers at Microsoft Research introduced a new architecture called Residual Network. 

Residual Network: In order to solve the problem of the vanishing/exploding gradient, this architecture introduced the concept called Residual Blocks. In this network, we use a technique called skip connections. The skip connection connects activations of a  layer to further layers by skipping some layers in between. This forms a residual block. Resnets are made by stacking these residual blocks together. 
The approach behind this network is instead of layers learning the underlying mapping, we allow the network to fit the residual mapping. So, instead of say H(x), initial mapping, let the network fit, 

F(x) := H(x) - x which gives H(x) := F(x) + x. 

Skip (Shortcut) connection

The advantage of adding this type of skip connection is that if any layer hurt the performance of architecture then it will be skipped by regularization. So, this results in training a very deep neural network without the problems caused by vanishing/exploding gradient.  The authors of the paper experimented on 100-1000 layers of the CIFAR-10 dataset. 
There is a similar approach called “highway networks”, these networks also use skip connection. Similar to LSTM these skip connections also use parametric gates. These gates determine how much information passes through the skip connection. This architecture however has not provided accuracy better than ResNet architecture. 

Network Architecture: This network uses a 34-layer plain network architecture inspired by VGG-19 in which then the shortcut connection is added. These shortcut connections then convert the architecture into a residual network.  

ResNet -34 architecture

Implementation: Using the Tensorflow and Keras API, we can design ResNet architecture (including Residual Blocks) from scratch. Below is the implementation of different ResNet architecture. For this implementation, we use the CIFAR-10 dataset. This dataset contains 60, 000 32×32 color images in 10 different classes (airplanes, cars, birds, cats, deer, dogs, frogs, horses, ships, and trucks), etc. This dataset can be assessed from keras.datasets API function. 

Step 1: First, we import the keras module and its APIs. These APIs help in building the architecture of the ResNet model.

Code: Importing libraries 

# Import Keras modules and its important APIs
import keras
from keras.layers import Dense, Conv2D, BatchNormalization, Activation
from keras.layers import AveragePooling2D, Input, Flatten
from keras.optimizers import Adam
from keras.callbacks import ModelCheckpoint, LearningRateScheduler
from keras.callbacks import ReduceLROnPlateau
from keras.preprocessing.image import ImageDataGenerator
from keras.regularizers import l2
from keras import backend as K
from keras.models import Model
from keras.datasets import cifar10
import numpy as np
import os

Step 2: Now, We set different hyper parameters that are required for ResNet architecture. We also did some preprocessing on our dataset to prepare it for training.

Code: Setting Training Hyperparameters  

python3

# Setting Training Hyperparameters 
batch_size = 32  # original ResNet paper uses batch_size = 128 for training 
epochs = 200
data_augmentation = True
num_classes = 10

# Data Preprocessing  
subtract_pixel_mean = True
n = 3

# Select ResNet Version 
version = 1

# Computed depth of  
if version == 1: 
    depth = n * 6 + 2
elif version == 2: 
    depth = n * 9 + 2

# Model name, depth and version 
model_type = 'ResNet % dv % d' % (depth, version) 

# Load the CIFAR-10 data. 
(x_train, y_train), (x_test, y_test) = cifar10.load_data() 

# Input image dimensions. 
input_shape = x_train.shape[1:] 

# Normalize data. 
x_train = x_train.astype('float32') / 255
x_test = x_test.astype('float32') / 255

# If subtract pixel mean is enabled 
if subtract_pixel_mean: 
    x_train_mean = np.mean(x_train, axis = 0) 
    x_train -= x_train_mean 
    x_test -= x_train_mean 

# Print Training and Test Samples  
print('x_train shape:', x_train.shape) 
print(x_train.shape[0], 'train samples') 
print(x_test.shape[0], 'test samples') 
print('y_train shape:', y_train.shape) 

# Convert class vectors to binary class matrices. 
y_train = keras.utils.to_categorical(y_train, num_classes) 
y_test = keras.utils.to_categorical(y_test, num_classes) 

Step 3: In this step, we set the learning rate according to the number of epochs. As the number of epochs the learning rate must be decreased to ensure better learning.

Code: Setting LR for different numbers of Epochs 

python3

# Setting LR for different number of Epochs 
def lr_schedule(epoch): 
    lr = 1e-3
    if epoch > 180: 
        lr *= 0.5e-3
    elif epoch > 160: 
        lr *= 1e-3
    elif epoch > 120: 
        lr *= 1e-2
    elif epoch > 80: 
        lr *= 1e-1
    print('Learning rate: ', lr) 
    return lr 

Step 4: Define basic ResNet building block that can be used for defining the ResNet V1 and V2 architecture.

Code: Basic ResNet Building Block 

python3

# Basic ResNet Building Block 

def resnet_layer(inputs, 
                 num_filters=16, 
                 kernel_size=3, 
                 strides=1, 
                 activation='relu', 
                 batch_normalization=True, 
    conv=Conv2D(num_filters, 
                  kernel_size=kernel_size, 
                  strides=strides, 
                  padding='same', 
                  kernel_initializer='he_normal', 
                  kernel_regularizer=l2(1e-4)) 

    x=inputs 
    if conv_first: 
        x = conv(x) 
        if batch_normalization: 
            x = BatchNormalization()(x) 
        if activation is not None: 
            x = Activation(activation)(x) 
    else: 
        if batch_normalization: 
            x = BatchNormalization()(x) 
        if activation is not None: 
            x = Activation(activation)(x) 
        x = conv(x) 
    return x 

Step 5: Define ResNet V1 architecture that is based on the ResNet building block we defined above:

Code: ResNet V1 architecture 

python3

def resnet_v1(input_shape, depth, num_classes=10): 

    if (depth - 2) % 6 != 0: 
        raise ValueError('depth should be 6n + 2 (eg 20, 32, 44 in [a])') 
    # Start model definition. 
    num_filters = 16
    num_res_blocks = int((depth - 2) / 6) 

    inputs = Input(shape=input_shape) 
    x = resnet_layer(inputs=inputs) 
    # Instantiate the stack of residual units 
    for stack in range(3): 
        for res_block in range(num_res_blocks): 
            strides = 1
            if stack & gt 
            0 and res_block == 0:  # first layer but not first stack 
                strides = 2  # downsample 
            y = resnet_layer(inputs=x, 
                             num_filters=num_filters, 
                             strides=strides) 
            y = resnet_layer(inputs=y, 
                             num_filters=num_filters, 
                             activation=None) 
            if stack & gt 
            0 and res_block == 0:  # first layer but not first stack 
                # linear projection residual shortcut connection to match 
                # changed dims 
                x = resnet_layer(inputs=x, 
                                 num_filters=num_filters, 
                                 kernel_size=1, 
                                 strides=strides, 
                                 activation=None, 
                                 batch_normalization=False) 
            x = keras.layers.add([x, y]) 
            x = Activation('relu')(x) 
        num_filters *= 2

    # Add classifier on top. 
    # v1 does not use BN after last shortcut connection-ReLU 
    x = AveragePooling2D(pool_size=8)(x) 
    y = Flatten()(x) 
    outputs = Dense(num_classes, 
                    activation='softmax', 
                    kernel_initializer='he_normal')(y) 

    # Instantiate model. 
    model = Model(inputs=inputs, outputs=outputs) 
    return model 

Step 6: Define ResNet V2 architecture that is based on the ResNet building block we defined above:

Code: ResNet V2 architecture 

python3

# ResNet V2 architecture 
def resnet_v2(input_shape, depth, num_classes=10): 
    if (depth - 2) % 9 != 0: 
        raise ValueError('depth should be 9n + 2 (eg 56 or 110 in [b])') 
    # Start model definition. 
    num_filters_in = 16
    num_res_blocks = int((depth - 2) / 9) 

    inputs = Input(shape=input_shape) 
    # v2 performs Conv2D with BN-ReLU on input before splitting into 2 paths 
    x = resnet_layer(inputs=inputs, 
                     num_filters=num_filters_in, 
                     conv_first=True) 

    # Instantiate the stack of residual units 
    for stage in range(3): 
        for res_block in range(num_res_blocks): 
            activation = 'relu'
            batch_normalization = True
            strides = 1
            if stage == 0: 
                num_filters_out = num_filters_in * 4
                if res_block == 0:  # first layer and first stage 
                    activation = None
                    batch_normalization = False
            else: 
                num_filters_out = num_filters_in * 2
                if res_block == 0:  # first layer but not first stage 
                    strides = 2    # downsample 

            # bottleneck residual unit 
            y = resnet_layer(inputs=x, 
                             num_filters=num_filters_in, 
                             kernel_size=1, 
                             strides=strides, 
                             activation=activation, 
                             batch_normalization=batch_normalization, 
                             conv_first=False) 
            y = resnet_layer(inputs=y, 
                             num_filters=num_filters_in, 
                             conv_first=False) 
            y = resnet_layer(inputs=y, 
                             num_filters=num_filters_out, 
                             kernel_size=1, 
                             conv_first=False) 
            if res_block == 0: 
                # linear projection residual shortcut connection to match 
                # changed dims 
                x = resnet_layer(inputs=x, 
                                 num_filters=num_filters_out, 
                                 kernel_size=1, 
                                 strides=strides, 
                                 activation=None, 
                                 batch_normalization=False) 
            x = keras.layers.add([x, y]) 

        num_filters_in = num_filters_out 

    # Add classifier on top. 
    # v2 has BN-ReLU before Pooling 
    x = BatchNormalization()(x) 
    x = Activation('relu')(x) 
    x = AveragePooling2D(pool_size=8)(x) 
    y = Flatten()(x) 
    outputs = Dense(num_classes, 
                    activation='softmax', 
                    kernel_initializer='he_normal')(y) 

    # Instantiate model. 
    model = Model(inputs=inputs, outputs=outputs) 
    return model 

Step 7: The code below is used to train and test the ResNet v1 and v2 architecture we defined above:

Code: Main function 

python3

# Main function  
if version == 2: 
    model = resnet_v2(input_shape = input_shape, depth = depth) 
else: 
    model = resnet_v1(input_shape = input_shape, depth = depth) 

model.compile(loss ='categorical_crossentropy', 
              optimizer = Adam(learning_rate = lr_schedule(0)), 
              metrics =['accuracy']) 
model.summary() 
print(model_type) 

# Prepare model saving directory. 
save_dir = os.path.join(os.getcwd(), 'saved_models') 
model_name = 'cifar10_% s_model.{epoch:03d}.h5' % model_type 
if not os.path.isdir(save_dir): 
    os.makedirs(save_dir) 
filepath = os.path.join(save_dir, model_name) 

# Prepare callbacks for model saving and for learning rate adjustment. 
checkpoint = ModelCheckpoint(filepath = filepath, 
                             monitor ='val_acc', 
                             verbose = 1, 
                             save_best_only = True) 

lr_scheduler = LearningRateScheduler(lr_schedule) 

lr_reducer = ReduceLROnPlateau(factor = np.sqrt(0.1), 
                               cooldown = 0, 
                               patience = 5, 
                               min_lr = 0.5e-6) 

callbacks = [checkpoint, lr_reducer, lr_scheduler] 

# Run training, with or without data augmentation. 
if not data_augmentation: 
    print('Not using data augmentation.') 
    model.fit(x_train, y_train, 
              batch_size = batch_size, 
              epochs = epochs, 
              validation_data =(x_test, y_test), 
              shuffle = True, 
              callbacks = callbacks) 
else: 
    print('Using real-time data augmentation.') 
    # This will do preprocessing and realtime data augmentation: 
    datagen = ImageDataGenerator( 
        # set input mean to 0 over the dataset 
        featurewise_center = False, 
        # set each sample mean to 0 
        samplewise_center = False, 
        # divide inputs by std of dataset 
        featurewise_std_normalization = False, 
        # divide each input by its std 
        samplewise_std_normalization = False, 
        # apply ZCA whitening 
        zca_whitening = False, 
        # epsilon for ZCA whitening 
        zca_epsilon = 1e-06, 
        # randomly rotate images in the range (deg 0 to 180) 
        rotation_range = 0, 
        # randomly shift images horizontally 
        width_shift_range = 0.1, 
        # randomly shift images vertically 
        height_shift_range = 0.1, 
        # set range for random shear 
        shear_range = 0., 
        # set range for random zoom 
        zoom_range = 0., 
        # set range for random channel shifts 
        channel_shift_range = 0., 
        # set mode for filling points outside the input boundaries 
        fill_mode ='nearest', 
        # value used for fill_mode = "constant" 
        cval = 0., 
        # randomly flip images 
        horizontal_flip = True, 
        # randomly flip images 
        vertical_flip = False, 
        # set rescaling factor (applied before any other transformation) 
        rescale = None, 
        # set function that will be applied on each input 
        preprocessing_function = None, 
        # image data format, either "channels_first" or "channels_last" 
        data_format = None, 
        # fraction of images reserved for validation (strictly between 0 and 1) 
        validation_split = 0.0) 

    # Compute quantities required for featurewise normalization 
    # (std, mean, and principal components if ZCA whitening is applied). 
    datagen.fit(x_train) 

    # Fit the model on the batches generated by datagen.flow(). 
    model.fit_generator(datagen.flow(x_train, y_train, batch_size = batch_size), 
                        validation_data =(x_test, y_test), 
                        epochs = epochs, verbose = 1, workers = 4, 
                        callbacks = callbacks) 

# Score trained model. 
scores = model.evaluate(x_test, y_test, verbose = 1) 
print('Test loss:', scores[0]) 
print('Test accuracy:', scores[1])

Results & Conclusion: 
On the ImageNet dataset,  the authors uses a 152-layers ResNet, which is 8 times more deep than VGG19 but still have less parameters. An ensemble of these ResNets generated an error of only 3.7% on ImageNet test set, the result which won ILSVRC 2015 competition. On COCO object detection dataset, it also generates a 28% relative improvement due to its very deep representation. 

Error-rate on ResNet Architecture

The result above shows that shortcut connections would be able to solve the problem caused by increasing the layers because as we increase layers from 18 to 34 the error rate on ImageNet Validation Set also decreases unlike the plain network.

top-1 and top-5 Error rate on ImageNet Validation Set.

Below are the results on ImageNet Test Set. The 3.57% top-5 error rate of ResNet was the lowest and thus ResNet architecture came first in ImageNet classification challenge in 2015.

Are you passionate about data and looking to make one giant leap into your career? Our Data Science Course will help you change your game and, most importantly, allow students, professionals, and working adults to tide over into the data science immersion. Master state-of-the-art methodologies, powerful tools, and industry best practices, hands-on projects, and real-world applications. Become the executive head of industries related to Data Analysis, Machine Learning, and Data Visualization with these growing skills. Ready to Transform Your Future? Enroll Now to Be a Data Science Expert!

P

pawangfg
12
Previous Article
Detect and Recognize Car License Plate from a video in real time
Next Article
Twitter Sentiment Analysis using Python
Read More
Video | Residual Networks (ResNet) - Deep Learning
Similar Reads
Introduction to Residual Networks
Recent years have seen tremendous progress in the field of Image Processing and Recognition. Deep Neural Networks are becoming deeper and more complex. It has been proved that adding more layers to a Neural Network can make it more robust for image-related tasks. But it can also cause them to lose accuracy. That's where Residual Networks come into
3 min read
Deep Belief Network (DBN) in Deep Learning
Discover data creation with Deep Belief Networks (DBNs), cutting-edge generative models that make use of deep architecture. This article walks you through the concepts of DBNs, how they work, and how to implement them using practical coding. What is a Deep Belief Network?Deep Belief Networks (DBNs) are sophisticated artificial neural networks used
9 min read
Deep Boltzmann Machines (DBMs) in Deep Learning
In this article, we will discuss the Deep Boltzmann Machines concepts and their applications in the real-world scenario. What are Deep Boltzmann Machines (DBMs)?Deep Boltzmann Machines (DBMs) are a kind of artificial neural network that belongs to the family of generative models. They are designed to discover intricate structures within large datas
10 min read
Unveiling the Power of Fastai: A Deep Dive into the Versatile Deep Learning Library
Fastai is a powerful deep-learning library designed for researchers and practitioners. It offers high-level abstractions, PyTorch integration, and application-specific APIs, making it both adaptable and accessible for a wide range of deep learning tasks. In this article, we'll delve into the intricacies of Fastai, a powerful deep-learning library.
9 min read
Spiking Neural Networks in Deep Learning
Spiking Neural Networks (SNNs) represent a novel approach in artificial neural networks, inspired by the biological processes of the human brain. Unlike traditional artificial neural networks (ANNs) that rely on continuous signal processing, SNNs operate on discrete events called "spikes." The aim of this article is to provide an in-depth understan
10 min read
Introduction to Multi-Task Learning(MTL) for Deep Learning
Multi-Task Learning (MTL) is a type of machine learning technique where a model is trained to perform multiple tasks simultaneously. In deep learning, MTL refers to training a neural network to perform multiple tasks by sharing some of the network's layers and parameters across tasks. In MTL, the goal is to improve the generalization performance of
6 min read
Artificial intelligence vs Machine Learning vs Deep Learning
Nowadays many misconceptions are there related to the words machine learning, deep learning, and artificial intelligence (AI), most people think all these things are the same whenever they hear the word AI, they directly relate that word to machine learning or vice versa, well yes, these things are related to each other but not the same. Let's see
4 min read
Need of Data Structures and Algorithms for Deep Learning and Machine Learning
Deep Learning is a field that is heavily based on Mathematics and you need to have a good understanding of Data Structures and Algorithms to solve the mathematical problems optimally. Data Structures and Algorithms can be used to determine how a problem is represented internally or how the actual storage pattern works &amp; what is happening under
6 min read
Difference Between Artificial Intelligence vs Machine Learning vs Deep Learning
Artificial Intelligence is basically the mechanism to incorporate human intelligence into machines through a set of rules(algorithm). AI is a combination of two words: "Artificial" meaning something made by humans or non-natural things and "Intelligence" meaning the ability to understand or think accordingly. Another definition could be that "AI is
14 min read
Difference Between Machine Learning and Deep Learning
If you are interested in building your career in the IT industry then you must have come across the term Data Science which is a booming field in terms of technologies and job availability as well. In this article, we will explore the Difference between Machine Learning and Deep Learning, two major fields within Data Science. Understanding these di
8 min read
Article Tags :
AI-ML-DS
Deep Learning
Machine Learning
AI-ML-DS With Python
+1 More
Practice Tags :
Machine Learning
python
288k+ interested Geeks
Data Structures & Algorithms in Python - Self Paced
Explore
203k+ interested Geeks
Python Full Course Online - Complete Beginner to Advanced
Explore
312k+ interested Geeks
Complete Machine Learning & Data Science Program
Explore

Share Your Experiences
100+ Machine Learning Projects with Source Code [2024]
Classification Projects
Regression Projects
Computer Vision Projects
OCR of Handwritten digits | OpenCV
Cartooning an Image using OpenCV - Python
Count number of Object using Python-OpenCV
Count number of Faces using Python - OpenCV
Text Detection and Extraction using OpenCV and OCR
FaceMask Detection using TensorFlow in Python
Dog Breed Classification using Transfer Learning
Flower Recognition Using Convolutional Neural Network
Emojify using Face Recognition with Machine Learning
Cat & Dog Classification using Convolutional Neural Network in Python
Traffic Signs Recognition using CNN and Keras in Python
Lung Cancer Detection using Convolutional Neural Network (CNN)
Lung Cancer Detection Using Transfer Learning
Pneumonia Detection using Deep Learning
Detecting Covid-19 with Chest X-ray
Skin Cancer Detection using TensorFlow
Age Detection using Deep Learning in OpenCV
Face and Hand Landmarks Detection using Python - Mediapipe, OpenCV
Detecting COVID-19 From Chest X-Ray Images using CNN
Image Segmentation Using TensorFlow
License Plate Recognition with OpenCV and Tesseract OCR
Detect and Recognize Car License Plate from a video in real time
Residual Networks (ResNet) - Deep Learning
Natural Language Processing Projects
Clustering Projects
Recommender System Project
Machine Learning & Data Science
Course

Share Your Experiences
100+ Machine Learning Projects with Source Code [2024]
Classification Projects
Regression Projects
Computer Vision Projects
OCR of Handwritten digits | OpenCV
Cartooning an Image using OpenCV - Python
Count number of Object using Python-OpenCV
Count number of Faces using Python - OpenCV
Text Detection and Extraction using OpenCV and OCR
FaceMask Detection using TensorFlow in Python
Dog Breed Classification using Transfer Learning
Flower Recognition Using Convolutional Neural Network
Emojify using Face Recognition with Machine Learning
Cat & Dog Classification using Convolutional Neural Network in Python
Traffic Signs Recognition using CNN and Keras in Python
Lung Cancer Detection using Convolutional Neural Network (CNN)
Lung Cancer Detection Using Transfer Learning
Pneumonia Detection using Deep Learning
Detecting Covid-19 with Chest X-ray
Skin Cancer Detection using TensorFlow
Age Detection using Deep Learning in OpenCV
Face and Hand Landmarks Detection using Python - Mediapipe, OpenCV
Detecting COVID-19 From Chest X-Ray Images using CNN
Image Segmentation Using TensorFlow
License Plate Recognition with OpenCV and Tesseract OCR
Detect and Recognize Car License Plate from a video in real time
Residual Networks (ResNet) - Deep Learning
Natural Language Processing Projects
Clustering Projects
Recommender System Project
Machine Learning & Data Science
Course

Share Your Experiences
100+ Machine Learning Projects with Source Code [2024]
Classification Projects
Regression Projects
Computer Vision Projects
OCR of Handwritten digits | OpenCV
Cartooning an Image using OpenCV - Python
Count number of Object using Python-OpenCV
Count number of Faces using Python - OpenCV
Text Detection and Extraction using OpenCV and OCR
FaceMask Detection using TensorFlow in Python
Dog Breed Classification using Transfer Learning
Flower Recognition Using Convolutional Neural Network
Emojify using Face Recognition with Machine Learning
Cat & Dog Classification using Convolutional Neural Network in Python
Traffic Signs Recognition using CNN and Keras in Python
Lung Cancer Detection using Convolutional Neural Network (CNN)
Lung Cancer Detection Using Transfer Learning
Pneumonia Detection using Deep Learning
Detecting Covid-19 with Chest X-ray
Skin Cancer Detection using TensorFlow
Age Detection using Deep Learning in OpenCV
Face and Hand Landmarks Detection using Python - Mediapipe, OpenCV
Detecting COVID-19 From Chest X-Ray Images using CNN
Image Segmentation Using TensorFlow
License Plate Recognition with OpenCV and Tesseract OCR
Detect and Recognize Car License Plate from a video in real time
Residual Networks (ResNet) - Deep Learning
Natural Language Processing Projects
Clustering Projects
Recommender System Project
Machine Learning & Data Science
Course

Share Your Experiences

100+ Machine Learning Projects with Source Code [2024]
Classification Projects
Regression Projects
Computer Vision Projects
OCR of Handwritten digits | OpenCV
Cartooning an Image using OpenCV - Python
Count number of Object using Python-OpenCV
Count number of Faces using Python - OpenCV
Text Detection and Extraction using OpenCV and OCR
FaceMask Detection using TensorFlow in Python
Dog Breed Classification using Transfer Learning
Flower Recognition Using Convolutional Neural Network
Emojify using Face Recognition with Machine Learning
Cat & Dog Classification using Convolutional Neural Network in Python
Traffic Signs Recognition using CNN and Keras in Python
Lung Cancer Detection using Convolutional Neural Network (CNN)
Lung Cancer Detection Using Transfer Learning
Pneumonia Detection using Deep Learning
Detecting Covid-19 with Chest X-ray
Skin Cancer Detection using TensorFlow
Age Detection using Deep Learning in OpenCV
Face and Hand Landmarks Detection using Python - Mediapipe, OpenCV
Detecting COVID-19 From Chest X-Ray Images using CNN
Image Segmentation Using TensorFlow
License Plate Recognition with OpenCV and Tesseract OCR
Detect and Recognize Car License Plate from a video in real time
Residual Networks (ResNet) - Deep Learning
Natural Language Processing Projects
Clustering Projects
Recommender System Project
Machine Learning & Data Science
Course

Classification Projects

Classification Projects

Regression Projects

Regression Projects

Computer Vision Projects
OCR of Handwritten digits | OpenCV
Cartooning an Image using OpenCV - Python
Count number of Object using Python-OpenCV
Count number of Faces using Python - OpenCV
Text Detection and Extraction using OpenCV and OCR
FaceMask Detection using TensorFlow in Python
Dog Breed Classification using Transfer Learning
Flower Recognition Using Convolutional Neural Network
Emojify using Face Recognition with Machine Learning
Cat & Dog Classification using Convolutional Neural Network in Python
Traffic Signs Recognition using CNN and Keras in Python
Lung Cancer Detection using Convolutional Neural Network (CNN)
Lung Cancer Detection Using Transfer Learning
Pneumonia Detection using Deep Learning
Detecting Covid-19 with Chest X-ray
Skin Cancer Detection using TensorFlow
Age Detection using Deep Learning in OpenCV
Face and Hand Landmarks Detection using Python - Mediapipe, OpenCV
Detecting COVID-19 From Chest X-Ray Images using CNN
Image Segmentation Using TensorFlow
License Plate Recognition with OpenCV and Tesseract OCR
Detect and Recognize Car License Plate from a video in real time
Residual Networks (ResNet) - Deep Learning

Computer Vision Projects

Natural Language Processing Projects

Natural Language Processing Projects

Clustering Projects

Clustering Projects

Recommender System Project

Recommender System Project

Residual Networks (ResNet) – Deep Learning
Last Updated : 10 Jan, 2023
Generative Summary
Now you can generate the summary of any article of your choice.
Got it

After the first CNN-based architecture (AlexNet) that win the ImageNet 2012 competition, Every subsequent winning architecture uses more layers in a deep neural network to reduce the error rate. This works for less number of layers, but when we increase the number of layers, there is a common problem in deep learning associated with that called the Vanishing/Exploding gradient. This causes the gradient to become 0 or too large. Thus when we increases number of layers, the training and test error rate also increases. 

Comparison of 20-layer vs 56-layer architecture

In the above plot, we can observe that a 56-layer CNN gives more error rate on both training and testing dataset than a 20-layer CNN architecture. After analyzing more on error rate the authors were able to reach conclusion that it is caused by vanishing/exploding gradient. 
ResNet, which was proposed in 2015 by researchers at Microsoft Research introduced a new architecture called Residual Network. 

Residual Network: In order to solve the problem of the vanishing/exploding gradient, this architecture introduced the concept called Residual Blocks. In this network, we use a technique called skip connections. The skip connection connects activations of a  layer to further layers by skipping some layers in between. This forms a residual block. Resnets are made by stacking these residual blocks together. 
The approach behind this network is instead of layers learning the underlying mapping, we allow the network to fit the residual mapping. So, instead of say H(x), initial mapping, let the network fit, 

F(x) := H(x) - x which gives H(x) := F(x) + x. 

Skip (Shortcut) connection

The advantage of adding this type of skip connection is that if any layer hurt the performance of architecture then it will be skipped by regularization. So, this results in training a very deep neural network without the problems caused by vanishing/exploding gradient.  The authors of the paper experimented on 100-1000 layers of the CIFAR-10 dataset. 
There is a similar approach called “highway networks”, these networks also use skip connection. Similar to LSTM these skip connections also use parametric gates. These gates determine how much information passes through the skip connection. This architecture however has not provided accuracy better than ResNet architecture. 

Network Architecture: This network uses a 34-layer plain network architecture inspired by VGG-19 in which then the shortcut connection is added. These shortcut connections then convert the architecture into a residual network.  

ResNet -34 architecture

Implementation: Using the Tensorflow and Keras API, we can design ResNet architecture (including Residual Blocks) from scratch. Below is the implementation of different ResNet architecture. For this implementation, we use the CIFAR-10 dataset. This dataset contains 60, 000 32×32 color images in 10 different classes (airplanes, cars, birds, cats, deer, dogs, frogs, horses, ships, and trucks), etc. This dataset can be assessed from keras.datasets API function. 

Step 1: First, we import the keras module and its APIs. These APIs help in building the architecture of the ResNet model.

Code: Importing libraries 

# Import Keras modules and its important APIs
import keras
from keras.layers import Dense, Conv2D, BatchNormalization, Activation
from keras.layers import AveragePooling2D, Input, Flatten
from keras.optimizers import Adam
from keras.callbacks import ModelCheckpoint, LearningRateScheduler
from keras.callbacks import ReduceLROnPlateau
from keras.preprocessing.image import ImageDataGenerator
from keras.regularizers import l2
from keras import backend as K
from keras.models import Model
from keras.datasets import cifar10
import numpy as np
import os

Step 2: Now, We set different hyper parameters that are required for ResNet architecture. We also did some preprocessing on our dataset to prepare it for training.

Code: Setting Training Hyperparameters  

python3

# Setting Training Hyperparameters 
batch_size = 32  # original ResNet paper uses batch_size = 128 for training 
epochs = 200
data_augmentation = True
num_classes = 10

# Data Preprocessing  
subtract_pixel_mean = True
n = 3

# Select ResNet Version 
version = 1

# Computed depth of  
if version == 1: 
    depth = n * 6 + 2
elif version == 2: 
    depth = n * 9 + 2

# Model name, depth and version 
model_type = 'ResNet % dv % d' % (depth, version) 

# Load the CIFAR-10 data. 
(x_train, y_train), (x_test, y_test) = cifar10.load_data() 

# Input image dimensions. 
input_shape = x_train.shape[1:] 

# Normalize data. 
x_train = x_train.astype('float32') / 255
x_test = x_test.astype('float32') / 255

# If subtract pixel mean is enabled 
if subtract_pixel_mean: 
    x_train_mean = np.mean(x_train, axis = 0) 
    x_train -= x_train_mean 
    x_test -= x_train_mean 

# Print Training and Test Samples  
print('x_train shape:', x_train.shape) 
print(x_train.shape[0], 'train samples') 
print(x_test.shape[0], 'test samples') 
print('y_train shape:', y_train.shape) 

# Convert class vectors to binary class matrices. 
y_train = keras.utils.to_categorical(y_train, num_classes) 
y_test = keras.utils.to_categorical(y_test, num_classes) 

Step 3: In this step, we set the learning rate according to the number of epochs. As the number of epochs the learning rate must be decreased to ensure better learning.

Code: Setting LR for different numbers of Epochs 

python3

# Setting LR for different number of Epochs 
def lr_schedule(epoch): 
    lr = 1e-3
    if epoch > 180: 
        lr *= 0.5e-3
    elif epoch > 160: 
        lr *= 1e-3
    elif epoch > 120: 
        lr *= 1e-2
    elif epoch > 80: 
        lr *= 1e-1
    print('Learning rate: ', lr) 
    return lr 

Step 4: Define basic ResNet building block that can be used for defining the ResNet V1 and V2 architecture.

Code: Basic ResNet Building Block 

python3

# Basic ResNet Building Block 

def resnet_layer(inputs, 
                 num_filters=16, 
                 kernel_size=3, 
                 strides=1, 
                 activation='relu', 
                 batch_normalization=True, 
    conv=Conv2D(num_filters, 
                  kernel_size=kernel_size, 
                  strides=strides, 
                  padding='same', 
                  kernel_initializer='he_normal', 
                  kernel_regularizer=l2(1e-4)) 

    x=inputs 
    if conv_first: 
        x = conv(x) 
        if batch_normalization: 
            x = BatchNormalization()(x) 
        if activation is not None: 
            x = Activation(activation)(x) 
    else: 
        if batch_normalization: 
            x = BatchNormalization()(x) 
        if activation is not None: 
            x = Activation(activation)(x) 
        x = conv(x) 
    return x 

Step 5: Define ResNet V1 architecture that is based on the ResNet building block we defined above:

Code: ResNet V1 architecture 

python3

def resnet_v1(input_shape, depth, num_classes=10): 

    if (depth - 2) % 6 != 0: 
        raise ValueError('depth should be 6n + 2 (eg 20, 32, 44 in [a])') 
    # Start model definition. 
    num_filters = 16
    num_res_blocks = int((depth - 2) / 6) 

    inputs = Input(shape=input_shape) 
    x = resnet_layer(inputs=inputs) 
    # Instantiate the stack of residual units 
    for stack in range(3): 
        for res_block in range(num_res_blocks): 
            strides = 1
            if stack & gt 
            0 and res_block == 0:  # first layer but not first stack 
                strides = 2  # downsample 
            y = resnet_layer(inputs=x, 
                             num_filters=num_filters, 
                             strides=strides) 
            y = resnet_layer(inputs=y, 
                             num_filters=num_filters, 
                             activation=None) 
            if stack & gt 
            0 and res_block == 0:  # first layer but not first stack 
                # linear projection residual shortcut connection to match 
                # changed dims 
                x = resnet_layer(inputs=x, 
                                 num_filters=num_filters, 
                                 kernel_size=1, 
                                 strides=strides, 
                                 activation=None, 
                                 batch_normalization=False) 
            x = keras.layers.add([x, y]) 
            x = Activation('relu')(x) 
        num_filters *= 2

    # Add classifier on top. 
    # v1 does not use BN after last shortcut connection-ReLU 
    x = AveragePooling2D(pool_size=8)(x) 
    y = Flatten()(x) 
    outputs = Dense(num_classes, 
                    activation='softmax', 
                    kernel_initializer='he_normal')(y) 

    # Instantiate model. 
    model = Model(inputs=inputs, outputs=outputs) 
    return model 

Step 6: Define ResNet V2 architecture that is based on the ResNet building block we defined above:

Code: ResNet V2 architecture 

python3

# ResNet V2 architecture 
def resnet_v2(input_shape, depth, num_classes=10): 
    if (depth - 2) % 9 != 0: 
        raise ValueError('depth should be 9n + 2 (eg 56 or 110 in [b])') 
    # Start model definition. 
    num_filters_in = 16
    num_res_blocks = int((depth - 2) / 9) 

    inputs = Input(shape=input_shape) 
    # v2 performs Conv2D with BN-ReLU on input before splitting into 2 paths 
    x = resnet_layer(inputs=inputs, 
                     num_filters=num_filters_in, 
                     conv_first=True) 

    # Instantiate the stack of residual units 
    for stage in range(3): 
        for res_block in range(num_res_blocks): 
            activation = 'relu'
            batch_normalization = True
            strides = 1
            if stage == 0: 
                num_filters_out = num_filters_in * 4
                if res_block == 0:  # first layer and first stage 
                    activation = None
                    batch_normalization = False
            else: 
                num_filters_out = num_filters_in * 2
                if res_block == 0:  # first layer but not first stage 
                    strides = 2    # downsample 

            # bottleneck residual unit 
            y = resnet_layer(inputs=x, 
                             num_filters=num_filters_in, 
                             kernel_size=1, 
                             strides=strides, 
                             activation=activation, 
                             batch_normalization=batch_normalization, 
                             conv_first=False) 
            y = resnet_layer(inputs=y, 
                             num_filters=num_filters_in, 
                             conv_first=False) 
            y = resnet_layer(inputs=y, 
                             num_filters=num_filters_out, 
                             kernel_size=1, 
                             conv_first=False) 
            if res_block == 0: 
                # linear projection residual shortcut connection to match 
                # changed dims 
                x = resnet_layer(inputs=x, 
                                 num_filters=num_filters_out, 
                                 kernel_size=1, 
                                 strides=strides, 
                                 activation=None, 
                                 batch_normalization=False) 
            x = keras.layers.add([x, y]) 

        num_filters_in = num_filters_out 

    # Add classifier on top. 
    # v2 has BN-ReLU before Pooling 
    x = BatchNormalization()(x) 
    x = Activation('relu')(x) 
    x = AveragePooling2D(pool_size=8)(x) 
    y = Flatten()(x) 
    outputs = Dense(num_classes, 
                    activation='softmax', 
                    kernel_initializer='he_normal')(y) 

    # Instantiate model. 
    model = Model(inputs=inputs, outputs=outputs) 
    return model 

Step 7: The code below is used to train and test the ResNet v1 and v2 architecture we defined above:

Code: Main function 

python3

# Main function  
if version == 2: 
    model = resnet_v2(input_shape = input_shape, depth = depth) 
else: 
    model = resnet_v1(input_shape = input_shape, depth = depth) 

model.compile(loss ='categorical_crossentropy', 
              optimizer = Adam(learning_rate = lr_schedule(0)), 
              metrics =['accuracy']) 
model.summary() 
print(model_type) 

# Prepare model saving directory. 
save_dir = os.path.join(os.getcwd(), 'saved_models') 
model_name = 'cifar10_% s_model.{epoch:03d}.h5' % model_type 
if not os.path.isdir(save_dir): 
    os.makedirs(save_dir) 
filepath = os.path.join(save_dir, model_name) 

# Prepare callbacks for model saving and for learning rate adjustment. 
checkpoint = ModelCheckpoint(filepath = filepath, 
                             monitor ='val_acc', 
                             verbose = 1, 
                             save_best_only = True) 

lr_scheduler = LearningRateScheduler(lr_schedule) 

lr_reducer = ReduceLROnPlateau(factor = np.sqrt(0.1), 
                               cooldown = 0, 
                               patience = 5, 
                               min_lr = 0.5e-6) 

callbacks = [checkpoint, lr_reducer, lr_scheduler] 

# Run training, with or without data augmentation. 
if not data_augmentation: 
    print('Not using data augmentation.') 
    model.fit(x_train, y_train, 
              batch_size = batch_size, 
              epochs = epochs, 
              validation_data =(x_test, y_test), 
              shuffle = True, 
              callbacks = callbacks) 
else: 
    print('Using real-time data augmentation.') 
    # This will do preprocessing and realtime data augmentation: 
    datagen = ImageDataGenerator( 
        # set input mean to 0 over the dataset 
        featurewise_center = False, 
        # set each sample mean to 0 
        samplewise_center = False, 
        # divide inputs by std of dataset 
        featurewise_std_normalization = False, 
        # divide each input by its std 
        samplewise_std_normalization = False, 
        # apply ZCA whitening 
        zca_whitening = False, 
        # epsilon for ZCA whitening 
        zca_epsilon = 1e-06, 
        # randomly rotate images in the range (deg 0 to 180) 
        rotation_range = 0, 
        # randomly shift images horizontally 
        width_shift_range = 0.1, 
        # randomly shift images vertically 
        height_shift_range = 0.1, 
        # set range for random shear 
        shear_range = 0., 
        # set range for random zoom 
        zoom_range = 0., 
        # set range for random channel shifts 
        channel_shift_range = 0., 
        # set mode for filling points outside the input boundaries 
        fill_mode ='nearest', 
        # value used for fill_mode = "constant" 
        cval = 0., 
        # randomly flip images 
        horizontal_flip = True, 
        # randomly flip images 
        vertical_flip = False, 
        # set rescaling factor (applied before any other transformation) 
        rescale = None, 
        # set function that will be applied on each input 
        preprocessing_function = None, 
        # image data format, either "channels_first" or "channels_last" 
        data_format = None, 
        # fraction of images reserved for validation (strictly between 0 and 1) 
        validation_split = 0.0) 

    # Compute quantities required for featurewise normalization 
    # (std, mean, and principal components if ZCA whitening is applied). 
    datagen.fit(x_train) 

    # Fit the model on the batches generated by datagen.flow(). 
    model.fit_generator(datagen.flow(x_train, y_train, batch_size = batch_size), 
                        validation_data =(x_test, y_test), 
                        epochs = epochs, verbose = 1, workers = 4, 
                        callbacks = callbacks) 

# Score trained model. 
scores = model.evaluate(x_test, y_test, verbose = 1) 
print('Test loss:', scores[0]) 
print('Test accuracy:', scores[1])

Results & Conclusion: 
On the ImageNet dataset,  the authors uses a 152-layers ResNet, which is 8 times more deep than VGG19 but still have less parameters. An ensemble of these ResNets generated an error of only 3.7% on ImageNet test set, the result which won ILSVRC 2015 competition. On COCO object detection dataset, it also generates a 28% relative improvement due to its very deep representation. 

Error-rate on ResNet Architecture

The result above shows that shortcut connections would be able to solve the problem caused by increasing the layers because as we increase layers from 18 to 34 the error rate on ImageNet Validation Set also decreases unlike the plain network.

top-1 and top-5 Error rate on ImageNet Validation Set.

Below are the results on ImageNet Test Set. The 3.57% top-5 error rate of ResNet was the lowest and thus ResNet architecture came first in ImageNet classification challenge in 2015.

Are you passionate about data and looking to make one giant leap into your career? Our Data Science Course will help you change your game and, most importantly, allow students, professionals, and working adults to tide over into the data science immersion. Master state-of-the-art methodologies, powerful tools, and industry best practices, hands-on projects, and real-world applications. Become the executive head of industries related to Data Analysis, Machine Learning, and Data Visualization with these growing skills. Ready to Transform Your Future? Enroll Now to Be a Data Science Expert!

P

pawangfg
12
Previous Article
Detect and Recognize Car License Plate from a video in real time
Next Article
Twitter Sentiment Analysis using Python
Read More
Video | Residual Networks (ResNet) - Deep Learning
Similar Reads
Introduction to Residual Networks
Recent years have seen tremendous progress in the field of Image Processing and Recognition. Deep Neural Networks are becoming deeper and more complex. It has been proved that adding more layers to a Neural Network can make it more robust for image-related tasks. But it can also cause them to lose accuracy. That's where Residual Networks come into
3 min read
Deep Belief Network (DBN) in Deep Learning
Discover data creation with Deep Belief Networks (DBNs), cutting-edge generative models that make use of deep architecture. This article walks you through the concepts of DBNs, how they work, and how to implement them using practical coding. What is a Deep Belief Network?Deep Belief Networks (DBNs) are sophisticated artificial neural networks used
9 min read
Deep Boltzmann Machines (DBMs) in Deep Learning
In this article, we will discuss the Deep Boltzmann Machines concepts and their applications in the real-world scenario. What are Deep Boltzmann Machines (DBMs)?Deep Boltzmann Machines (DBMs) are a kind of artificial neural network that belongs to the family of generative models. They are designed to discover intricate structures within large datas
10 min read
Unveiling the Power of Fastai: A Deep Dive into the Versatile Deep Learning Library
Fastai is a powerful deep-learning library designed for researchers and practitioners. It offers high-level abstractions, PyTorch integration, and application-specific APIs, making it both adaptable and accessible for a wide range of deep learning tasks. In this article, we'll delve into the intricacies of Fastai, a powerful deep-learning library.
9 min read
Spiking Neural Networks in Deep Learning
Spiking Neural Networks (SNNs) represent a novel approach in artificial neural networks, inspired by the biological processes of the human brain. Unlike traditional artificial neural networks (ANNs) that rely on continuous signal processing, SNNs operate on discrete events called "spikes." The aim of this article is to provide an in-depth understan
10 min read
Introduction to Multi-Task Learning(MTL) for Deep Learning
Multi-Task Learning (MTL) is a type of machine learning technique where a model is trained to perform multiple tasks simultaneously. In deep learning, MTL refers to training a neural network to perform multiple tasks by sharing some of the network's layers and parameters across tasks. In MTL, the goal is to improve the generalization performance of
6 min read
Artificial intelligence vs Machine Learning vs Deep Learning
Nowadays many misconceptions are there related to the words machine learning, deep learning, and artificial intelligence (AI), most people think all these things are the same whenever they hear the word AI, they directly relate that word to machine learning or vice versa, well yes, these things are related to each other but not the same. Let's see
4 min read
Need of Data Structures and Algorithms for Deep Learning and Machine Learning
Deep Learning is a field that is heavily based on Mathematics and you need to have a good understanding of Data Structures and Algorithms to solve the mathematical problems optimally. Data Structures and Algorithms can be used to determine how a problem is represented internally or how the actual storage pattern works &amp; what is happening under
6 min read
Difference Between Artificial Intelligence vs Machine Learning vs Deep Learning
Artificial Intelligence is basically the mechanism to incorporate human intelligence into machines through a set of rules(algorithm). AI is a combination of two words: "Artificial" meaning something made by humans or non-natural things and "Intelligence" meaning the ability to understand or think accordingly. Another definition could be that "AI is
14 min read
Difference Between Machine Learning and Deep Learning
If you are interested in building your career in the IT industry then you must have come across the term Data Science which is a booming field in terms of technologies and job availability as well. In this article, we will explore the Difference between Machine Learning and Deep Learning, two major fields within Data Science. Understanding these di
8 min read
Article Tags :
AI-ML-DS
Deep Learning
Machine Learning
AI-ML-DS With Python
+1 More
Practice Tags :
Machine Learning
python

Residual Networks (ResNet) – Deep Learning
Last Updated : 10 Jan, 2023
Generative Summary
Now you can generate the summary of any article of your choice.
Got it

After the first CNN-based architecture (AlexNet) that win the ImageNet 2012 competition, Every subsequent winning architecture uses more layers in a deep neural network to reduce the error rate. This works for less number of layers, but when we increase the number of layers, there is a common problem in deep learning associated with that called the Vanishing/Exploding gradient. This causes the gradient to become 0 or too large. Thus when we increases number of layers, the training and test error rate also increases. 

Comparison of 20-layer vs 56-layer architecture

In the above plot, we can observe that a 56-layer CNN gives more error rate on both training and testing dataset than a 20-layer CNN architecture. After analyzing more on error rate the authors were able to reach conclusion that it is caused by vanishing/exploding gradient. 
ResNet, which was proposed in 2015 by researchers at Microsoft Research introduced a new architecture called Residual Network. 

Residual Network: In order to solve the problem of the vanishing/exploding gradient, this architecture introduced the concept called Residual Blocks. In this network, we use a technique called skip connections. The skip connection connects activations of a  layer to further layers by skipping some layers in between. This forms a residual block. Resnets are made by stacking these residual blocks together. 
The approach behind this network is instead of layers learning the underlying mapping, we allow the network to fit the residual mapping. So, instead of say H(x), initial mapping, let the network fit, 

F(x) := H(x) - x which gives H(x) := F(x) + x. 

Skip (Shortcut) connection

The advantage of adding this type of skip connection is that if any layer hurt the performance of architecture then it will be skipped by regularization. So, this results in training a very deep neural network without the problems caused by vanishing/exploding gradient.  The authors of the paper experimented on 100-1000 layers of the CIFAR-10 dataset. 
There is a similar approach called “highway networks”, these networks also use skip connection. Similar to LSTM these skip connections also use parametric gates. These gates determine how much information passes through the skip connection. This architecture however has not provided accuracy better than ResNet architecture. 

Network Architecture: This network uses a 34-layer plain network architecture inspired by VGG-19 in which then the shortcut connection is added. These shortcut connections then convert the architecture into a residual network.  

ResNet -34 architecture

Implementation: Using the Tensorflow and Keras API, we can design ResNet architecture (including Residual Blocks) from scratch. Below is the implementation of different ResNet architecture. For this implementation, we use the CIFAR-10 dataset. This dataset contains 60, 000 32×32 color images in 10 different classes (airplanes, cars, birds, cats, deer, dogs, frogs, horses, ships, and trucks), etc. This dataset can be assessed from keras.datasets API function. 

Step 1: First, we import the keras module and its APIs. These APIs help in building the architecture of the ResNet model.

Code: Importing libraries 

# Import Keras modules and its important APIs
import keras
from keras.layers import Dense, Conv2D, BatchNormalization, Activation
from keras.layers import AveragePooling2D, Input, Flatten
from keras.optimizers import Adam
from keras.callbacks import ModelCheckpoint, LearningRateScheduler
from keras.callbacks import ReduceLROnPlateau
from keras.preprocessing.image import ImageDataGenerator
from keras.regularizers import l2
from keras import backend as K
from keras.models import Model
from keras.datasets import cifar10
import numpy as np
import os

Step 2: Now, We set different hyper parameters that are required for ResNet architecture. We also did some preprocessing on our dataset to prepare it for training.

Code: Setting Training Hyperparameters  

python3

# Setting Training Hyperparameters 
batch_size = 32  # original ResNet paper uses batch_size = 128 for training 
epochs = 200
data_augmentation = True
num_classes = 10

# Data Preprocessing  
subtract_pixel_mean = True
n = 3

# Select ResNet Version 
version = 1

# Computed depth of  
if version == 1: 
    depth = n * 6 + 2
elif version == 2: 
    depth = n * 9 + 2

# Model name, depth and version 
model_type = 'ResNet % dv % d' % (depth, version) 

# Load the CIFAR-10 data. 
(x_train, y_train), (x_test, y_test) = cifar10.load_data() 

# Input image dimensions. 
input_shape = x_train.shape[1:] 

# Normalize data. 
x_train = x_train.astype('float32') / 255
x_test = x_test.astype('float32') / 255

# If subtract pixel mean is enabled 
if subtract_pixel_mean: 
    x_train_mean = np.mean(x_train, axis = 0) 
    x_train -= x_train_mean 
    x_test -= x_train_mean 

# Print Training and Test Samples  
print('x_train shape:', x_train.shape) 
print(x_train.shape[0], 'train samples') 
print(x_test.shape[0], 'test samples') 
print('y_train shape:', y_train.shape) 

# Convert class vectors to binary class matrices. 
y_train = keras.utils.to_categorical(y_train, num_classes) 
y_test = keras.utils.to_categorical(y_test, num_classes) 

Step 3: In this step, we set the learning rate according to the number of epochs. As the number of epochs the learning rate must be decreased to ensure better learning.

Code: Setting LR for different numbers of Epochs 

python3

# Setting LR for different number of Epochs 
def lr_schedule(epoch): 
    lr = 1e-3
    if epoch > 180: 
        lr *= 0.5e-3
    elif epoch > 160: 
        lr *= 1e-3
    elif epoch > 120: 
        lr *= 1e-2
    elif epoch > 80: 
        lr *= 1e-1
    print('Learning rate: ', lr) 
    return lr 

Step 4: Define basic ResNet building block that can be used for defining the ResNet V1 and V2 architecture.

Code: Basic ResNet Building Block 

python3

# Basic ResNet Building Block 

def resnet_layer(inputs, 
                 num_filters=16, 
                 kernel_size=3, 
                 strides=1, 
                 activation='relu', 
                 batch_normalization=True, 
    conv=Conv2D(num_filters, 
                  kernel_size=kernel_size, 
                  strides=strides, 
                  padding='same', 
                  kernel_initializer='he_normal', 
                  kernel_regularizer=l2(1e-4)) 

    x=inputs 
    if conv_first: 
        x = conv(x) 
        if batch_normalization: 
            x = BatchNormalization()(x) 
        if activation is not None: 
            x = Activation(activation)(x) 
    else: 
        if batch_normalization: 
            x = BatchNormalization()(x) 
        if activation is not None: 
            x = Activation(activation)(x) 
        x = conv(x) 
    return x 

Step 5: Define ResNet V1 architecture that is based on the ResNet building block we defined above:

Code: ResNet V1 architecture 

python3

def resnet_v1(input_shape, depth, num_classes=10): 

    if (depth - 2) % 6 != 0: 
        raise ValueError('depth should be 6n + 2 (eg 20, 32, 44 in [a])') 
    # Start model definition. 
    num_filters = 16
    num_res_blocks = int((depth - 2) / 6) 

    inputs = Input(shape=input_shape) 
    x = resnet_layer(inputs=inputs) 
    # Instantiate the stack of residual units 
    for stack in range(3): 
        for res_block in range(num_res_blocks): 
            strides = 1
            if stack & gt 
            0 and res_block == 0:  # first layer but not first stack 
                strides = 2  # downsample 
            y = resnet_layer(inputs=x, 
                             num_filters=num_filters, 
                             strides=strides) 
            y = resnet_layer(inputs=y, 
                             num_filters=num_filters, 
                             activation=None) 
            if stack & gt 
            0 and res_block == 0:  # first layer but not first stack 
                # linear projection residual shortcut connection to match 
                # changed dims 
                x = resnet_layer(inputs=x, 
                                 num_filters=num_filters, 
                                 kernel_size=1, 
                                 strides=strides, 
                                 activation=None, 
                                 batch_normalization=False) 
            x = keras.layers.add([x, y]) 
            x = Activation('relu')(x) 
        num_filters *= 2

    # Add classifier on top. 
    # v1 does not use BN after last shortcut connection-ReLU 
    x = AveragePooling2D(pool_size=8)(x) 
    y = Flatten()(x) 
    outputs = Dense(num_classes, 
                    activation='softmax', 
                    kernel_initializer='he_normal')(y) 

    # Instantiate model. 
    model = Model(inputs=inputs, outputs=outputs) 
    return model 

Step 6: Define ResNet V2 architecture that is based on the ResNet building block we defined above:

Code: ResNet V2 architecture 

python3

# ResNet V2 architecture 
def resnet_v2(input_shape, depth, num_classes=10): 
    if (depth - 2) % 9 != 0: 
        raise ValueError('depth should be 9n + 2 (eg 56 or 110 in [b])') 
    # Start model definition. 
    num_filters_in = 16
    num_res_blocks = int((depth - 2) / 9) 

    inputs = Input(shape=input_shape) 
    # v2 performs Conv2D with BN-ReLU on input before splitting into 2 paths 
    x = resnet_layer(inputs=inputs, 
                     num_filters=num_filters_in, 
                     conv_first=True) 

    # Instantiate the stack of residual units 
    for stage in range(3): 
        for res_block in range(num_res_blocks): 
            activation = 'relu'
            batch_normalization = True
            strides = 1
            if stage == 0: 
                num_filters_out = num_filters_in * 4
                if res_block == 0:  # first layer and first stage 
                    activation = None
                    batch_normalization = False
            else: 
                num_filters_out = num_filters_in * 2
                if res_block == 0:  # first layer but not first stage 
                    strides = 2    # downsample 

            # bottleneck residual unit 
            y = resnet_layer(inputs=x, 
                             num_filters=num_filters_in, 
                             kernel_size=1, 
                             strides=strides, 
                             activation=activation, 
                             batch_normalization=batch_normalization, 
                             conv_first=False) 
            y = resnet_layer(inputs=y, 
                             num_filters=num_filters_in, 
                             conv_first=False) 
            y = resnet_layer(inputs=y, 
                             num_filters=num_filters_out, 
                             kernel_size=1, 
                             conv_first=False) 
            if res_block == 0: 
                # linear projection residual shortcut connection to match 
                # changed dims 
                x = resnet_layer(inputs=x, 
                                 num_filters=num_filters_out, 
                                 kernel_size=1, 
                                 strides=strides, 
                                 activation=None, 
                                 batch_normalization=False) 
            x = keras.layers.add([x, y]) 

        num_filters_in = num_filters_out 

    # Add classifier on top. 
    # v2 has BN-ReLU before Pooling 
    x = BatchNormalization()(x) 
    x = Activation('relu')(x) 
    x = AveragePooling2D(pool_size=8)(x) 
    y = Flatten()(x) 
    outputs = Dense(num_classes, 
                    activation='softmax', 
                    kernel_initializer='he_normal')(y) 

    # Instantiate model. 
    model = Model(inputs=inputs, outputs=outputs) 
    return model 

Step 7: The code below is used to train and test the ResNet v1 and v2 architecture we defined above:

Code: Main function 

python3

# Main function  
if version == 2: 
    model = resnet_v2(input_shape = input_shape, depth = depth) 
else: 
    model = resnet_v1(input_shape = input_shape, depth = depth) 

model.compile(loss ='categorical_crossentropy', 
              optimizer = Adam(learning_rate = lr_schedule(0)), 
              metrics =['accuracy']) 
model.summary() 
print(model_type) 

# Prepare model saving directory. 
save_dir = os.path.join(os.getcwd(), 'saved_models') 
model_name = 'cifar10_% s_model.{epoch:03d}.h5' % model_type 
if not os.path.isdir(save_dir): 
    os.makedirs(save_dir) 
filepath = os.path.join(save_dir, model_name) 

# Prepare callbacks for model saving and for learning rate adjustment. 
checkpoint = ModelCheckpoint(filepath = filepath, 
                             monitor ='val_acc', 
                             verbose = 1, 
                             save_best_only = True) 

lr_scheduler = LearningRateScheduler(lr_schedule) 

lr_reducer = ReduceLROnPlateau(factor = np.sqrt(0.1), 
                               cooldown = 0, 
                               patience = 5, 
                               min_lr = 0.5e-6) 

callbacks = [checkpoint, lr_reducer, lr_scheduler] 

# Run training, with or without data augmentation. 
if not data_augmentation: 
    print('Not using data augmentation.') 
    model.fit(x_train, y_train, 
              batch_size = batch_size, 
              epochs = epochs, 
              validation_data =(x_test, y_test), 
              shuffle = True, 
              callbacks = callbacks) 
else: 
    print('Using real-time data augmentation.') 
    # This will do preprocessing and realtime data augmentation: 
    datagen = ImageDataGenerator( 
        # set input mean to 0 over the dataset 
        featurewise_center = False, 
        # set each sample mean to 0 
        samplewise_center = False, 
        # divide inputs by std of dataset 
        featurewise_std_normalization = False, 
        # divide each input by its std 
        samplewise_std_normalization = False, 
        # apply ZCA whitening 
        zca_whitening = False, 
        # epsilon for ZCA whitening 
        zca_epsilon = 1e-06, 
        # randomly rotate images in the range (deg 0 to 180) 
        rotation_range = 0, 
        # randomly shift images horizontally 
        width_shift_range = 0.1, 
        # randomly shift images vertically 
        height_shift_range = 0.1, 
        # set range for random shear 
        shear_range = 0., 
        # set range for random zoom 
        zoom_range = 0., 
        # set range for random channel shifts 
        channel_shift_range = 0., 
        # set mode for filling points outside the input boundaries 
        fill_mode ='nearest', 
        # value used for fill_mode = "constant" 
        cval = 0., 
        # randomly flip images 
        horizontal_flip = True, 
        # randomly flip images 
        vertical_flip = False, 
        # set rescaling factor (applied before any other transformation) 
        rescale = None, 
        # set function that will be applied on each input 
        preprocessing_function = None, 
        # image data format, either "channels_first" or "channels_last" 
        data_format = None, 
        # fraction of images reserved for validation (strictly between 0 and 1) 
        validation_split = 0.0) 

    # Compute quantities required for featurewise normalization 
    # (std, mean, and principal components if ZCA whitening is applied). 
    datagen.fit(x_train) 

    # Fit the model on the batches generated by datagen.flow(). 
    model.fit_generator(datagen.flow(x_train, y_train, batch_size = batch_size), 
                        validation_data =(x_test, y_test), 
                        epochs = epochs, verbose = 1, workers = 4, 
                        callbacks = callbacks) 

# Score trained model. 
scores = model.evaluate(x_test, y_test, verbose = 1) 
print('Test loss:', scores[0]) 
print('Test accuracy:', scores[1])

Results & Conclusion: 
On the ImageNet dataset,  the authors uses a 152-layers ResNet, which is 8 times more deep than VGG19 but still have less parameters. An ensemble of these ResNets generated an error of only 3.7% on ImageNet test set, the result which won ILSVRC 2015 competition. On COCO object detection dataset, it also generates a 28% relative improvement due to its very deep representation. 

Error-rate on ResNet Architecture

The result above shows that shortcut connections would be able to solve the problem caused by increasing the layers because as we increase layers from 18 to 34 the error rate on ImageNet Validation Set also decreases unlike the plain network.

top-1 and top-5 Error rate on ImageNet Validation Set.

Below are the results on ImageNet Test Set. The 3.57% top-5 error rate of ResNet was the lowest and thus ResNet architecture came first in ImageNet classification challenge in 2015.

Are you passionate about data and looking to make one giant leap into your career? Our Data Science Course will help you change your game and, most importantly, allow students, professionals, and working adults to tide over into the data science immersion. Master state-of-the-art methodologies, powerful tools, and industry best practices, hands-on projects, and real-world applications. Become the executive head of industries related to Data Analysis, Machine Learning, and Data Visualization with these growing skills. Ready to Transform Your Future? Enroll Now to Be a Data Science Expert!

P

pawangfg
12
Previous Article
Detect and Recognize Car License Plate from a video in real time
Next Article
Twitter Sentiment Analysis using Python
Read More
Video | Residual Networks (ResNet) - Deep Learning
Similar Reads
Introduction to Residual Networks
Recent years have seen tremendous progress in the field of Image Processing and Recognition. Deep Neural Networks are becoming deeper and more complex. It has been proved that adding more layers to a Neural Network can make it more robust for image-related tasks. But it can also cause them to lose accuracy. That's where Residual Networks come into
3 min read
Deep Belief Network (DBN) in Deep Learning
Discover data creation with Deep Belief Networks (DBNs), cutting-edge generative models that make use of deep architecture. This article walks you through the concepts of DBNs, how they work, and how to implement them using practical coding. What is a Deep Belief Network?Deep Belief Networks (DBNs) are sophisticated artificial neural networks used
9 min read
Deep Boltzmann Machines (DBMs) in Deep Learning
In this article, we will discuss the Deep Boltzmann Machines concepts and their applications in the real-world scenario. What are Deep Boltzmann Machines (DBMs)?Deep Boltzmann Machines (DBMs) are a kind of artificial neural network that belongs to the family of generative models. They are designed to discover intricate structures within large datas
10 min read
Unveiling the Power of Fastai: A Deep Dive into the Versatile Deep Learning Library
Fastai is a powerful deep-learning library designed for researchers and practitioners. It offers high-level abstractions, PyTorch integration, and application-specific APIs, making it both adaptable and accessible for a wide range of deep learning tasks. In this article, we'll delve into the intricacies of Fastai, a powerful deep-learning library.
9 min read
Spiking Neural Networks in Deep Learning
Spiking Neural Networks (SNNs) represent a novel approach in artificial neural networks, inspired by the biological processes of the human brain. Unlike traditional artificial neural networks (ANNs) that rely on continuous signal processing, SNNs operate on discrete events called "spikes." The aim of this article is to provide an in-depth understan
10 min read
Introduction to Multi-Task Learning(MTL) for Deep Learning
Multi-Task Learning (MTL) is a type of machine learning technique where a model is trained to perform multiple tasks simultaneously. In deep learning, MTL refers to training a neural network to perform multiple tasks by sharing some of the network's layers and parameters across tasks. In MTL, the goal is to improve the generalization performance of
6 min read
Artificial intelligence vs Machine Learning vs Deep Learning
Nowadays many misconceptions are there related to the words machine learning, deep learning, and artificial intelligence (AI), most people think all these things are the same whenever they hear the word AI, they directly relate that word to machine learning or vice versa, well yes, these things are related to each other but not the same. Let's see
4 min read
Need of Data Structures and Algorithms for Deep Learning and Machine Learning
Deep Learning is a field that is heavily based on Mathematics and you need to have a good understanding of Data Structures and Algorithms to solve the mathematical problems optimally. Data Structures and Algorithms can be used to determine how a problem is represented internally or how the actual storage pattern works &amp; what is happening under
6 min read
Difference Between Artificial Intelligence vs Machine Learning vs Deep Learning
Artificial Intelligence is basically the mechanism to incorporate human intelligence into machines through a set of rules(algorithm). AI is a combination of two words: "Artificial" meaning something made by humans or non-natural things and "Intelligence" meaning the ability to understand or think accordingly. Another definition could be that "AI is
14 min read
Difference Between Machine Learning and Deep Learning
If you are interested in building your career in the IT industry then you must have come across the term Data Science which is a booming field in terms of technologies and job availability as well. In this article, we will explore the Difference between Machine Learning and Deep Learning, two major fields within Data Science. Understanding these di
8 min read
Article Tags :
AI-ML-DS
Deep Learning
Machine Learning
AI-ML-DS With Python
+1 More
Practice Tags :
Machine Learning
python

Residual Networks (ResNet) – Deep Learning
Last Updated : 10 Jan, 2023
Generative Summary
Now you can generate the summary of any article of your choice.
Got it

After the first CNN-based architecture (AlexNet) that win the ImageNet 2012 competition, Every subsequent winning architecture uses more layers in a deep neural network to reduce the error rate. This works for less number of layers, but when we increase the number of layers, there is a common problem in deep learning associated with that called the Vanishing/Exploding gradient. This causes the gradient to become 0 or too large. Thus when we increases number of layers, the training and test error rate also increases. 

Comparison of 20-layer vs 56-layer architecture

In the above plot, we can observe that a 56-layer CNN gives more error rate on both training and testing dataset than a 20-layer CNN architecture. After analyzing more on error rate the authors were able to reach conclusion that it is caused by vanishing/exploding gradient. 
ResNet, which was proposed in 2015 by researchers at Microsoft Research introduced a new architecture called Residual Network. 

Residual Network: In order to solve the problem of the vanishing/exploding gradient, this architecture introduced the concept called Residual Blocks. In this network, we use a technique called skip connections. The skip connection connects activations of a  layer to further layers by skipping some layers in between. This forms a residual block. Resnets are made by stacking these residual blocks together. 
The approach behind this network is instead of layers learning the underlying mapping, we allow the network to fit the residual mapping. So, instead of say H(x), initial mapping, let the network fit, 

F(x) := H(x) - x which gives H(x) := F(x) + x. 

Skip (Shortcut) connection

The advantage of adding this type of skip connection is that if any layer hurt the performance of architecture then it will be skipped by regularization. So, this results in training a very deep neural network without the problems caused by vanishing/exploding gradient.  The authors of the paper experimented on 100-1000 layers of the CIFAR-10 dataset. 
There is a similar approach called “highway networks”, these networks also use skip connection. Similar to LSTM these skip connections also use parametric gates. These gates determine how much information passes through the skip connection. This architecture however has not provided accuracy better than ResNet architecture. 

Network Architecture: This network uses a 34-layer plain network architecture inspired by VGG-19 in which then the shortcut connection is added. These shortcut connections then convert the architecture into a residual network.  

ResNet -34 architecture

Implementation: Using the Tensorflow and Keras API, we can design ResNet architecture (including Residual Blocks) from scratch. Below is the implementation of different ResNet architecture. For this implementation, we use the CIFAR-10 dataset. This dataset contains 60, 000 32×32 color images in 10 different classes (airplanes, cars, birds, cats, deer, dogs, frogs, horses, ships, and trucks), etc. This dataset can be assessed from keras.datasets API function. 

Step 1: First, we import the keras module and its APIs. These APIs help in building the architecture of the ResNet model.

Code: Importing libraries 

# Import Keras modules and its important APIs
import keras
from keras.layers import Dense, Conv2D, BatchNormalization, Activation
from keras.layers import AveragePooling2D, Input, Flatten
from keras.optimizers import Adam
from keras.callbacks import ModelCheckpoint, LearningRateScheduler
from keras.callbacks import ReduceLROnPlateau
from keras.preprocessing.image import ImageDataGenerator
from keras.regularizers import l2
from keras import backend as K
from keras.models import Model
from keras.datasets import cifar10
import numpy as np
import os

Step 2: Now, We set different hyper parameters that are required for ResNet architecture. We also did some preprocessing on our dataset to prepare it for training.

Code: Setting Training Hyperparameters  

python3

# Setting Training Hyperparameters 
batch_size = 32  # original ResNet paper uses batch_size = 128 for training 
epochs = 200
data_augmentation = True
num_classes = 10

# Data Preprocessing  
subtract_pixel_mean = True
n = 3

# Select ResNet Version 
version = 1

# Computed depth of  
if version == 1: 
    depth = n * 6 + 2
elif version == 2: 
    depth = n * 9 + 2

# Model name, depth and version 
model_type = 'ResNet % dv % d' % (depth, version) 

# Load the CIFAR-10 data. 
(x_train, y_train), (x_test, y_test) = cifar10.load_data() 

# Input image dimensions. 
input_shape = x_train.shape[1:] 

# Normalize data. 
x_train = x_train.astype('float32') / 255
x_test = x_test.astype('float32') / 255

# If subtract pixel mean is enabled 
if subtract_pixel_mean: 
    x_train_mean = np.mean(x_train, axis = 0) 
    x_train -= x_train_mean 
    x_test -= x_train_mean 

# Print Training and Test Samples  
print('x_train shape:', x_train.shape) 
print(x_train.shape[0], 'train samples') 
print(x_test.shape[0], 'test samples') 
print('y_train shape:', y_train.shape) 

# Convert class vectors to binary class matrices. 
y_train = keras.utils.to_categorical(y_train, num_classes) 
y_test = keras.utils.to_categorical(y_test, num_classes) 

Step 3: In this step, we set the learning rate according to the number of epochs. As the number of epochs the learning rate must be decreased to ensure better learning.

Code: Setting LR for different numbers of Epochs 

python3

# Setting LR for different number of Epochs 
def lr_schedule(epoch): 
    lr = 1e-3
    if epoch > 180: 
        lr *= 0.5e-3
    elif epoch > 160: 
        lr *= 1e-3
    elif epoch > 120: 
        lr *= 1e-2
    elif epoch > 80: 
        lr *= 1e-1
    print('Learning rate: ', lr) 
    return lr 

Step 4: Define basic ResNet building block that can be used for defining the ResNet V1 and V2 architecture.

Code: Basic ResNet Building Block 

python3

# Basic ResNet Building Block 

def resnet_layer(inputs, 
                 num_filters=16, 
                 kernel_size=3, 
                 strides=1, 
                 activation='relu', 
                 batch_normalization=True, 
    conv=Conv2D(num_filters, 
                  kernel_size=kernel_size, 
                  strides=strides, 
                  padding='same', 
                  kernel_initializer='he_normal', 
                  kernel_regularizer=l2(1e-4)) 

    x=inputs 
    if conv_first: 
        x = conv(x) 
        if batch_normalization: 
            x = BatchNormalization()(x) 
        if activation is not None: 
            x = Activation(activation)(x) 
    else: 
        if batch_normalization: 
            x = BatchNormalization()(x) 
        if activation is not None: 
            x = Activation(activation)(x) 
        x = conv(x) 
    return x 

Step 5: Define ResNet V1 architecture that is based on the ResNet building block we defined above:

Code: ResNet V1 architecture 

python3

def resnet_v1(input_shape, depth, num_classes=10): 

    if (depth - 2) % 6 != 0: 
        raise ValueError('depth should be 6n + 2 (eg 20, 32, 44 in [a])') 
    # Start model definition. 
    num_filters = 16
    num_res_blocks = int((depth - 2) / 6) 

    inputs = Input(shape=input_shape) 
    x = resnet_layer(inputs=inputs) 
    # Instantiate the stack of residual units 
    for stack in range(3): 
        for res_block in range(num_res_blocks): 
            strides = 1
            if stack & gt 
            0 and res_block == 0:  # first layer but not first stack 
                strides = 2  # downsample 
            y = resnet_layer(inputs=x, 
                             num_filters=num_filters, 
                             strides=strides) 
            y = resnet_layer(inputs=y, 
                             num_filters=num_filters, 
                             activation=None) 
            if stack & gt 
            0 and res_block == 0:  # first layer but not first stack 
                # linear projection residual shortcut connection to match 
                # changed dims 
                x = resnet_layer(inputs=x, 
                                 num_filters=num_filters, 
                                 kernel_size=1, 
                                 strides=strides, 
                                 activation=None, 
                                 batch_normalization=False) 
            x = keras.layers.add([x, y]) 
            x = Activation('relu')(x) 
        num_filters *= 2

    # Add classifier on top. 
    # v1 does not use BN after last shortcut connection-ReLU 
    x = AveragePooling2D(pool_size=8)(x) 
    y = Flatten()(x) 
    outputs = Dense(num_classes, 
                    activation='softmax', 
                    kernel_initializer='he_normal')(y) 

    # Instantiate model. 
    model = Model(inputs=inputs, outputs=outputs) 
    return model 

Step 6: Define ResNet V2 architecture that is based on the ResNet building block we defined above:

Code: ResNet V2 architecture 

python3

# ResNet V2 architecture 
def resnet_v2(input_shape, depth, num_classes=10): 
    if (depth - 2) % 9 != 0: 
        raise ValueError('depth should be 9n + 2 (eg 56 or 110 in [b])') 
    # Start model definition. 
    num_filters_in = 16
    num_res_blocks = int((depth - 2) / 9) 

    inputs = Input(shape=input_shape) 
    # v2 performs Conv2D with BN-ReLU on input before splitting into 2 paths 
    x = resnet_layer(inputs=inputs, 
                     num_filters=num_filters_in, 
                     conv_first=True) 

    # Instantiate the stack of residual units 
    for stage in range(3): 
        for res_block in range(num_res_blocks): 
            activation = 'relu'
            batch_normalization = True
            strides = 1
            if stage == 0: 
                num_filters_out = num_filters_in * 4
                if res_block == 0:  # first layer and first stage 
                    activation = None
                    batch_normalization = False
            else: 
                num_filters_out = num_filters_in * 2
                if res_block == 0:  # first layer but not first stage 
                    strides = 2    # downsample 

            # bottleneck residual unit 
            y = resnet_layer(inputs=x, 
                             num_filters=num_filters_in, 
                             kernel_size=1, 
                             strides=strides, 
                             activation=activation, 
                             batch_normalization=batch_normalization, 
                             conv_first=False) 
            y = resnet_layer(inputs=y, 
                             num_filters=num_filters_in, 
                             conv_first=False) 
            y = resnet_layer(inputs=y, 
                             num_filters=num_filters_out, 
                             kernel_size=1, 
                             conv_first=False) 
            if res_block == 0: 
                # linear projection residual shortcut connection to match 
                # changed dims 
                x = resnet_layer(inputs=x, 
                                 num_filters=num_filters_out, 
                                 kernel_size=1, 
                                 strides=strides, 
                                 activation=None, 
                                 batch_normalization=False) 
            x = keras.layers.add([x, y]) 

        num_filters_in = num_filters_out 

    # Add classifier on top. 
    # v2 has BN-ReLU before Pooling 
    x = BatchNormalization()(x) 
    x = Activation('relu')(x) 
    x = AveragePooling2D(pool_size=8)(x) 
    y = Flatten()(x) 
    outputs = Dense(num_classes, 
                    activation='softmax', 
                    kernel_initializer='he_normal')(y) 

    # Instantiate model. 
    model = Model(inputs=inputs, outputs=outputs) 
    return model 

Step 7: The code below is used to train and test the ResNet v1 and v2 architecture we defined above:

Code: Main function 

python3

# Main function  
if version == 2: 
    model = resnet_v2(input_shape = input_shape, depth = depth) 
else: 
    model = resnet_v1(input_shape = input_shape, depth = depth) 

model.compile(loss ='categorical_crossentropy', 
              optimizer = Adam(learning_rate = lr_schedule(0)), 
              metrics =['accuracy']) 
model.summary() 
print(model_type) 

# Prepare model saving directory. 
save_dir = os.path.join(os.getcwd(), 'saved_models') 
model_name = 'cifar10_% s_model.{epoch:03d}.h5' % model_type 
if not os.path.isdir(save_dir): 
    os.makedirs(save_dir) 
filepath = os.path.join(save_dir, model_name) 

# Prepare callbacks for model saving and for learning rate adjustment. 
checkpoint = ModelCheckpoint(filepath = filepath, 
                             monitor ='val_acc', 
                             verbose = 1, 
                             save_best_only = True) 

lr_scheduler = LearningRateScheduler(lr_schedule) 

lr_reducer = ReduceLROnPlateau(factor = np.sqrt(0.1), 
                               cooldown = 0, 
                               patience = 5, 
                               min_lr = 0.5e-6) 

callbacks = [checkpoint, lr_reducer, lr_scheduler] 

# Run training, with or without data augmentation. 
if not data_augmentation: 
    print('Not using data augmentation.') 
    model.fit(x_train, y_train, 
              batch_size = batch_size, 
              epochs = epochs, 
              validation_data =(x_test, y_test), 
              shuffle = True, 
              callbacks = callbacks) 
else: 
    print('Using real-time data augmentation.') 
    # This will do preprocessing and realtime data augmentation: 
    datagen = ImageDataGenerator( 
        # set input mean to 0 over the dataset 
        featurewise_center = False, 
        # set each sample mean to 0 
        samplewise_center = False, 
        # divide inputs by std of dataset 
        featurewise_std_normalization = False, 
        # divide each input by its std 
        samplewise_std_normalization = False, 
        # apply ZCA whitening 
        zca_whitening = False, 
        # epsilon for ZCA whitening 
        zca_epsilon = 1e-06, 
        # randomly rotate images in the range (deg 0 to 180) 
        rotation_range = 0, 
        # randomly shift images horizontally 
        width_shift_range = 0.1, 
        # randomly shift images vertically 
        height_shift_range = 0.1, 
        # set range for random shear 
        shear_range = 0., 
        # set range for random zoom 
        zoom_range = 0., 
        # set range for random channel shifts 
        channel_shift_range = 0., 
        # set mode for filling points outside the input boundaries 
        fill_mode ='nearest', 
        # value used for fill_mode = "constant" 
        cval = 0., 
        # randomly flip images 
        horizontal_flip = True, 
        # randomly flip images 
        vertical_flip = False, 
        # set rescaling factor (applied before any other transformation) 
        rescale = None, 
        # set function that will be applied on each input 
        preprocessing_function = None, 
        # image data format, either "channels_first" or "channels_last" 
        data_format = None, 
        # fraction of images reserved for validation (strictly between 0 and 1) 
        validation_split = 0.0) 

    # Compute quantities required for featurewise normalization 
    # (std, mean, and principal components if ZCA whitening is applied). 
    datagen.fit(x_train) 

    # Fit the model on the batches generated by datagen.flow(). 
    model.fit_generator(datagen.flow(x_train, y_train, batch_size = batch_size), 
                        validation_data =(x_test, y_test), 
                        epochs = epochs, verbose = 1, workers = 4, 
                        callbacks = callbacks) 

# Score trained model. 
scores = model.evaluate(x_test, y_test, verbose = 1) 
print('Test loss:', scores[0]) 
print('Test accuracy:', scores[1])

Results & Conclusion: 
On the ImageNet dataset,  the authors uses a 152-layers ResNet, which is 8 times more deep than VGG19 but still have less parameters. An ensemble of these ResNets generated an error of only 3.7% on ImageNet test set, the result which won ILSVRC 2015 competition. On COCO object detection dataset, it also generates a 28% relative improvement due to its very deep representation. 

Error-rate on ResNet Architecture

The result above shows that shortcut connections would be able to solve the problem caused by increasing the layers because as we increase layers from 18 to 34 the error rate on ImageNet Validation Set also decreases unlike the plain network.

top-1 and top-5 Error rate on ImageNet Validation Set.

Below are the results on ImageNet Test Set. The 3.57% top-5 error rate of ResNet was the lowest and thus ResNet architecture came first in ImageNet classification challenge in 2015.

Are you passionate about data and looking to make one giant leap into your career? Our Data Science Course will help you change your game and, most importantly, allow students, professionals, and working adults to tide over into the data science immersion. Master state-of-the-art methodologies, powerful tools, and industry best practices, hands-on projects, and real-world applications. Become the executive head of industries related to Data Analysis, Machine Learning, and Data Visualization with these growing skills. Ready to Transform Your Future? Enroll Now to Be a Data Science Expert!

P

pawangfg
12
Previous Article
Detect and Recognize Car License Plate from a video in real time
Next Article
Twitter Sentiment Analysis using Python
Read More
Video | Residual Networks (ResNet) - Deep Learning
Similar Reads
Introduction to Residual Networks
Recent years have seen tremendous progress in the field of Image Processing and Recognition. Deep Neural Networks are becoming deeper and more complex. It has been proved that adding more layers to a Neural Network can make it more robust for image-related tasks. But it can also cause them to lose accuracy. That's where Residual Networks come into
3 min read
Deep Belief Network (DBN) in Deep Learning
Discover data creation with Deep Belief Networks (DBNs), cutting-edge generative models that make use of deep architecture. This article walks you through the concepts of DBNs, how they work, and how to implement them using practical coding. What is a Deep Belief Network?Deep Belief Networks (DBNs) are sophisticated artificial neural networks used
9 min read
Deep Boltzmann Machines (DBMs) in Deep Learning
In this article, we will discuss the Deep Boltzmann Machines concepts and their applications in the real-world scenario. What are Deep Boltzmann Machines (DBMs)?Deep Boltzmann Machines (DBMs) are a kind of artificial neural network that belongs to the family of generative models. They are designed to discover intricate structures within large datas
10 min read
Unveiling the Power of Fastai: A Deep Dive into the Versatile Deep Learning Library
Fastai is a powerful deep-learning library designed for researchers and practitioners. It offers high-level abstractions, PyTorch integration, and application-specific APIs, making it both adaptable and accessible for a wide range of deep learning tasks. In this article, we'll delve into the intricacies of Fastai, a powerful deep-learning library.
9 min read
Spiking Neural Networks in Deep Learning
Spiking Neural Networks (SNNs) represent a novel approach in artificial neural networks, inspired by the biological processes of the human brain. Unlike traditional artificial neural networks (ANNs) that rely on continuous signal processing, SNNs operate on discrete events called "spikes." The aim of this article is to provide an in-depth understan
10 min read
Introduction to Multi-Task Learning(MTL) for Deep Learning
Multi-Task Learning (MTL) is a type of machine learning technique where a model is trained to perform multiple tasks simultaneously. In deep learning, MTL refers to training a neural network to perform multiple tasks by sharing some of the network's layers and parameters across tasks. In MTL, the goal is to improve the generalization performance of
6 min read
Artificial intelligence vs Machine Learning vs Deep Learning
Nowadays many misconceptions are there related to the words machine learning, deep learning, and artificial intelligence (AI), most people think all these things are the same whenever they hear the word AI, they directly relate that word to machine learning or vice versa, well yes, these things are related to each other but not the same. Let's see
4 min read
Need of Data Structures and Algorithms for Deep Learning and Machine Learning
Deep Learning is a field that is heavily based on Mathematics and you need to have a good understanding of Data Structures and Algorithms to solve the mathematical problems optimally. Data Structures and Algorithms can be used to determine how a problem is represented internally or how the actual storage pattern works &amp; what is happening under
6 min read
Difference Between Artificial Intelligence vs Machine Learning vs Deep Learning
Artificial Intelligence is basically the mechanism to incorporate human intelligence into machines through a set of rules(algorithm). AI is a combination of two words: "Artificial" meaning something made by humans or non-natural things and "Intelligence" meaning the ability to understand or think accordingly. Another definition could be that "AI is
14 min read
Difference Between Machine Learning and Deep Learning
If you are interested in building your career in the IT industry then you must have come across the term Data Science which is a booming field in terms of technologies and job availability as well. In this article, we will explore the Difference between Machine Learning and Deep Learning, two major fields within Data Science. Understanding these di
8 min read
Article Tags :
AI-ML-DS
Deep Learning
Machine Learning
AI-ML-DS With Python
+1 More
Practice Tags :
Machine Learning
python

Residual Networks (ResNet) – Deep Learning
Last Updated : 10 Jan, 2023
Generative Summary
Now you can generate the summary of any article of your choice.
Got it

After the first CNN-based architecture (AlexNet) that win the ImageNet 2012 competition, Every subsequent winning architecture uses more layers in a deep neural network to reduce the error rate. This works for less number of layers, but when we increase the number of layers, there is a common problem in deep learning associated with that called the Vanishing/Exploding gradient. This causes the gradient to become 0 or too large. Thus when we increases number of layers, the training and test error rate also increases. 

Comparison of 20-layer vs 56-layer architecture

In the above plot, we can observe that a 56-layer CNN gives more error rate on both training and testing dataset than a 20-layer CNN architecture. After analyzing more on error rate the authors were able to reach conclusion that it is caused by vanishing/exploding gradient. 
ResNet, which was proposed in 2015 by researchers at Microsoft Research introduced a new architecture called Residual Network. 

Residual Network: In order to solve the problem of the vanishing/exploding gradient, this architecture introduced the concept called Residual Blocks. In this network, we use a technique called skip connections. The skip connection connects activations of a  layer to further layers by skipping some layers in between. This forms a residual block. Resnets are made by stacking these residual blocks together. 
The approach behind this network is instead of layers learning the underlying mapping, we allow the network to fit the residual mapping. So, instead of say H(x), initial mapping, let the network fit, 

F(x) := H(x) - x which gives H(x) := F(x) + x. 

Skip (Shortcut) connection

The advantage of adding this type of skip connection is that if any layer hurt the performance of architecture then it will be skipped by regularization. So, this results in training a very deep neural network without the problems caused by vanishing/exploding gradient.  The authors of the paper experimented on 100-1000 layers of the CIFAR-10 dataset. 
There is a similar approach called “highway networks”, these networks also use skip connection. Similar to LSTM these skip connections also use parametric gates. These gates determine how much information passes through the skip connection. This architecture however has not provided accuracy better than ResNet architecture. 

Network Architecture: This network uses a 34-layer plain network architecture inspired by VGG-19 in which then the shortcut connection is added. These shortcut connections then convert the architecture into a residual network.  

ResNet -34 architecture

Implementation: Using the Tensorflow and Keras API, we can design ResNet architecture (including Residual Blocks) from scratch. Below is the implementation of different ResNet architecture. For this implementation, we use the CIFAR-10 dataset. This dataset contains 60, 000 32×32 color images in 10 different classes (airplanes, cars, birds, cats, deer, dogs, frogs, horses, ships, and trucks), etc. This dataset can be assessed from keras.datasets API function. 

Step 1: First, we import the keras module and its APIs. These APIs help in building the architecture of the ResNet model.

Code: Importing libraries 

# Import Keras modules and its important APIs
import keras
from keras.layers import Dense, Conv2D, BatchNormalization, Activation
from keras.layers import AveragePooling2D, Input, Flatten
from keras.optimizers import Adam
from keras.callbacks import ModelCheckpoint, LearningRateScheduler
from keras.callbacks import ReduceLROnPlateau
from keras.preprocessing.image import ImageDataGenerator
from keras.regularizers import l2
from keras import backend as K
from keras.models import Model
from keras.datasets import cifar10
import numpy as np
import os

Step 2: Now, We set different hyper parameters that are required for ResNet architecture. We also did some preprocessing on our dataset to prepare it for training.

Code: Setting Training Hyperparameters  

python3

# Setting Training Hyperparameters 
batch_size = 32  # original ResNet paper uses batch_size = 128 for training 
epochs = 200
data_augmentation = True
num_classes = 10

# Data Preprocessing  
subtract_pixel_mean = True
n = 3

# Select ResNet Version 
version = 1

# Computed depth of  
if version == 1: 
    depth = n * 6 + 2
elif version == 2: 
    depth = n * 9 + 2

# Model name, depth and version 
model_type = 'ResNet % dv % d' % (depth, version) 

# Load the CIFAR-10 data. 
(x_train, y_train), (x_test, y_test) = cifar10.load_data() 

# Input image dimensions. 
input_shape = x_train.shape[1:] 

# Normalize data. 
x_train = x_train.astype('float32') / 255
x_test = x_test.astype('float32') / 255

# If subtract pixel mean is enabled 
if subtract_pixel_mean: 
    x_train_mean = np.mean(x_train, axis = 0) 
    x_train -= x_train_mean 
    x_test -= x_train_mean 

# Print Training and Test Samples  
print('x_train shape:', x_train.shape) 
print(x_train.shape[0], 'train samples') 
print(x_test.shape[0], 'test samples') 
print('y_train shape:', y_train.shape) 

# Convert class vectors to binary class matrices. 
y_train = keras.utils.to_categorical(y_train, num_classes) 
y_test = keras.utils.to_categorical(y_test, num_classes) 

Step 3: In this step, we set the learning rate according to the number of epochs. As the number of epochs the learning rate must be decreased to ensure better learning.

Code: Setting LR for different numbers of Epochs 

python3

# Setting LR for different number of Epochs 
def lr_schedule(epoch): 
    lr = 1e-3
    if epoch > 180: 
        lr *= 0.5e-3
    elif epoch > 160: 
        lr *= 1e-3
    elif epoch > 120: 
        lr *= 1e-2
    elif epoch > 80: 
        lr *= 1e-1
    print('Learning rate: ', lr) 
    return lr 

Step 4: Define basic ResNet building block that can be used for defining the ResNet V1 and V2 architecture.

Code: Basic ResNet Building Block 

python3

# Basic ResNet Building Block 

def resnet_layer(inputs, 
                 num_filters=16, 
                 kernel_size=3, 
                 strides=1, 
                 activation='relu', 
                 batch_normalization=True, 
    conv=Conv2D(num_filters, 
                  kernel_size=kernel_size, 
                  strides=strides, 
                  padding='same', 
                  kernel_initializer='he_normal', 
                  kernel_regularizer=l2(1e-4)) 

    x=inputs 
    if conv_first: 
        x = conv(x) 
        if batch_normalization: 
            x = BatchNormalization()(x) 
        if activation is not None: 
            x = Activation(activation)(x) 
    else: 
        if batch_normalization: 
            x = BatchNormalization()(x) 
        if activation is not None: 
            x = Activation(activation)(x) 
        x = conv(x) 
    return x 

Step 5: Define ResNet V1 architecture that is based on the ResNet building block we defined above:

Code: ResNet V1 architecture 

python3

def resnet_v1(input_shape, depth, num_classes=10): 

    if (depth - 2) % 6 != 0: 
        raise ValueError('depth should be 6n + 2 (eg 20, 32, 44 in [a])') 
    # Start model definition. 
    num_filters = 16
    num_res_blocks = int((depth - 2) / 6) 

    inputs = Input(shape=input_shape) 
    x = resnet_layer(inputs=inputs) 
    # Instantiate the stack of residual units 
    for stack in range(3): 
        for res_block in range(num_res_blocks): 
            strides = 1
            if stack & gt 
            0 and res_block == 0:  # first layer but not first stack 
                strides = 2  # downsample 
            y = resnet_layer(inputs=x, 
                             num_filters=num_filters, 
                             strides=strides) 
            y = resnet_layer(inputs=y, 
                             num_filters=num_filters, 
                             activation=None) 
            if stack & gt 
            0 and res_block == 0:  # first layer but not first stack 
                # linear projection residual shortcut connection to match 
                # changed dims 
                x = resnet_layer(inputs=x, 
                                 num_filters=num_filters, 
                                 kernel_size=1, 
                                 strides=strides, 
                                 activation=None, 
                                 batch_normalization=False) 
            x = keras.layers.add([x, y]) 
            x = Activation('relu')(x) 
        num_filters *= 2

    # Add classifier on top. 
    # v1 does not use BN after last shortcut connection-ReLU 
    x = AveragePooling2D(pool_size=8)(x) 
    y = Flatten()(x) 
    outputs = Dense(num_classes, 
                    activation='softmax', 
                    kernel_initializer='he_normal')(y) 

    # Instantiate model. 
    model = Model(inputs=inputs, outputs=outputs) 
    return model 

Step 6: Define ResNet V2 architecture that is based on the ResNet building block we defined above:

Code: ResNet V2 architecture 

python3

# ResNet V2 architecture 
def resnet_v2(input_shape, depth, num_classes=10): 
    if (depth - 2) % 9 != 0: 
        raise ValueError('depth should be 9n + 2 (eg 56 or 110 in [b])') 
    # Start model definition. 
    num_filters_in = 16
    num_res_blocks = int((depth - 2) / 9) 

    inputs = Input(shape=input_shape) 
    # v2 performs Conv2D with BN-ReLU on input before splitting into 2 paths 
    x = resnet_layer(inputs=inputs, 
                     num_filters=num_filters_in, 
                     conv_first=True) 

    # Instantiate the stack of residual units 
    for stage in range(3): 
        for res_block in range(num_res_blocks): 
            activation = 'relu'
            batch_normalization = True
            strides = 1
            if stage == 0: 
                num_filters_out = num_filters_in * 4
                if res_block == 0:  # first layer and first stage 
                    activation = None
                    batch_normalization = False
            else: 
                num_filters_out = num_filters_in * 2
                if res_block == 0:  # first layer but not first stage 
                    strides = 2    # downsample 

            # bottleneck residual unit 
            y = resnet_layer(inputs=x, 
                             num_filters=num_filters_in, 
                             kernel_size=1, 
                             strides=strides, 
                             activation=activation, 
                             batch_normalization=batch_normalization, 
                             conv_first=False) 
            y = resnet_layer(inputs=y, 
                             num_filters=num_filters_in, 
                             conv_first=False) 
            y = resnet_layer(inputs=y, 
                             num_filters=num_filters_out, 
                             kernel_size=1, 
                             conv_first=False) 
            if res_block == 0: 
                # linear projection residual shortcut connection to match 
                # changed dims 
                x = resnet_layer(inputs=x, 
                                 num_filters=num_filters_out, 
                                 kernel_size=1, 
                                 strides=strides, 
                                 activation=None, 
                                 batch_normalization=False) 
            x = keras.layers.add([x, y]) 

        num_filters_in = num_filters_out 

    # Add classifier on top. 
    # v2 has BN-ReLU before Pooling 
    x = BatchNormalization()(x) 
    x = Activation('relu')(x) 
    x = AveragePooling2D(pool_size=8)(x) 
    y = Flatten()(x) 
    outputs = Dense(num_classes, 
                    activation='softmax', 
                    kernel_initializer='he_normal')(y) 

    # Instantiate model. 
    model = Model(inputs=inputs, outputs=outputs) 
    return model 

Step 7: The code below is used to train and test the ResNet v1 and v2 architecture we defined above:

Code: Main function 

python3

# Main function  
if version == 2: 
    model = resnet_v2(input_shape = input_shape, depth = depth) 
else: 
    model = resnet_v1(input_shape = input_shape, depth = depth) 

model.compile(loss ='categorical_crossentropy', 
              optimizer = Adam(learning_rate = lr_schedule(0)), 
              metrics =['accuracy']) 
model.summary() 
print(model_type) 

# Prepare model saving directory. 
save_dir = os.path.join(os.getcwd(), 'saved_models') 
model_name = 'cifar10_% s_model.{epoch:03d}.h5' % model_type 
if not os.path.isdir(save_dir): 
    os.makedirs(save_dir) 
filepath = os.path.join(save_dir, model_name) 

# Prepare callbacks for model saving and for learning rate adjustment. 
checkpoint = ModelCheckpoint(filepath = filepath, 
                             monitor ='val_acc', 
                             verbose = 1, 
                             save_best_only = True) 

lr_scheduler = LearningRateScheduler(lr_schedule) 

lr_reducer = ReduceLROnPlateau(factor = np.sqrt(0.1), 
                               cooldown = 0, 
                               patience = 5, 
                               min_lr = 0.5e-6) 

callbacks = [checkpoint, lr_reducer, lr_scheduler] 

# Run training, with or without data augmentation. 
if not data_augmentation: 
    print('Not using data augmentation.') 
    model.fit(x_train, y_train, 
              batch_size = batch_size, 
              epochs = epochs, 
              validation_data =(x_test, y_test), 
              shuffle = True, 
              callbacks = callbacks) 
else: 
    print('Using real-time data augmentation.') 
    # This will do preprocessing and realtime data augmentation: 
    datagen = ImageDataGenerator( 
        # set input mean to 0 over the dataset 
        featurewise_center = False, 
        # set each sample mean to 0 
        samplewise_center = False, 
        # divide inputs by std of dataset 
        featurewise_std_normalization = False, 
        # divide each input by its std 
        samplewise_std_normalization = False, 
        # apply ZCA whitening 
        zca_whitening = False, 
        # epsilon for ZCA whitening 
        zca_epsilon = 1e-06, 
        # randomly rotate images in the range (deg 0 to 180) 
        rotation_range = 0, 
        # randomly shift images horizontally 
        width_shift_range = 0.1, 
        # randomly shift images vertically 
        height_shift_range = 0.1, 
        # set range for random shear 
        shear_range = 0., 
        # set range for random zoom 
        zoom_range = 0., 
        # set range for random channel shifts 
        channel_shift_range = 0., 
        # set mode for filling points outside the input boundaries 
        fill_mode ='nearest', 
        # value used for fill_mode = "constant" 
        cval = 0., 
        # randomly flip images 
        horizontal_flip = True, 
        # randomly flip images 
        vertical_flip = False, 
        # set rescaling factor (applied before any other transformation) 
        rescale = None, 
        # set function that will be applied on each input 
        preprocessing_function = None, 
        # image data format, either "channels_first" or "channels_last" 
        data_format = None, 
        # fraction of images reserved for validation (strictly between 0 and 1) 
        validation_split = 0.0) 

    # Compute quantities required for featurewise normalization 
    # (std, mean, and principal components if ZCA whitening is applied). 
    datagen.fit(x_train) 

    # Fit the model on the batches generated by datagen.flow(). 
    model.fit_generator(datagen.flow(x_train, y_train, batch_size = batch_size), 
                        validation_data =(x_test, y_test), 
                        epochs = epochs, verbose = 1, workers = 4, 
                        callbacks = callbacks) 

# Score trained model. 
scores = model.evaluate(x_test, y_test, verbose = 1) 
print('Test loss:', scores[0]) 
print('Test accuracy:', scores[1])

Results & Conclusion: 
On the ImageNet dataset,  the authors uses a 152-layers ResNet, which is 8 times more deep than VGG19 but still have less parameters. An ensemble of these ResNets generated an error of only 3.7% on ImageNet test set, the result which won ILSVRC 2015 competition. On COCO object detection dataset, it also generates a 28% relative improvement due to its very deep representation. 

Error-rate on ResNet Architecture

The result above shows that shortcut connections would be able to solve the problem caused by increasing the layers because as we increase layers from 18 to 34 the error rate on ImageNet Validation Set also decreases unlike the plain network.

top-1 and top-5 Error rate on ImageNet Validation Set.

Below are the results on ImageNet Test Set. The 3.57% top-5 error rate of ResNet was the lowest and thus ResNet architecture came first in ImageNet classification challenge in 2015.

Are you passionate about data and looking to make one giant leap into your career? Our Data Science Course will help you change your game and, most importantly, allow students, professionals, and working adults to tide over into the data science immersion. Master state-of-the-art methodologies, powerful tools, and industry best practices, hands-on projects, and real-world applications. Become the executive head of industries related to Data Analysis, Machine Learning, and Data Visualization with these growing skills. Ready to Transform Your Future? Enroll Now to Be a Data Science Expert!

P

pawangfg
12
Previous Article
Detect and Recognize Car License Plate from a video in real time
Next Article
Twitter Sentiment Analysis using Python
Read More
Video | Residual Networks (ResNet) - Deep Learning
Similar Reads
Introduction to Residual Networks
Recent years have seen tremendous progress in the field of Image Processing and Recognition. Deep Neural Networks are becoming deeper and more complex. It has been proved that adding more layers to a Neural Network can make it more robust for image-related tasks. But it can also cause them to lose accuracy. That's where Residual Networks come into
3 min read
Deep Belief Network (DBN) in Deep Learning
Discover data creation with Deep Belief Networks (DBNs), cutting-edge generative models that make use of deep architecture. This article walks you through the concepts of DBNs, how they work, and how to implement them using practical coding. What is a Deep Belief Network?Deep Belief Networks (DBNs) are sophisticated artificial neural networks used
9 min read
Deep Boltzmann Machines (DBMs) in Deep Learning
In this article, we will discuss the Deep Boltzmann Machines concepts and their applications in the real-world scenario. What are Deep Boltzmann Machines (DBMs)?Deep Boltzmann Machines (DBMs) are a kind of artificial neural network that belongs to the family of generative models. They are designed to discover intricate structures within large datas
10 min read
Unveiling the Power of Fastai: A Deep Dive into the Versatile Deep Learning Library
Fastai is a powerful deep-learning library designed for researchers and practitioners. It offers high-level abstractions, PyTorch integration, and application-specific APIs, making it both adaptable and accessible for a wide range of deep learning tasks. In this article, we'll delve into the intricacies of Fastai, a powerful deep-learning library.
9 min read
Spiking Neural Networks in Deep Learning
Spiking Neural Networks (SNNs) represent a novel approach in artificial neural networks, inspired by the biological processes of the human brain. Unlike traditional artificial neural networks (ANNs) that rely on continuous signal processing, SNNs operate on discrete events called "spikes." The aim of this article is to provide an in-depth understan
10 min read
Introduction to Multi-Task Learning(MTL) for Deep Learning
Multi-Task Learning (MTL) is a type of machine learning technique where a model is trained to perform multiple tasks simultaneously. In deep learning, MTL refers to training a neural network to perform multiple tasks by sharing some of the network's layers and parameters across tasks. In MTL, the goal is to improve the generalization performance of
6 min read
Artificial intelligence vs Machine Learning vs Deep Learning
Nowadays many misconceptions are there related to the words machine learning, deep learning, and artificial intelligence (AI), most people think all these things are the same whenever they hear the word AI, they directly relate that word to machine learning or vice versa, well yes, these things are related to each other but not the same. Let's see
4 min read
Need of Data Structures and Algorithms for Deep Learning and Machine Learning
Deep Learning is a field that is heavily based on Mathematics and you need to have a good understanding of Data Structures and Algorithms to solve the mathematical problems optimally. Data Structures and Algorithms can be used to determine how a problem is represented internally or how the actual storage pattern works &amp; what is happening under
6 min read
Difference Between Artificial Intelligence vs Machine Learning vs Deep Learning
Artificial Intelligence is basically the mechanism to incorporate human intelligence into machines through a set of rules(algorithm). AI is a combination of two words: "Artificial" meaning something made by humans or non-natural things and "Intelligence" meaning the ability to understand or think accordingly. Another definition could be that "AI is
14 min read
Difference Between Machine Learning and Deep Learning
If you are interested in building your career in the IT industry then you must have come across the term Data Science which is a booming field in terms of technologies and job availability as well. In this article, we will explore the Difference between Machine Learning and Deep Learning, two major fields within Data Science. Understanding these di
8 min read
Article Tags :
AI-ML-DS
Deep Learning
Machine Learning
AI-ML-DS With Python
+1 More
Practice Tags :
Machine Learning
python

Residual Networks (ResNet) – Deep Learning
Last Updated : 10 Jan, 2023
Generative Summary
Now you can generate the summary of any article of your choice.
Got it

Residual Networks (ResNet) – Deep Learning
Last Updated : 10 Jan, 2023

Residual Networks (ResNet) – Deep Learning

Residual Networks (ResNet) – Deep Learning

Last Updated : 10 Jan, 2023

Generative Summary
Now you can generate the summary of any article of your choice.
Got it

Generative Summary
Now you can generate the summary of any article of your choice.
Got it

Generative Summary
Now you can generate the summary of any article of your choice.
Got it

Generative Summary
Now you can generate the summary of any article of your choice.
Got it

Generative Summary
Now you can generate the summary of any article of your choice.
Got it

Generative Summary
Now you can generate the summary of any article of your choice.

Generative Summary

Now you can generate the summary of any article of your choice.

Got it

Suggest changes

                                                        12 Likes

                                                        Like

                                                        Save

                                                        Share

                                                        Report

                                                    Follow

Suggest changes

                                                        12 Likes

                                                        Like

                                                        Save

                                                        Share

                                                        Report

                                                    Follow

Suggest changes

Suggest changes

Suggest changes

12 Likes

                                                        Like

12 Likes

                                                        Like

12 Likes

Like

Save

Save

Save

Share

Share

Share

Report

Report

Report

Follow

After the first CNN-based architecture (AlexNet) that win the ImageNet 2012 competition, Every subsequent winning architecture uses more layers in a deep neural network to reduce the error rate. This works for less number of layers, but when we increase the number of layers, there is a common problem in deep learning associated with that called the Vanishing/Exploding gradient. This causes the gradient to become 0 or too large. Thus when we increases number of layers, the training and test error rate also increases. 

Comparison of 20-layer vs 56-layer architecture

In the above plot, we can observe that a 56-layer CNN gives more error rate on both training and testing dataset than a 20-layer CNN architecture. After analyzing more on error rate the authors were able to reach conclusion that it is caused by vanishing/exploding gradient. 
ResNet, which was proposed in 2015 by researchers at Microsoft Research introduced a new architecture called Residual Network. 

Residual Network: In order to solve the problem of the vanishing/exploding gradient, this architecture introduced the concept called Residual Blocks. In this network, we use a technique called skip connections. The skip connection connects activations of a  layer to further layers by skipping some layers in between. This forms a residual block. Resnets are made by stacking these residual blocks together. 
The approach behind this network is instead of layers learning the underlying mapping, we allow the network to fit the residual mapping. So, instead of say H(x), initial mapping, let the network fit, 

F(x) := H(x) - x which gives H(x) := F(x) + x. 

Skip (Shortcut) connection

The advantage of adding this type of skip connection is that if any layer hurt the performance of architecture then it will be skipped by regularization. So, this results in training a very deep neural network without the problems caused by vanishing/exploding gradient.  The authors of the paper experimented on 100-1000 layers of the CIFAR-10 dataset. 
There is a similar approach called “highway networks”, these networks also use skip connection. Similar to LSTM these skip connections also use parametric gates. These gates determine how much information passes through the skip connection. This architecture however has not provided accuracy better than ResNet architecture. 

Network Architecture: This network uses a 34-layer plain network architecture inspired by VGG-19 in which then the shortcut connection is added. These shortcut connections then convert the architecture into a residual network.  

ResNet -34 architecture

Implementation: Using the Tensorflow and Keras API, we can design ResNet architecture (including Residual Blocks) from scratch. Below is the implementation of different ResNet architecture. For this implementation, we use the CIFAR-10 dataset. This dataset contains 60, 000 32×32 color images in 10 different classes (airplanes, cars, birds, cats, deer, dogs, frogs, horses, ships, and trucks), etc. This dataset can be assessed from keras.datasets API function. 

Step 1: First, we import the keras module and its APIs. These APIs help in building the architecture of the ResNet model.

Code: Importing libraries 

# Import Keras modules and its important APIs
import keras
from keras.layers import Dense, Conv2D, BatchNormalization, Activation
from keras.layers import AveragePooling2D, Input, Flatten
from keras.optimizers import Adam
from keras.callbacks import ModelCheckpoint, LearningRateScheduler
from keras.callbacks import ReduceLROnPlateau
from keras.preprocessing.image import ImageDataGenerator
from keras.regularizers import l2
from keras import backend as K
from keras.models import Model
from keras.datasets import cifar10
import numpy as np
import os

Step 2: Now, We set different hyper parameters that are required for ResNet architecture. We also did some preprocessing on our dataset to prepare it for training.

Code: Setting Training Hyperparameters  

python3

# Setting Training Hyperparameters 
batch_size = 32  # original ResNet paper uses batch_size = 128 for training 
epochs = 200
data_augmentation = True
num_classes = 10

# Data Preprocessing  
subtract_pixel_mean = True
n = 3

# Select ResNet Version 
version = 1

# Computed depth of  
if version == 1: 
    depth = n * 6 + 2
elif version == 2: 
    depth = n * 9 + 2

# Model name, depth and version 
model_type = 'ResNet % dv % d' % (depth, version) 

# Load the CIFAR-10 data. 
(x_train, y_train), (x_test, y_test) = cifar10.load_data() 

# Input image dimensions. 
input_shape = x_train.shape[1:] 

# Normalize data. 
x_train = x_train.astype('float32') / 255
x_test = x_test.astype('float32') / 255

# If subtract pixel mean is enabled 
if subtract_pixel_mean: 
    x_train_mean = np.mean(x_train, axis = 0) 
    x_train -= x_train_mean 
    x_test -= x_train_mean 

# Print Training and Test Samples  
print('x_train shape:', x_train.shape) 
print(x_train.shape[0], 'train samples') 
print(x_test.shape[0], 'test samples') 
print('y_train shape:', y_train.shape) 

# Convert class vectors to binary class matrices. 
y_train = keras.utils.to_categorical(y_train, num_classes) 
y_test = keras.utils.to_categorical(y_test, num_classes) 

Step 3: In this step, we set the learning rate according to the number of epochs. As the number of epochs the learning rate must be decreased to ensure better learning.

Code: Setting LR for different numbers of Epochs 

python3

# Setting LR for different number of Epochs 
def lr_schedule(epoch): 
    lr = 1e-3
    if epoch > 180: 
        lr *= 0.5e-3
    elif epoch > 160: 
        lr *= 1e-3
    elif epoch > 120: 
        lr *= 1e-2
    elif epoch > 80: 
        lr *= 1e-1
    print('Learning rate: ', lr) 
    return lr 

Step 4: Define basic ResNet building block that can be used for defining the ResNet V1 and V2 architecture.

Code: Basic ResNet Building Block 

python3

# Basic ResNet Building Block 

def resnet_layer(inputs, 
                 num_filters=16, 
                 kernel_size=3, 
                 strides=1, 
                 activation='relu', 
                 batch_normalization=True, 
    conv=Conv2D(num_filters, 
                  kernel_size=kernel_size, 
                  strides=strides, 
                  padding='same', 
                  kernel_initializer='he_normal', 
                  kernel_regularizer=l2(1e-4)) 

    x=inputs 
    if conv_first: 
        x = conv(x) 
        if batch_normalization: 
            x = BatchNormalization()(x) 
        if activation is not None: 
            x = Activation(activation)(x) 
    else: 
        if batch_normalization: 
            x = BatchNormalization()(x) 
        if activation is not None: 
            x = Activation(activation)(x) 
        x = conv(x) 
    return x 

Step 5: Define ResNet V1 architecture that is based on the ResNet building block we defined above:

Code: ResNet V1 architecture 

python3

def resnet_v1(input_shape, depth, num_classes=10): 

    if (depth - 2) % 6 != 0: 
        raise ValueError('depth should be 6n + 2 (eg 20, 32, 44 in [a])') 
    # Start model definition. 
    num_filters = 16
    num_res_blocks = int((depth - 2) / 6) 

    inputs = Input(shape=input_shape) 
    x = resnet_layer(inputs=inputs) 
    # Instantiate the stack of residual units 
    for stack in range(3): 
        for res_block in range(num_res_blocks): 
            strides = 1
            if stack & gt 
            0 and res_block == 0:  # first layer but not first stack 
                strides = 2  # downsample 
            y = resnet_layer(inputs=x, 
                             num_filters=num_filters, 
                             strides=strides) 
            y = resnet_layer(inputs=y, 
                             num_filters=num_filters, 
                             activation=None) 
            if stack & gt 
            0 and res_block == 0:  # first layer but not first stack 
                # linear projection residual shortcut connection to match 
                # changed dims 
                x = resnet_layer(inputs=x, 
                                 num_filters=num_filters, 
                                 kernel_size=1, 
                                 strides=strides, 
                                 activation=None, 
                                 batch_normalization=False) 
            x = keras.layers.add([x, y]) 
            x = Activation('relu')(x) 
        num_filters *= 2

    # Add classifier on top. 
    # v1 does not use BN after last shortcut connection-ReLU 
    x = AveragePooling2D(pool_size=8)(x) 
    y = Flatten()(x) 
    outputs = Dense(num_classes, 
                    activation='softmax', 
                    kernel_initializer='he_normal')(y) 

    # Instantiate model. 
    model = Model(inputs=inputs, outputs=outputs) 
    return model 

Step 6: Define ResNet V2 architecture that is based on the ResNet building block we defined above:

Code: ResNet V2 architecture 

python3

# ResNet V2 architecture 
def resnet_v2(input_shape, depth, num_classes=10): 
    if (depth - 2) % 9 != 0: 
        raise ValueError('depth should be 9n + 2 (eg 56 or 110 in [b])') 
    # Start model definition. 
    num_filters_in = 16
    num_res_blocks = int((depth - 2) / 9) 

    inputs = Input(shape=input_shape) 
    # v2 performs Conv2D with BN-ReLU on input before splitting into 2 paths 
    x = resnet_layer(inputs=inputs, 
                     num_filters=num_filters_in, 
                     conv_first=True) 

    # Instantiate the stack of residual units 
    for stage in range(3): 
        for res_block in range(num_res_blocks): 
            activation = 'relu'
            batch_normalization = True
            strides = 1
            if stage == 0: 
                num_filters_out = num_filters_in * 4
                if res_block == 0:  # first layer and first stage 
                    activation = None
                    batch_normalization = False
            else: 
                num_filters_out = num_filters_in * 2
                if res_block == 0:  # first layer but not first stage 
                    strides = 2    # downsample 

            # bottleneck residual unit 
            y = resnet_layer(inputs=x, 
                             num_filters=num_filters_in, 
                             kernel_size=1, 
                             strides=strides, 
                             activation=activation, 
                             batch_normalization=batch_normalization, 
                             conv_first=False) 
            y = resnet_layer(inputs=y, 
                             num_filters=num_filters_in, 
                             conv_first=False) 
            y = resnet_layer(inputs=y, 
                             num_filters=num_filters_out, 
                             kernel_size=1, 
                             conv_first=False) 
            if res_block == 0: 
                # linear projection residual shortcut connection to match 
                # changed dims 
                x = resnet_layer(inputs=x, 
                                 num_filters=num_filters_out, 
                                 kernel_size=1, 
                                 strides=strides, 
                                 activation=None, 
                                 batch_normalization=False) 
            x = keras.layers.add([x, y]) 

        num_filters_in = num_filters_out 

    # Add classifier on top. 
    # v2 has BN-ReLU before Pooling 
    x = BatchNormalization()(x) 
    x = Activation('relu')(x) 
    x = AveragePooling2D(pool_size=8)(x) 
    y = Flatten()(x) 
    outputs = Dense(num_classes, 
                    activation='softmax', 
                    kernel_initializer='he_normal')(y) 

    # Instantiate model. 
    model = Model(inputs=inputs, outputs=outputs) 
    return model 

Step 7: The code below is used to train and test the ResNet v1 and v2 architecture we defined above:

Code: Main function 

python3

# Main function  
if version == 2: 
    model = resnet_v2(input_shape = input_shape, depth = depth) 
else: 
    model = resnet_v1(input_shape = input_shape, depth = depth) 

model.compile(loss ='categorical_crossentropy', 
              optimizer = Adam(learning_rate = lr_schedule(0)), 
              metrics =['accuracy']) 
model.summary() 
print(model_type) 

# Prepare model saving directory. 
save_dir = os.path.join(os.getcwd(), 'saved_models') 
model_name = 'cifar10_% s_model.{epoch:03d}.h5' % model_type 
if not os.path.isdir(save_dir): 
    os.makedirs(save_dir) 
filepath = os.path.join(save_dir, model_name) 

# Prepare callbacks for model saving and for learning rate adjustment. 
checkpoint = ModelCheckpoint(filepath = filepath, 
                             monitor ='val_acc', 
                             verbose = 1, 
                             save_best_only = True) 

lr_scheduler = LearningRateScheduler(lr_schedule) 

lr_reducer = ReduceLROnPlateau(factor = np.sqrt(0.1), 
                               cooldown = 0, 
                               patience = 5, 
                               min_lr = 0.5e-6) 

callbacks = [checkpoint, lr_reducer, lr_scheduler] 

# Run training, with or without data augmentation. 
if not data_augmentation: 
    print('Not using data augmentation.') 
    model.fit(x_train, y_train, 
              batch_size = batch_size, 
              epochs = epochs, 
              validation_data =(x_test, y_test), 
              shuffle = True, 
              callbacks = callbacks) 
else: 
    print('Using real-time data augmentation.') 
    # This will do preprocessing and realtime data augmentation: 
    datagen = ImageDataGenerator( 
        # set input mean to 0 over the dataset 
        featurewise_center = False, 
        # set each sample mean to 0 
        samplewise_center = False, 
        # divide inputs by std of dataset 
        featurewise_std_normalization = False, 
        # divide each input by its std 
        samplewise_std_normalization = False, 
        # apply ZCA whitening 
        zca_whitening = False, 
        # epsilon for ZCA whitening 
        zca_epsilon = 1e-06, 
        # randomly rotate images in the range (deg 0 to 180) 
        rotation_range = 0, 
        # randomly shift images horizontally 
        width_shift_range = 0.1, 
        # randomly shift images vertically 
        height_shift_range = 0.1, 
        # set range for random shear 
        shear_range = 0., 
        # set range for random zoom 
        zoom_range = 0., 
        # set range for random channel shifts 
        channel_shift_range = 0., 
        # set mode for filling points outside the input boundaries 
        fill_mode ='nearest', 
        # value used for fill_mode = "constant" 
        cval = 0., 
        # randomly flip images 
        horizontal_flip = True, 
        # randomly flip images 
        vertical_flip = False, 
        # set rescaling factor (applied before any other transformation) 
        rescale = None, 
        # set function that will be applied on each input 
        preprocessing_function = None, 
        # image data format, either "channels_first" or "channels_last" 
        data_format = None, 
        # fraction of images reserved for validation (strictly between 0 and 1) 
        validation_split = 0.0) 

    # Compute quantities required for featurewise normalization 
    # (std, mean, and principal components if ZCA whitening is applied). 
    datagen.fit(x_train) 

    # Fit the model on the batches generated by datagen.flow(). 
    model.fit_generator(datagen.flow(x_train, y_train, batch_size = batch_size), 
                        validation_data =(x_test, y_test), 
                        epochs = epochs, verbose = 1, workers = 4, 
                        callbacks = callbacks) 

# Score trained model. 
scores = model.evaluate(x_test, y_test, verbose = 1) 
print('Test loss:', scores[0]) 
print('Test accuracy:', scores[1])

Results & Conclusion: 
On the ImageNet dataset,  the authors uses a 152-layers ResNet, which is 8 times more deep than VGG19 but still have less parameters. An ensemble of these ResNets generated an error of only 3.7% on ImageNet test set, the result which won ILSVRC 2015 competition. On COCO object detection dataset, it also generates a 28% relative improvement due to its very deep representation. 

Error-rate on ResNet Architecture

The result above shows that shortcut connections would be able to solve the problem caused by increasing the layers because as we increase layers from 18 to 34 the error rate on ImageNet Validation Set also decreases unlike the plain network.

top-1 and top-5 Error rate on ImageNet Validation Set.

Below are the results on ImageNet Test Set. The 3.57% top-5 error rate of ResNet was the lowest and thus ResNet architecture came first in ImageNet classification challenge in 2015.

Are you passionate about data and looking to make one giant leap into your career? Our Data Science Course will help you change your game and, most importantly, allow students, professionals, and working adults to tide over into the data science immersion. Master state-of-the-art methodologies, powerful tools, and industry best practices, hands-on projects, and real-world applications. Become the executive head of industries related to Data Analysis, Machine Learning, and Data Visualization with these growing skills. Ready to Transform Your Future? Enroll Now to Be a Data Science Expert!

P

pawangfg
12
Previous Article
Detect and Recognize Car License Plate from a video in real time
Next Article
Twitter Sentiment Analysis using Python

After the first CNN-based architecture (AlexNet) that win the ImageNet 2012 competition, Every subsequent winning architecture uses more layers in a deep neural network to reduce the error rate. This works for less number of layers, but when we increase the number of layers, there is a common problem in deep learning associated with that called the Vanishing/Exploding gradient. This causes the gradient to become 0 or too large. Thus when we increases number of layers, the training and test error rate also increases.

Comparison of 20-layer vs 56-layer architecture

Comparison of 20-layer vs 56-layer architecture

In the above plot, we can observe that a 56-layer CNN gives more error rate on both training and testing dataset than a 20-layer CNN architecture. After analyzing more on error rate the authors were able to reach conclusion that it is caused by vanishing/exploding gradient. 
ResNet, which was proposed in 2015 by researchers at Microsoft Research introduced a new architecture called Residual Network.

Residual Network: In order to solve the problem of the vanishing/exploding gradient, this architecture introduced the concept called Residual Blocks. In this network, we use a technique called skip connections. The skip connection connects activations of a  layer to further layers by skipping some layers in between. This forms a residual block. Resnets are made by stacking these residual blocks together. 
The approach behind this network is instead of layers learning the underlying mapping, we allow the network to fit the residual mapping. So, instead of say H(x), initial mapping, let the network fit,

Skip (Shortcut) connection

Skip (Shortcut) connection

The advantage of adding this type of skip connection is that if any layer hurt the performance of architecture then it will be skipped by regularization. So, this results in training a very deep neural network without the problems caused by vanishing/exploding gradient.  The authors of the paper experimented on 100-1000 layers of the CIFAR-10 dataset. 
There is a similar approach called “highway networks”, these networks also use skip connection. Similar to LSTM these skip connections also use parametric gates. These gates determine how much information passes through the skip connection. This architecture however has not provided accuracy better than ResNet architecture.

Network Architecture: This network uses a 34-layer plain network architecture inspired by VGG-19 in which then the shortcut connection is added. These shortcut connections then convert the architecture into a residual network.

ResNet -34 architecture

ResNet -34 architecture

Implementation: Using the Tensorflow and Keras API, we can design ResNet architecture (including Residual Blocks) from scratch. Below is the implementation of different ResNet architecture. For this implementation, we use the CIFAR-10 dataset. This dataset contains 60, 000 32×32 color images in 10 different classes (airplanes, cars, birds, cats, deer, dogs, frogs, horses, ships, and trucks), etc. This dataset can be assessed from keras.datasets API function.

Step 1: First, we import the keras module and its APIs. These APIs help in building the architecture of the ResNet model.

Code: Importing libraries

Step 2: Now, We set different hyper parameters that are required for ResNet architecture. We also did some preprocessing on our dataset to prepare it for training.

Code: Setting Training Hyperparameters

python3

# Setting Training Hyperparameters 
batch_size = 32  # original ResNet paper uses batch_size = 128 for training 
epochs = 200
data_augmentation = True
num_classes = 10

# Data Preprocessing  
subtract_pixel_mean = True
n = 3

# Select ResNet Version 
version = 1

# Computed depth of  
if version == 1: 
    depth = n * 6 + 2
elif version == 2: 
    depth = n * 9 + 2

# Model name, depth and version 
model_type = 'ResNet % dv % d' % (depth, version) 

# Load the CIFAR-10 data. 
(x_train, y_train), (x_test, y_test) = cifar10.load_data() 

# Input image dimensions. 
input_shape = x_train.shape[1:] 

# Normalize data. 
x_train = x_train.astype('float32') / 255
x_test = x_test.astype('float32') / 255

# If subtract pixel mean is enabled 
if subtract_pixel_mean: 
    x_train_mean = np.mean(x_train, axis = 0) 
    x_train -= x_train_mean 
    x_test -= x_train_mean 

# Print Training and Test Samples  
print('x_train shape:', x_train.shape) 
print(x_train.shape[0], 'train samples') 
print(x_test.shape[0], 'test samples') 
print('y_train shape:', y_train.shape) 

# Convert class vectors to binary class matrices. 
y_train = keras.utils.to_categorical(y_train, num_classes) 
y_test = keras.utils.to_categorical(y_test, num_classes)

python3

# Setting Training Hyperparameters 
batch_size = 32  # original ResNet paper uses batch_size = 128 for training 
epochs = 200
data_augmentation = True
num_classes = 10

# Data Preprocessing  
subtract_pixel_mean = True
n = 3

# Select ResNet Version 
version = 1

# Computed depth of  
if version == 1: 
    depth = n * 6 + 2
elif version == 2: 
    depth = n * 9 + 2

# Model name, depth and version 
model_type = 'ResNet % dv % d' % (depth, version) 

# Load the CIFAR-10 data. 
(x_train, y_train), (x_test, y_test) = cifar10.load_data() 

# Input image dimensions. 
input_shape = x_train.shape[1:] 

# Normalize data. 
x_train = x_train.astype('float32') / 255
x_test = x_test.astype('float32') / 255

# If subtract pixel mean is enabled 
if subtract_pixel_mean: 
    x_train_mean = np.mean(x_train, axis = 0) 
    x_train -= x_train_mean 
    x_test -= x_train_mean 

# Print Training and Test Samples  
print('x_train shape:', x_train.shape) 
print(x_train.shape[0], 'train samples') 
print(x_test.shape[0], 'test samples') 
print('y_train shape:', y_train.shape) 

# Convert class vectors to binary class matrices. 
y_train = keras.utils.to_categorical(y_train, num_classes) 
y_test = keras.utils.to_categorical(y_test, num_classes)

python3

# Setting Training Hyperparameters 
batch_size = 32  # original ResNet paper uses batch_size = 128 for training 
epochs = 200
data_augmentation = True
num_classes = 10

# Data Preprocessing  
subtract_pixel_mean = True
n = 3

# Select ResNet Version 
version = 1

# Computed depth of  
if version == 1: 
    depth = n * 6 + 2
elif version == 2: 
    depth = n * 9 + 2

# Model name, depth and version 
model_type = 'ResNet % dv % d' % (depth, version) 

# Load the CIFAR-10 data. 
(x_train, y_train), (x_test, y_test) = cifar10.load_data() 

# Input image dimensions. 
input_shape = x_train.shape[1:] 

# Normalize data. 
x_train = x_train.astype('float32') / 255
x_test = x_test.astype('float32') / 255

# If subtract pixel mean is enabled 
if subtract_pixel_mean: 
    x_train_mean = np.mean(x_train, axis = 0) 
    x_train -= x_train_mean 
    x_test -= x_train_mean 

# Print Training and Test Samples  
print('x_train shape:', x_train.shape) 
print(x_train.shape[0], 'train samples') 
print(x_test.shape[0], 'test samples') 
print('y_train shape:', y_train.shape) 

# Convert class vectors to binary class matrices. 
y_train = keras.utils.to_categorical(y_train, num_classes) 
y_test = keras.utils.to_categorical(y_test, num_classes)

# Setting Training Hyperparameters 
batch_size = 32  # original ResNet paper uses batch_size = 128 for training 
epochs = 200
data_augmentation = True
num_classes = 10

# Data Preprocessing  
subtract_pixel_mean = True
n = 3

# Select ResNet Version 
version = 1

# Computed depth of  
if version == 1: 
    depth = n * 6 + 2
elif version == 2: 
    depth = n * 9 + 2

# Model name, depth and version 
model_type = 'ResNet % dv % d' % (depth, version) 

# Load the CIFAR-10 data. 
(x_train, y_train), (x_test, y_test) = cifar10.load_data() 

# Input image dimensions. 
input_shape = x_train.shape[1:] 

# Normalize data. 
x_train = x_train.astype('float32') / 255
x_test = x_test.astype('float32') / 255

# If subtract pixel mean is enabled 
if subtract_pixel_mean: 
    x_train_mean = np.mean(x_train, axis = 0) 
    x_train -= x_train_mean 
    x_test -= x_train_mean 

# Print Training and Test Samples  
print('x_train shape:', x_train.shape) 
print(x_train.shape[0], 'train samples') 
print(x_test.shape[0], 'test samples') 
print('y_train shape:', y_train.shape) 

# Convert class vectors to binary class matrices. 
y_train = keras.utils.to_categorical(y_train, num_classes) 
y_test = keras.utils.to_categorical(y_test, num_classes)

# Setting Training Hyperparameters 
batch_size = 32  # original ResNet paper uses batch_size = 128 for training 
epochs = 200
data_augmentation = True
num_classes = 10

# Data Preprocessing  
subtract_pixel_mean = True
n = 3

# Select ResNet Version 
version = 1

# Computed depth of  
if version == 1: 
    depth = n * 6 + 2
elif version == 2: 
    depth = n * 9 + 2

# Model name, depth and version 
model_type = 'ResNet % dv % d' % (depth, version) 

# Load the CIFAR-10 data. 
(x_train, y_train), (x_test, y_test) = cifar10.load_data() 

# Input image dimensions. 
input_shape = x_train.shape[1:] 

# Normalize data. 
x_train = x_train.astype('float32') / 255
x_test = x_test.astype('float32') / 255

# If subtract pixel mean is enabled 
if subtract_pixel_mean: 
    x_train_mean = np.mean(x_train, axis = 0) 
    x_train -= x_train_mean 
    x_test -= x_train_mean 

# Print Training and Test Samples  
print('x_train shape:', x_train.shape) 
print(x_train.shape[0], 'train samples') 
print(x_test.shape[0], 'test samples') 
print('y_train shape:', y_train.shape) 

# Convert class vectors to binary class matrices. 
y_train = keras.utils.to_categorical(y_train, num_classes) 
y_test = keras.utils.to_categorical(y_test, num_classes)

# Setting Training Hyperparameters 
batch_size = 32  # original ResNet paper uses batch_size = 128 for training 
epochs = 200
data_augmentation = True
num_classes = 10

# Data Preprocessing  
subtract_pixel_mean = True
n = 3

# Select ResNet Version 
version = 1

# Computed depth of  
if version == 1: 
    depth = n * 6 + 2
elif version == 2: 
    depth = n * 9 + 2

# Model name, depth and version 
model_type = 'ResNet % dv % d' % (depth, version) 

# Load the CIFAR-10 data. 
(x_train, y_train), (x_test, y_test) = cifar10.load_data() 

# Input image dimensions. 
input_shape = x_train.shape[1:] 

# Normalize data. 
x_train = x_train.astype('float32') / 255
x_test = x_test.astype('float32') / 255

# If subtract pixel mean is enabled 
if subtract_pixel_mean: 
    x_train_mean = np.mean(x_train, axis = 0) 
    x_train -= x_train_mean 
    x_test -= x_train_mean 

# Print Training and Test Samples  
print('x_train shape:', x_train.shape) 
print(x_train.shape[0], 'train samples') 
print(x_test.shape[0], 'test samples') 
print('y_train shape:', y_train.shape) 

# Convert class vectors to binary class matrices. 
y_train = keras.utils.to_categorical(y_train, num_classes) 
y_test = keras.utils.to_categorical(y_test, num_classes)

# Setting Training Hyperparameters 
batch_size = 32  # original ResNet paper uses batch_size = 128 for training 
epochs = 200
data_augmentation = True
num_classes = 10

# Data Preprocessing  
subtract_pixel_mean = True
n = 3

# Select ResNet Version 
version = 1

# Computed depth of  
if version == 1: 
    depth = n * 6 + 2
elif version == 2: 
    depth = n * 9 + 2

# Model name, depth and version 
model_type = 'ResNet % dv % d' % (depth, version) 

# Load the CIFAR-10 data. 
(x_train, y_train), (x_test, y_test) = cifar10.load_data() 

# Input image dimensions. 
input_shape = x_train.shape[1:] 

# Normalize data. 
x_train = x_train.astype('float32') / 255
x_test = x_test.astype('float32') / 255

# If subtract pixel mean is enabled 
if subtract_pixel_mean: 
    x_train_mean = np.mean(x_train, axis = 0) 
    x_train -= x_train_mean 
    x_test -= x_train_mean 

# Print Training and Test Samples  
print('x_train shape:', x_train.shape) 
print(x_train.shape[0], 'train samples') 
print(x_test.shape[0], 'test samples') 
print('y_train shape:', y_train.shape) 

# Convert class vectors to binary class matrices. 
y_train = keras.utils.to_categorical(y_train, num_classes) 
y_test = keras.utils.to_categorical(y_test, num_classes)

# Setting Training Hyperparameters

batch_size = 32  # original ResNet paper uses batch_size = 128 for training

epochs = 200

data_augmentation = True

num_classes = 10

# Data Preprocessing

subtract_pixel_mean = True

n = 3

# Select ResNet Version

version = 1

# Computed depth of

if version == 1:

depth = n * 6 + 2

elif version == 2:

depth = n * 9 + 2

# Model name, depth and version

model_type = 'ResNet % dv % d' % (depth, version)

# Load the CIFAR-10 data.

(x_train, y_train), (x_test, y_test) = cifar10.load_data()

# Input image dimensions.

input_shape = x_train.shape[1:]

# Normalize data.

x_train = x_train.astype('float32') / 255

x_test = x_test.astype('float32') / 255

# If subtract pixel mean is enabled

if subtract_pixel_mean:

x_train_mean = np.mean(x_train, axis = 0)

x_train -= x_train_mean

x_test -= x_train_mean

# Print Training and Test Samples

print('x_train shape:', x_train.shape)

print(x_train.shape[0], 'train samples')

print(x_test.shape[0], 'test samples')

print('y_train shape:', y_train.shape)

# Convert class vectors to binary class matrices.

y_train = keras.utils.to_categorical(y_train, num_classes)

y_test = keras.utils.to_categorical(y_test, num_classes)

Step 3: In this step, we set the learning rate according to the number of epochs. As the number of epochs the learning rate must be decreased to ensure better learning.

Code: Setting LR for different numbers of Epochs

python3

# Setting LR for different number of Epochs 
def lr_schedule(epoch): 
    lr = 1e-3
    if epoch > 180: 
        lr *= 0.5e-3
    elif epoch > 160: 
        lr *= 1e-3
    elif epoch > 120: 
        lr *= 1e-2
    elif epoch > 80: 
        lr *= 1e-1
    print('Learning rate: ', lr) 
    return lr

python3

# Setting LR for different number of Epochs 
def lr_schedule(epoch): 
    lr = 1e-3
    if epoch > 180: 
        lr *= 0.5e-3
    elif epoch > 160: 
        lr *= 1e-3
    elif epoch > 120: 
        lr *= 1e-2
    elif epoch > 80: 
        lr *= 1e-1
    print('Learning rate: ', lr) 
    return lr

python3

# Setting LR for different number of Epochs 
def lr_schedule(epoch): 
    lr = 1e-3
    if epoch > 180: 
        lr *= 0.5e-3
    elif epoch > 160: 
        lr *= 1e-3
    elif epoch > 120: 
        lr *= 1e-2
    elif epoch > 80: 
        lr *= 1e-1
    print('Learning rate: ', lr) 
    return lr

# Setting LR for different number of Epochs 
def lr_schedule(epoch): 
    lr = 1e-3
    if epoch > 180: 
        lr *= 0.5e-3
    elif epoch > 160: 
        lr *= 1e-3
    elif epoch > 120: 
        lr *= 1e-2
    elif epoch > 80: 
        lr *= 1e-1
    print('Learning rate: ', lr) 
    return lr

# Setting LR for different number of Epochs 
def lr_schedule(epoch): 
    lr = 1e-3
    if epoch > 180: 
        lr *= 0.5e-3
    elif epoch > 160: 
        lr *= 1e-3
    elif epoch > 120: 
        lr *= 1e-2
    elif epoch > 80: 
        lr *= 1e-1
    print('Learning rate: ', lr) 
    return lr

# Setting LR for different number of Epochs 
def lr_schedule(epoch): 
    lr = 1e-3
    if epoch > 180: 
        lr *= 0.5e-3
    elif epoch > 160: 
        lr *= 1e-3
    elif epoch > 120: 
        lr *= 1e-2
    elif epoch > 80: 
        lr *= 1e-1
    print('Learning rate: ', lr) 
    return lr

# Setting LR for different number of Epochs 
def lr_schedule(epoch): 
    lr = 1e-3
    if epoch > 180: 
        lr *= 0.5e-3
    elif epoch > 160: 
        lr *= 1e-3
    elif epoch > 120: 
        lr *= 1e-2
    elif epoch > 80: 
        lr *= 1e-1
    print('Learning rate: ', lr) 
    return lr

# Setting LR for different number of Epochs

def lr_schedule(epoch):

lr = 1e-3

if epoch > 180:

lr *= 0.5e-3

elif epoch > 160:

lr *= 1e-3

elif epoch > 120:

lr *= 1e-2

elif epoch > 80:

lr *= 1e-1

print('Learning rate: ', lr)

return lr

Step 4: Define basic ResNet building block that can be used for defining the ResNet V1 and V2 architecture.

Code: Basic ResNet Building Block

python3

# Basic ResNet Building Block 

def resnet_layer(inputs, 
                 num_filters=16, 
                 kernel_size=3, 
                 strides=1, 
                 activation='relu', 
                 batch_normalization=True, 
    conv=Conv2D(num_filters, 
                  kernel_size=kernel_size, 
                  strides=strides, 
                  padding='same', 
                  kernel_initializer='he_normal', 
                  kernel_regularizer=l2(1e-4)) 

    x=inputs 
    if conv_first: 
        x = conv(x) 
        if batch_normalization: 
            x = BatchNormalization()(x) 
        if activation is not None: 
            x = Activation(activation)(x) 
    else: 
        if batch_normalization: 
            x = BatchNormalization()(x) 
        if activation is not None: 
            x = Activation(activation)(x) 
        x = conv(x) 
    return x

python3

# Basic ResNet Building Block 

def resnet_layer(inputs, 
                 num_filters=16, 
                 kernel_size=3, 
                 strides=1, 
                 activation='relu', 
                 batch_normalization=True, 
    conv=Conv2D(num_filters, 
                  kernel_size=kernel_size, 
                  strides=strides, 
                  padding='same', 
                  kernel_initializer='he_normal', 
                  kernel_regularizer=l2(1e-4)) 

    x=inputs 
    if conv_first: 
        x = conv(x) 
        if batch_normalization: 
            x = BatchNormalization()(x) 
        if activation is not None: 
            x = Activation(activation)(x) 
    else: 
        if batch_normalization: 
            x = BatchNormalization()(x) 
        if activation is not None: 
            x = Activation(activation)(x) 
        x = conv(x) 
    return x

python3

# Basic ResNet Building Block 

def resnet_layer(inputs, 
                 num_filters=16, 
                 kernel_size=3, 
                 strides=1, 
                 activation='relu', 
                 batch_normalization=True, 
    conv=Conv2D(num_filters, 
                  kernel_size=kernel_size, 
                  strides=strides, 
                  padding='same', 
                  kernel_initializer='he_normal', 
                  kernel_regularizer=l2(1e-4)) 

    x=inputs 
    if conv_first: 
        x = conv(x) 
        if batch_normalization: 
            x = BatchNormalization()(x) 
        if activation is not None: 
            x = Activation(activation)(x) 
    else: 
        if batch_normalization: 
            x = BatchNormalization()(x) 
        if activation is not None: 
            x = Activation(activation)(x) 
        x = conv(x) 
    return x

# Basic ResNet Building Block 

def resnet_layer(inputs, 
                 num_filters=16, 
                 kernel_size=3, 
                 strides=1, 
                 activation='relu', 
                 batch_normalization=True, 
    conv=Conv2D(num_filters, 
                  kernel_size=kernel_size, 
                  strides=strides, 
                  padding='same', 
                  kernel_initializer='he_normal', 
                  kernel_regularizer=l2(1e-4)) 

    x=inputs 
    if conv_first: 
        x = conv(x) 
        if batch_normalization: 
            x = BatchNormalization()(x) 
        if activation is not None: 
            x = Activation(activation)(x) 
    else: 
        if batch_normalization: 
            x = BatchNormalization()(x) 
        if activation is not None: 
            x = Activation(activation)(x) 
        x = conv(x) 
    return x

# Basic ResNet Building Block 

def resnet_layer(inputs, 
                 num_filters=16, 
                 kernel_size=3, 
                 strides=1, 
                 activation='relu', 
                 batch_normalization=True, 
    conv=Conv2D(num_filters, 
                  kernel_size=kernel_size, 
                  strides=strides, 
                  padding='same', 
                  kernel_initializer='he_normal', 
                  kernel_regularizer=l2(1e-4)) 

    x=inputs 
    if conv_first: 
        x = conv(x) 
        if batch_normalization: 
            x = BatchNormalization()(x) 
        if activation is not None: 
            x = Activation(activation)(x) 
    else: 
        if batch_normalization: 
            x = BatchNormalization()(x) 
        if activation is not None: 
            x = Activation(activation)(x) 
        x = conv(x) 
    return x

# Basic ResNet Building Block 

def resnet_layer(inputs, 
                 num_filters=16, 
                 kernel_size=3, 
                 strides=1, 
                 activation='relu', 
                 batch_normalization=True, 
    conv=Conv2D(num_filters, 
                  kernel_size=kernel_size, 
                  strides=strides, 
                  padding='same', 
                  kernel_initializer='he_normal', 
                  kernel_regularizer=l2(1e-4)) 

    x=inputs 
    if conv_first: 
        x = conv(x) 
        if batch_normalization: 
            x = BatchNormalization()(x) 
        if activation is not None: 
            x = Activation(activation)(x) 
    else: 
        if batch_normalization: 
            x = BatchNormalization()(x) 
        if activation is not None: 
            x = Activation(activation)(x) 
        x = conv(x) 
    return x

# Basic ResNet Building Block 

def resnet_layer(inputs, 
                 num_filters=16, 
                 kernel_size=3, 
                 strides=1, 
                 activation='relu', 
                 batch_normalization=True, 
    conv=Conv2D(num_filters, 
                  kernel_size=kernel_size, 
                  strides=strides, 
                  padding='same', 
                  kernel_initializer='he_normal', 
                  kernel_regularizer=l2(1e-4)) 

    x=inputs 
    if conv_first: 
        x = conv(x) 
        if batch_normalization: 
            x = BatchNormalization()(x) 
        if activation is not None: 
            x = Activation(activation)(x) 
    else: 
        if batch_normalization: 
            x = BatchNormalization()(x) 
        if activation is not None: 
            x = Activation(activation)(x) 
        x = conv(x) 
    return x

# Basic ResNet Building Block

def resnet_layer(inputs,

num_filters=16,

kernel_size=3,

strides=1,

activation='relu',

batch_normalization=True,

conv=Conv2D(num_filters,

kernel_size=kernel_size,

strides=strides,

padding='same',

kernel_initializer='he_normal',

kernel_regularizer=l2(1e-4))

x=inputs

if conv_first:

x = conv(x)

if batch_normalization:

x = BatchNormalization()(x)

if activation is not None:

x = Activation(activation)(x)

else:

if batch_normalization:

x = BatchNormalization()(x)

if activation is not None:

x = Activation(activation)(x)

x = conv(x)

return x

Step 5: Define ResNet V1 architecture that is based on the ResNet building block we defined above:

Code: ResNet V1 architecture

python3

def resnet_v1(input_shape, depth, num_classes=10): 

    if (depth - 2) % 6 != 0: 
        raise ValueError('depth should be 6n + 2 (eg 20, 32, 44 in [a])') 
    # Start model definition. 
    num_filters = 16
    num_res_blocks = int((depth - 2) / 6) 

    inputs = Input(shape=input_shape) 
    x = resnet_layer(inputs=inputs) 
    # Instantiate the stack of residual units 
    for stack in range(3): 
        for res_block in range(num_res_blocks): 
            strides = 1
            if stack & gt 
            0 and res_block == 0:  # first layer but not first stack 
                strides = 2  # downsample 
            y = resnet_layer(inputs=x, 
                             num_filters=num_filters, 
                             strides=strides) 
            y = resnet_layer(inputs=y, 
                             num_filters=num_filters, 
                             activation=None) 
            if stack & gt 
            0 and res_block == 0:  # first layer but not first stack 
                # linear projection residual shortcut connection to match 
                # changed dims 
                x = resnet_layer(inputs=x, 
                                 num_filters=num_filters, 
                                 kernel_size=1, 
                                 strides=strides, 
                                 activation=None, 
                                 batch_normalization=False) 
            x = keras.layers.add([x, y]) 
            x = Activation('relu')(x) 
        num_filters *= 2

    # Add classifier on top. 
    # v1 does not use BN after last shortcut connection-ReLU 
    x = AveragePooling2D(pool_size=8)(x) 
    y = Flatten()(x) 
    outputs = Dense(num_classes, 
                    activation='softmax', 
                    kernel_initializer='he_normal')(y) 

    # Instantiate model. 
    model = Model(inputs=inputs, outputs=outputs) 
    return model

python3

def resnet_v1(input_shape, depth, num_classes=10): 

    if (depth - 2) % 6 != 0: 
        raise ValueError('depth should be 6n + 2 (eg 20, 32, 44 in [a])') 
    # Start model definition. 
    num_filters = 16
    num_res_blocks = int((depth - 2) / 6) 

    inputs = Input(shape=input_shape) 
    x = resnet_layer(inputs=inputs) 
    # Instantiate the stack of residual units 
    for stack in range(3): 
        for res_block in range(num_res_blocks): 
            strides = 1
            if stack & gt 
            0 and res_block == 0:  # first layer but not first stack 
                strides = 2  # downsample 
            y = resnet_layer(inputs=x, 
                             num_filters=num_filters, 
                             strides=strides) 
            y = resnet_layer(inputs=y, 
                             num_filters=num_filters, 
                             activation=None) 
            if stack & gt 
            0 and res_block == 0:  # first layer but not first stack 
                # linear projection residual shortcut connection to match 
                # changed dims 
                x = resnet_layer(inputs=x, 
                                 num_filters=num_filters, 
                                 kernel_size=1, 
                                 strides=strides, 
                                 activation=None, 
                                 batch_normalization=False) 
            x = keras.layers.add([x, y]) 
            x = Activation('relu')(x) 
        num_filters *= 2

    # Add classifier on top. 
    # v1 does not use BN after last shortcut connection-ReLU 
    x = AveragePooling2D(pool_size=8)(x) 
    y = Flatten()(x) 
    outputs = Dense(num_classes, 
                    activation='softmax', 
                    kernel_initializer='he_normal')(y) 

    # Instantiate model. 
    model = Model(inputs=inputs, outputs=outputs) 
    return model

python3

def resnet_v1(input_shape, depth, num_classes=10): 

    if (depth - 2) % 6 != 0: 
        raise ValueError('depth should be 6n + 2 (eg 20, 32, 44 in [a])') 
    # Start model definition. 
    num_filters = 16
    num_res_blocks = int((depth - 2) / 6) 

    inputs = Input(shape=input_shape) 
    x = resnet_layer(inputs=inputs) 
    # Instantiate the stack of residual units 
    for stack in range(3): 
        for res_block in range(num_res_blocks): 
            strides = 1
            if stack & gt 
            0 and res_block == 0:  # first layer but not first stack 
                strides = 2  # downsample 
            y = resnet_layer(inputs=x, 
                             num_filters=num_filters, 
                             strides=strides) 
            y = resnet_layer(inputs=y, 
                             num_filters=num_filters, 
                             activation=None) 
            if stack & gt 
            0 and res_block == 0:  # first layer but not first stack 
                # linear projection residual shortcut connection to match 
                # changed dims 
                x = resnet_layer(inputs=x, 
                                 num_filters=num_filters, 
                                 kernel_size=1, 
                                 strides=strides, 
                                 activation=None, 
                                 batch_normalization=False) 
            x = keras.layers.add([x, y]) 
            x = Activation('relu')(x) 
        num_filters *= 2

    # Add classifier on top. 
    # v1 does not use BN after last shortcut connection-ReLU 
    x = AveragePooling2D(pool_size=8)(x) 
    y = Flatten()(x) 
    outputs = Dense(num_classes, 
                    activation='softmax', 
                    kernel_initializer='he_normal')(y) 

    # Instantiate model. 
    model = Model(inputs=inputs, outputs=outputs) 
    return model

python3

def resnet_v1(input_shape, depth, num_classes=10): 

    if (depth - 2) % 6 != 0: 
        raise ValueError('depth should be 6n + 2 (eg 20, 32, 44 in [a])') 
    # Start model definition. 
    num_filters = 16
    num_res_blocks = int((depth - 2) / 6) 

    inputs = Input(shape=input_shape) 
    x = resnet_layer(inputs=inputs) 
    # Instantiate the stack of residual units 
    for stack in range(3): 
        for res_block in range(num_res_blocks): 
            strides = 1
            if stack & gt 
            0 and res_block == 0:  # first layer but not first stack 
                strides = 2  # downsample 
            y = resnet_layer(inputs=x, 
                             num_filters=num_filters, 
                             strides=strides) 
            y = resnet_layer(inputs=y, 
                             num_filters=num_filters, 
                             activation=None) 
            if stack & gt 
            0 and res_block == 0:  # first layer but not first stack 
                # linear projection residual shortcut connection to match 
                # changed dims 
                x = resnet_layer(inputs=x, 
                                 num_filters=num_filters, 
                                 kernel_size=1, 
                                 strides=strides, 
                                 activation=None, 
                                 batch_normalization=False) 
            x = keras.layers.add([x, y]) 
            x = Activation('relu')(x) 
        num_filters *= 2

    # Add classifier on top. 
    # v1 does not use BN after last shortcut connection-ReLU 
    x = AveragePooling2D(pool_size=8)(x) 
    y = Flatten()(x) 
    outputs = Dense(num_classes, 
                    activation='softmax', 
                    kernel_initializer='he_normal')(y) 

    # Instantiate model. 
    model = Model(inputs=inputs, outputs=outputs) 
    return model

def resnet_v1(input_shape, depth, num_classes=10): 

    if (depth - 2) % 6 != 0: 
        raise ValueError('depth should be 6n + 2 (eg 20, 32, 44 in [a])') 
    # Start model definition. 
    num_filters = 16
    num_res_blocks = int((depth - 2) / 6) 

    inputs = Input(shape=input_shape) 
    x = resnet_layer(inputs=inputs) 
    # Instantiate the stack of residual units 
    for stack in range(3): 
        for res_block in range(num_res_blocks): 
            strides = 1
            if stack & gt 
            0 and res_block == 0:  # first layer but not first stack 
                strides = 2  # downsample 
            y = resnet_layer(inputs=x, 
                             num_filters=num_filters, 
                             strides=strides) 
            y = resnet_layer(inputs=y, 
                             num_filters=num_filters, 
                             activation=None) 
            if stack & gt 
            0 and res_block == 0:  # first layer but not first stack 
                # linear projection residual shortcut connection to match 
                # changed dims 
                x = resnet_layer(inputs=x, 
                                 num_filters=num_filters, 
                                 kernel_size=1, 
                                 strides=strides, 
                                 activation=None, 
                                 batch_normalization=False) 
            x = keras.layers.add([x, y]) 
            x = Activation('relu')(x) 
        num_filters *= 2

    # Add classifier on top. 
    # v1 does not use BN after last shortcut connection-ReLU 
    x = AveragePooling2D(pool_size=8)(x) 
    y = Flatten()(x) 
    outputs = Dense(num_classes, 
                    activation='softmax', 
                    kernel_initializer='he_normal')(y) 

    # Instantiate model. 
    model = Model(inputs=inputs, outputs=outputs) 
    return model

def resnet_v1(input_shape, depth, num_classes=10): 

    if (depth - 2) % 6 != 0: 
        raise ValueError('depth should be 6n + 2 (eg 20, 32, 44 in [a])') 
    # Start model definition. 
    num_filters = 16
    num_res_blocks = int((depth - 2) / 6) 

    inputs = Input(shape=input_shape) 
    x = resnet_layer(inputs=inputs) 
    # Instantiate the stack of residual units 
    for stack in range(3): 
        for res_block in range(num_res_blocks): 
            strides = 1
            if stack & gt 
            0 and res_block == 0:  # first layer but not first stack 
                strides = 2  # downsample 
            y = resnet_layer(inputs=x, 
                             num_filters=num_filters, 
                             strides=strides) 
            y = resnet_layer(inputs=y, 
                             num_filters=num_filters, 
                             activation=None) 
            if stack & gt 
            0 and res_block == 0:  # first layer but not first stack 
                # linear projection residual shortcut connection to match 
                # changed dims 
                x = resnet_layer(inputs=x, 
                                 num_filters=num_filters, 
                                 kernel_size=1, 
                                 strides=strides, 
                                 activation=None, 
                                 batch_normalization=False) 
            x = keras.layers.add([x, y]) 
            x = Activation('relu')(x) 
        num_filters *= 2

    # Add classifier on top. 
    # v1 does not use BN after last shortcut connection-ReLU 
    x = AveragePooling2D(pool_size=8)(x) 
    y = Flatten()(x) 
    outputs = Dense(num_classes, 
                    activation='softmax', 
                    kernel_initializer='he_normal')(y) 

    # Instantiate model. 
    model = Model(inputs=inputs, outputs=outputs) 
    return model

def resnet_v1(input_shape, depth, num_classes=10): 

    if (depth - 2) % 6 != 0: 
        raise ValueError('depth should be 6n + 2 (eg 20, 32, 44 in [a])') 
    # Start model definition. 
    num_filters = 16
    num_res_blocks = int((depth - 2) / 6) 

    inputs = Input(shape=input_shape) 
    x = resnet_layer(inputs=inputs) 
    # Instantiate the stack of residual units 
    for stack in range(3): 
        for res_block in range(num_res_blocks): 
            strides = 1
            if stack & gt 
            0 and res_block == 0:  # first layer but not first stack 
                strides = 2  # downsample 
            y = resnet_layer(inputs=x, 
                             num_filters=num_filters, 
                             strides=strides) 
            y = resnet_layer(inputs=y, 
                             num_filters=num_filters, 
                             activation=None) 
            if stack & gt 
            0 and res_block == 0:  # first layer but not first stack 
                # linear projection residual shortcut connection to match 
                # changed dims 
                x = resnet_layer(inputs=x, 
                                 num_filters=num_filters, 
                                 kernel_size=1, 
                                 strides=strides, 
                                 activation=None, 
                                 batch_normalization=False) 
            x = keras.layers.add([x, y]) 
            x = Activation('relu')(x) 
        num_filters *= 2

    # Add classifier on top. 
    # v1 does not use BN after last shortcut connection-ReLU 
    x = AveragePooling2D(pool_size=8)(x) 
    y = Flatten()(x) 
    outputs = Dense(num_classes, 
                    activation='softmax', 
                    kernel_initializer='he_normal')(y) 

    # Instantiate model. 
    model = Model(inputs=inputs, outputs=outputs) 
    return model

def resnet_v1(input_shape, depth, num_classes=10): 

    if (depth - 2) % 6 != 0: 
        raise ValueError('depth should be 6n + 2 (eg 20, 32, 44 in [a])') 
    # Start model definition. 
    num_filters = 16
    num_res_blocks = int((depth - 2) / 6) 

    inputs = Input(shape=input_shape) 
    x = resnet_layer(inputs=inputs) 
    # Instantiate the stack of residual units 
    for stack in range(3): 
        for res_block in range(num_res_blocks): 
            strides = 1
            if stack & gt 
            0 and res_block == 0:  # first layer but not first stack 
                strides = 2  # downsample 
            y = resnet_layer(inputs=x, 
                             num_filters=num_filters, 
                             strides=strides) 
            y = resnet_layer(inputs=y, 
                             num_filters=num_filters, 
                             activation=None) 
            if stack & gt 
            0 and res_block == 0:  # first layer but not first stack 
                # linear projection residual shortcut connection to match 
                # changed dims 
                x = resnet_layer(inputs=x, 
                                 num_filters=num_filters, 
                                 kernel_size=1, 
                                 strides=strides, 
                                 activation=None, 
                                 batch_normalization=False) 
            x = keras.layers.add([x, y]) 
            x = Activation('relu')(x) 
        num_filters *= 2

    # Add classifier on top. 
    # v1 does not use BN after last shortcut connection-ReLU 
    x = AveragePooling2D(pool_size=8)(x) 
    y = Flatten()(x) 
    outputs = Dense(num_classes, 
                    activation='softmax', 
                    kernel_initializer='he_normal')(y) 

    # Instantiate model. 
    model = Model(inputs=inputs, outputs=outputs) 
    return model

def resnet_v1(input_shape, depth, num_classes=10):

if (depth - 2) % 6 != 0:

raise ValueError('depth should be 6n + 2 (eg 20, 32, 44 in [a])')

# Start model definition.

num_filters = 16

num_res_blocks = int((depth - 2) / 6)

inputs = Input(shape=input_shape)

x = resnet_layer(inputs=inputs)

# Instantiate the stack of residual units

for stack in range(3):

for res_block in range(num_res_blocks):

strides = 1

if stack & gt

0 and res_block == 0:  # first layer but not first stack

strides = 2  # downsample

y = resnet_layer(inputs=x,

num_filters=num_filters,

strides=strides)

y = resnet_layer(inputs=y,

num_filters=num_filters,

activation=None)

if stack & gt

0 and res_block == 0:  # first layer but not first stack

# linear projection residual shortcut connection to match

# changed dims

x = resnet_layer(inputs=x,

num_filters=num_filters,

kernel_size=1,

strides=strides,

activation=None,

batch_normalization=False)

x = keras.layers.add([x, y])

x = Activation('relu')(x)

num_filters *= 2

# Add classifier on top.

# v1 does not use BN after last shortcut connection-ReLU

x = AveragePooling2D(pool_size=8)(x)

y = Flatten()(x)

outputs = Dense(num_classes,

activation='softmax',

kernel_initializer='he_normal')(y)

# Instantiate model.

model = Model(inputs=inputs, outputs=outputs)

return model

Step 6: Define ResNet V2 architecture that is based on the ResNet building block we defined above:

Code: ResNet V2 architecture

python3

# ResNet V2 architecture 
def resnet_v2(input_shape, depth, num_classes=10): 
    if (depth - 2) % 9 != 0: 
        raise ValueError('depth should be 9n + 2 (eg 56 or 110 in [b])') 
    # Start model definition. 
    num_filters_in = 16
    num_res_blocks = int((depth - 2) / 9) 

    inputs = Input(shape=input_shape) 
    # v2 performs Conv2D with BN-ReLU on input before splitting into 2 paths 
    x = resnet_layer(inputs=inputs, 
                     num_filters=num_filters_in, 
                     conv_first=True) 

    # Instantiate the stack of residual units 
    for stage in range(3): 
        for res_block in range(num_res_blocks): 
            activation = 'relu'
            batch_normalization = True
            strides = 1
            if stage == 0: 
                num_filters_out = num_filters_in * 4
                if res_block == 0:  # first layer and first stage 
                    activation = None
                    batch_normalization = False
            else: 
                num_filters_out = num_filters_in * 2
                if res_block == 0:  # first layer but not first stage 
                    strides = 2    # downsample 

            # bottleneck residual unit 
            y = resnet_layer(inputs=x, 
                             num_filters=num_filters_in, 
                             kernel_size=1, 
                             strides=strides, 
                             activation=activation, 
                             batch_normalization=batch_normalization, 
                             conv_first=False) 
            y = resnet_layer(inputs=y, 
                             num_filters=num_filters_in, 
                             conv_first=False) 
            y = resnet_layer(inputs=y, 
                             num_filters=num_filters_out, 
                             kernel_size=1, 
                             conv_first=False) 
            if res_block == 0: 
                # linear projection residual shortcut connection to match 
                # changed dims 
                x = resnet_layer(inputs=x, 
                                 num_filters=num_filters_out, 
                                 kernel_size=1, 
                                 strides=strides, 
                                 activation=None, 
                                 batch_normalization=False) 
            x = keras.layers.add([x, y]) 

        num_filters_in = num_filters_out 

    # Add classifier on top. 
    # v2 has BN-ReLU before Pooling 
    x = BatchNormalization()(x) 
    x = Activation('relu')(x) 
    x = AveragePooling2D(pool_size=8)(x) 
    y = Flatten()(x) 
    outputs = Dense(num_classes, 
                    activation='softmax', 
                    kernel_initializer='he_normal')(y) 

    # Instantiate model. 
    model = Model(inputs=inputs, outputs=outputs) 
    return model

python3

# ResNet V2 architecture 
def resnet_v2(input_shape, depth, num_classes=10): 
    if (depth - 2) % 9 != 0: 
        raise ValueError('depth should be 9n + 2 (eg 56 or 110 in [b])') 
    # Start model definition. 
    num_filters_in = 16
    num_res_blocks = int((depth - 2) / 9) 

    inputs = Input(shape=input_shape) 
    # v2 performs Conv2D with BN-ReLU on input before splitting into 2 paths 
    x = resnet_layer(inputs=inputs, 
                     num_filters=num_filters_in, 
                     conv_first=True) 

    # Instantiate the stack of residual units 
    for stage in range(3): 
        for res_block in range(num_res_blocks): 
            activation = 'relu'
            batch_normalization = True
            strides = 1
            if stage == 0: 
                num_filters_out = num_filters_in * 4
                if res_block == 0:  # first layer and first stage 
                    activation = None
                    batch_normalization = False
            else: 
                num_filters_out = num_filters_in * 2
                if res_block == 0:  # first layer but not first stage 
                    strides = 2    # downsample 

            # bottleneck residual unit 
            y = resnet_layer(inputs=x, 
                             num_filters=num_filters_in, 
                             kernel_size=1, 
                             strides=strides, 
                             activation=activation, 
                             batch_normalization=batch_normalization, 
                             conv_first=False) 
            y = resnet_layer(inputs=y, 
                             num_filters=num_filters_in, 
                             conv_first=False) 
            y = resnet_layer(inputs=y, 
                             num_filters=num_filters_out, 
                             kernel_size=1, 
                             conv_first=False) 
            if res_block == 0: 
                # linear projection residual shortcut connection to match 
                # changed dims 
                x = resnet_layer(inputs=x, 
                                 num_filters=num_filters_out, 
                                 kernel_size=1, 
                                 strides=strides, 
                                 activation=None, 
                                 batch_normalization=False) 
            x = keras.layers.add([x, y]) 

        num_filters_in = num_filters_out 

    # Add classifier on top. 
    # v2 has BN-ReLU before Pooling 
    x = BatchNormalization()(x) 
    x = Activation('relu')(x) 
    x = AveragePooling2D(pool_size=8)(x) 
    y = Flatten()(x) 
    outputs = Dense(num_classes, 
                    activation='softmax', 
                    kernel_initializer='he_normal')(y) 

    # Instantiate model. 
    model = Model(inputs=inputs, outputs=outputs) 
    return model

python3

# ResNet V2 architecture 
def resnet_v2(input_shape, depth, num_classes=10): 
    if (depth - 2) % 9 != 0: 
        raise ValueError('depth should be 9n + 2 (eg 56 or 110 in [b])') 
    # Start model definition. 
    num_filters_in = 16
    num_res_blocks = int((depth - 2) / 9) 

    inputs = Input(shape=input_shape) 
    # v2 performs Conv2D with BN-ReLU on input before splitting into 2 paths 
    x = resnet_layer(inputs=inputs, 
                     num_filters=num_filters_in, 
                     conv_first=True) 

    # Instantiate the stack of residual units 
    for stage in range(3): 
        for res_block in range(num_res_blocks): 
            activation = 'relu'
            batch_normalization = True
            strides = 1
            if stage == 0: 
                num_filters_out = num_filters_in * 4
                if res_block == 0:  # first layer and first stage 
                    activation = None
                    batch_normalization = False
            else: 
                num_filters_out = num_filters_in * 2
                if res_block == 0:  # first layer but not first stage 
                    strides = 2    # downsample 

            # bottleneck residual unit 
            y = resnet_layer(inputs=x, 
                             num_filters=num_filters_in, 
                             kernel_size=1, 
                             strides=strides, 
                             activation=activation, 
                             batch_normalization=batch_normalization, 
                             conv_first=False) 
            y = resnet_layer(inputs=y, 
                             num_filters=num_filters_in, 
                             conv_first=False) 
            y = resnet_layer(inputs=y, 
                             num_filters=num_filters_out, 
                             kernel_size=1, 
                             conv_first=False) 
            if res_block == 0: 
                # linear projection residual shortcut connection to match 
                # changed dims 
                x = resnet_layer(inputs=x, 
                                 num_filters=num_filters_out, 
                                 kernel_size=1, 
                                 strides=strides, 
                                 activation=None, 
                                 batch_normalization=False) 
            x = keras.layers.add([x, y]) 

        num_filters_in = num_filters_out 

    # Add classifier on top. 
    # v2 has BN-ReLU before Pooling 
    x = BatchNormalization()(x) 
    x = Activation('relu')(x) 
    x = AveragePooling2D(pool_size=8)(x) 
    y = Flatten()(x) 
    outputs = Dense(num_classes, 
                    activation='softmax', 
                    kernel_initializer='he_normal')(y) 

    # Instantiate model. 
    model = Model(inputs=inputs, outputs=outputs) 
    return model

python3

# ResNet V2 architecture 
def resnet_v2(input_shape, depth, num_classes=10): 
    if (depth - 2) % 9 != 0: 
        raise ValueError('depth should be 9n + 2 (eg 56 or 110 in [b])') 
    # Start model definition. 
    num_filters_in = 16
    num_res_blocks = int((depth - 2) / 9) 

    inputs = Input(shape=input_shape) 
    # v2 performs Conv2D with BN-ReLU on input before splitting into 2 paths 
    x = resnet_layer(inputs=inputs, 
                     num_filters=num_filters_in, 
                     conv_first=True) 

    # Instantiate the stack of residual units 
    for stage in range(3): 
        for res_block in range(num_res_blocks): 
            activation = 'relu'
            batch_normalization = True
            strides = 1
            if stage == 0: 
                num_filters_out = num_filters_in * 4
                if res_block == 0:  # first layer and first stage 
                    activation = None
                    batch_normalization = False
            else: 
                num_filters_out = num_filters_in * 2
                if res_block == 0:  # first layer but not first stage 
                    strides = 2    # downsample 

            # bottleneck residual unit 
            y = resnet_layer(inputs=x, 
                             num_filters=num_filters_in, 
                             kernel_size=1, 
                             strides=strides, 
                             activation=activation, 
                             batch_normalization=batch_normalization, 
                             conv_first=False) 
            y = resnet_layer(inputs=y, 
                             num_filters=num_filters_in, 
                             conv_first=False) 
            y = resnet_layer(inputs=y, 
                             num_filters=num_filters_out, 
                             kernel_size=1, 
                             conv_first=False) 
            if res_block == 0: 
                # linear projection residual shortcut connection to match 
                # changed dims 
                x = resnet_layer(inputs=x, 
                                 num_filters=num_filters_out, 
                                 kernel_size=1, 
                                 strides=strides, 
                                 activation=None, 
                                 batch_normalization=False) 
            x = keras.layers.add([x, y]) 

        num_filters_in = num_filters_out 

    # Add classifier on top. 
    # v2 has BN-ReLU before Pooling 
    x = BatchNormalization()(x) 
    x = Activation('relu')(x) 
    x = AveragePooling2D(pool_size=8)(x) 
    y = Flatten()(x) 
    outputs = Dense(num_classes, 
                    activation='softmax', 
                    kernel_initializer='he_normal')(y) 

    # Instantiate model. 
    model = Model(inputs=inputs, outputs=outputs) 
    return model

# ResNet V2 architecture 
def resnet_v2(input_shape, depth, num_classes=10): 
    if (depth - 2) % 9 != 0: 
        raise ValueError('depth should be 9n + 2 (eg 56 or 110 in [b])') 
    # Start model definition. 
    num_filters_in = 16
    num_res_blocks = int((depth - 2) / 9) 

    inputs = Input(shape=input_shape) 
    # v2 performs Conv2D with BN-ReLU on input before splitting into 2 paths 
    x = resnet_layer(inputs=inputs, 
                     num_filters=num_filters_in, 
                     conv_first=True) 

    # Instantiate the stack of residual units 
    for stage in range(3): 
        for res_block in range(num_res_blocks): 
            activation = 'relu'
            batch_normalization = True
            strides = 1
            if stage == 0: 
                num_filters_out = num_filters_in * 4
                if res_block == 0:  # first layer and first stage 
                    activation = None
                    batch_normalization = False
            else: 
                num_filters_out = num_filters_in * 2
                if res_block == 0:  # first layer but not first stage 
                    strides = 2    # downsample 

            # bottleneck residual unit 
            y = resnet_layer(inputs=x, 
                             num_filters=num_filters_in, 
                             kernel_size=1, 
                             strides=strides, 
                             activation=activation, 
                             batch_normalization=batch_normalization, 
                             conv_first=False) 
            y = resnet_layer(inputs=y, 
                             num_filters=num_filters_in, 
                             conv_first=False) 
            y = resnet_layer(inputs=y, 
                             num_filters=num_filters_out, 
                             kernel_size=1, 
                             conv_first=False) 
            if res_block == 0: 
                # linear projection residual shortcut connection to match 
                # changed dims 
                x = resnet_layer(inputs=x, 
                                 num_filters=num_filters_out, 
                                 kernel_size=1, 
                                 strides=strides, 
                                 activation=None, 
                                 batch_normalization=False) 
            x = keras.layers.add([x, y]) 

        num_filters_in = num_filters_out 

    # Add classifier on top. 
    # v2 has BN-ReLU before Pooling 
    x = BatchNormalization()(x) 
    x = Activation('relu')(x) 
    x = AveragePooling2D(pool_size=8)(x) 
    y = Flatten()(x) 
    outputs = Dense(num_classes, 
                    activation='softmax', 
                    kernel_initializer='he_normal')(y) 

    # Instantiate model. 
    model = Model(inputs=inputs, outputs=outputs) 
    return model

# ResNet V2 architecture 
def resnet_v2(input_shape, depth, num_classes=10): 
    if (depth - 2) % 9 != 0: 
        raise ValueError('depth should be 9n + 2 (eg 56 or 110 in [b])') 
    # Start model definition. 
    num_filters_in = 16
    num_res_blocks = int((depth - 2) / 9) 

    inputs = Input(shape=input_shape) 
    # v2 performs Conv2D with BN-ReLU on input before splitting into 2 paths 
    x = resnet_layer(inputs=inputs, 
                     num_filters=num_filters_in, 
                     conv_first=True) 

    # Instantiate the stack of residual units 
    for stage in range(3): 
        for res_block in range(num_res_blocks): 
            activation = 'relu'
            batch_normalization = True
            strides = 1
            if stage == 0: 
                num_filters_out = num_filters_in * 4
                if res_block == 0:  # first layer and first stage 
                    activation = None
                    batch_normalization = False
            else: 
                num_filters_out = num_filters_in * 2
                if res_block == 0:  # first layer but not first stage 
                    strides = 2    # downsample 

            # bottleneck residual unit 
            y = resnet_layer(inputs=x, 
                             num_filters=num_filters_in, 
                             kernel_size=1, 
                             strides=strides, 
                             activation=activation, 
                             batch_normalization=batch_normalization, 
                             conv_first=False) 
            y = resnet_layer(inputs=y, 
                             num_filters=num_filters_in, 
                             conv_first=False) 
            y = resnet_layer(inputs=y, 
                             num_filters=num_filters_out, 
                             kernel_size=1, 
                             conv_first=False) 
            if res_block == 0: 
                # linear projection residual shortcut connection to match 
                # changed dims 
                x = resnet_layer(inputs=x, 
                                 num_filters=num_filters_out, 
                                 kernel_size=1, 
                                 strides=strides, 
                                 activation=None, 
                                 batch_normalization=False) 
            x = keras.layers.add([x, y]) 

        num_filters_in = num_filters_out 

    # Add classifier on top. 
    # v2 has BN-ReLU before Pooling 
    x = BatchNormalization()(x) 
    x = Activation('relu')(x) 
    x = AveragePooling2D(pool_size=8)(x) 
    y = Flatten()(x) 
    outputs = Dense(num_classes, 
                    activation='softmax', 
                    kernel_initializer='he_normal')(y) 

    # Instantiate model. 
    model = Model(inputs=inputs, outputs=outputs) 
    return model

# ResNet V2 architecture 
def resnet_v2(input_shape, depth, num_classes=10): 
    if (depth - 2) % 9 != 0: 
        raise ValueError('depth should be 9n + 2 (eg 56 or 110 in [b])') 
    # Start model definition. 
    num_filters_in = 16
    num_res_blocks = int((depth - 2) / 9) 

    inputs = Input(shape=input_shape) 
    # v2 performs Conv2D with BN-ReLU on input before splitting into 2 paths 
    x = resnet_layer(inputs=inputs, 
                     num_filters=num_filters_in, 
                     conv_first=True) 

    # Instantiate the stack of residual units 
    for stage in range(3): 
        for res_block in range(num_res_blocks): 
            activation = 'relu'
            batch_normalization = True
            strides = 1
            if stage == 0: 
                num_filters_out = num_filters_in * 4
                if res_block == 0:  # first layer and first stage 
                    activation = None
                    batch_normalization = False
            else: 
                num_filters_out = num_filters_in * 2
                if res_block == 0:  # first layer but not first stage 
                    strides = 2    # downsample 

            # bottleneck residual unit 
            y = resnet_layer(inputs=x, 
                             num_filters=num_filters_in, 
                             kernel_size=1, 
                             strides=strides, 
                             activation=activation, 
                             batch_normalization=batch_normalization, 
                             conv_first=False) 
            y = resnet_layer(inputs=y, 
                             num_filters=num_filters_in, 
                             conv_first=False) 
            y = resnet_layer(inputs=y, 
                             num_filters=num_filters_out, 
                             kernel_size=1, 
                             conv_first=False) 
            if res_block == 0: 
                # linear projection residual shortcut connection to match 
                # changed dims 
                x = resnet_layer(inputs=x, 
                                 num_filters=num_filters_out, 
                                 kernel_size=1, 
                                 strides=strides, 
                                 activation=None, 
                                 batch_normalization=False) 
            x = keras.layers.add([x, y]) 

        num_filters_in = num_filters_out 

    # Add classifier on top. 
    # v2 has BN-ReLU before Pooling 
    x = BatchNormalization()(x) 
    x = Activation('relu')(x) 
    x = AveragePooling2D(pool_size=8)(x) 
    y = Flatten()(x) 
    outputs = Dense(num_classes, 
                    activation='softmax', 
                    kernel_initializer='he_normal')(y) 

    # Instantiate model. 
    model = Model(inputs=inputs, outputs=outputs) 
    return model

# ResNet V2 architecture 
def resnet_v2(input_shape, depth, num_classes=10): 
    if (depth - 2) % 9 != 0: 
        raise ValueError('depth should be 9n + 2 (eg 56 or 110 in [b])') 
    # Start model definition. 
    num_filters_in = 16
    num_res_blocks = int((depth - 2) / 9) 

    inputs = Input(shape=input_shape) 
    # v2 performs Conv2D with BN-ReLU on input before splitting into 2 paths 
    x = resnet_layer(inputs=inputs, 
                     num_filters=num_filters_in, 
                     conv_first=True) 

    # Instantiate the stack of residual units 
    for stage in range(3): 
        for res_block in range(num_res_blocks): 
            activation = 'relu'
            batch_normalization = True
            strides = 1
            if stage == 0: 
                num_filters_out = num_filters_in * 4
                if res_block == 0:  # first layer and first stage 
                    activation = None
                    batch_normalization = False
            else: 
                num_filters_out = num_filters_in * 2
                if res_block == 0:  # first layer but not first stage 
                    strides = 2    # downsample 

            # bottleneck residual unit 
            y = resnet_layer(inputs=x, 
                             num_filters=num_filters_in, 
                             kernel_size=1, 
                             strides=strides, 
                             activation=activation, 
                             batch_normalization=batch_normalization, 
                             conv_first=False) 
            y = resnet_layer(inputs=y, 
                             num_filters=num_filters_in, 
                             conv_first=False) 
            y = resnet_layer(inputs=y, 
                             num_filters=num_filters_out, 
                             kernel_size=1, 
                             conv_first=False) 
            if res_block == 0: 
                # linear projection residual shortcut connection to match 
                # changed dims 
                x = resnet_layer(inputs=x, 
                                 num_filters=num_filters_out, 
                                 kernel_size=1, 
                                 strides=strides, 
                                 activation=None, 
                                 batch_normalization=False) 
            x = keras.layers.add([x, y]) 

        num_filters_in = num_filters_out 

    # Add classifier on top. 
    # v2 has BN-ReLU before Pooling 
    x = BatchNormalization()(x) 
    x = Activation('relu')(x) 
    x = AveragePooling2D(pool_size=8)(x) 
    y = Flatten()(x) 
    outputs = Dense(num_classes, 
                    activation='softmax', 
                    kernel_initializer='he_normal')(y) 

    # Instantiate model. 
    model = Model(inputs=inputs, outputs=outputs) 
    return model

# ResNet V2 architecture

def resnet_v2(input_shape, depth, num_classes=10):

if (depth - 2) % 9 != 0:

raise ValueError('depth should be 9n + 2 (eg 56 or 110 in [b])')

# Start model definition.

num_filters_in = 16

num_res_blocks = int((depth - 2) / 9)

inputs = Input(shape=input_shape)

# v2 performs Conv2D with BN-ReLU on input before splitting into 2 paths

x = resnet_layer(inputs=inputs,

num_filters=num_filters_in,

conv_first=True)

# Instantiate the stack of residual units

for stage in range(3):

for res_block in range(num_res_blocks):

activation = 'relu'

batch_normalization = True

strides = 1

if stage == 0:

num_filters_out = num_filters_in * 4

if res_block == 0:  # first layer and first stage

activation = None

batch_normalization = False

else:

num_filters_out = num_filters_in * 2

if res_block == 0:  # first layer but not first stage

strides = 2    # downsample

# bottleneck residual unit

y = resnet_layer(inputs=x,

num_filters=num_filters_in,

kernel_size=1,

strides=strides,

activation=activation,

batch_normalization=batch_normalization,

conv_first=False)

y = resnet_layer(inputs=y,

num_filters=num_filters_in,

conv_first=False)

y = resnet_layer(inputs=y,

num_filters=num_filters_out,

kernel_size=1,

conv_first=False)

if res_block == 0:

# linear projection residual shortcut connection to match

# changed dims

x = resnet_layer(inputs=x,

num_filters=num_filters_out,

kernel_size=1,

strides=strides,

activation=None,

batch_normalization=False)

x = keras.layers.add([x, y])

num_filters_in = num_filters_out

# Add classifier on top.

# v2 has BN-ReLU before Pooling

x = BatchNormalization()(x)

x = Activation('relu')(x)

x = AveragePooling2D(pool_size=8)(x)

y = Flatten()(x)

outputs = Dense(num_classes,

activation='softmax',

kernel_initializer='he_normal')(y)

# Instantiate model.

model = Model(inputs=inputs, outputs=outputs)

return model

Step 7: The code below is used to train and test the ResNet v1 and v2 architecture we defined above:

Code: Main function

python3

# Main function  
if version == 2: 
    model = resnet_v2(input_shape = input_shape, depth = depth) 
else: 
    model = resnet_v1(input_shape = input_shape, depth = depth) 

model.compile(loss ='categorical_crossentropy', 
              optimizer = Adam(learning_rate = lr_schedule(0)), 
              metrics =['accuracy']) 
model.summary() 
print(model_type) 

# Prepare model saving directory. 
save_dir = os.path.join(os.getcwd(), 'saved_models') 
model_name = 'cifar10_% s_model.{epoch:03d}.h5' % model_type 
if not os.path.isdir(save_dir): 
    os.makedirs(save_dir) 
filepath = os.path.join(save_dir, model_name) 

# Prepare callbacks for model saving and for learning rate adjustment. 
checkpoint = ModelCheckpoint(filepath = filepath, 
                             monitor ='val_acc', 
                             verbose = 1, 
                             save_best_only = True) 

lr_scheduler = LearningRateScheduler(lr_schedule) 

lr_reducer = ReduceLROnPlateau(factor = np.sqrt(0.1), 
                               cooldown = 0, 
                               patience = 5, 
                               min_lr = 0.5e-6) 

callbacks = [checkpoint, lr_reducer, lr_scheduler] 

# Run training, with or without data augmentation. 
if not data_augmentation: 
    print('Not using data augmentation.') 
    model.fit(x_train, y_train, 
              batch_size = batch_size, 
              epochs = epochs, 
              validation_data =(x_test, y_test), 
              shuffle = True, 
              callbacks = callbacks) 
else: 
    print('Using real-time data augmentation.') 
    # This will do preprocessing and realtime data augmentation: 
    datagen = ImageDataGenerator( 
        # set input mean to 0 over the dataset 
        featurewise_center = False, 
        # set each sample mean to 0 
        samplewise_center = False, 
        # divide inputs by std of dataset 
        featurewise_std_normalization = False, 
        # divide each input by its std 
        samplewise_std_normalization = False, 
        # apply ZCA whitening 
        zca_whitening = False, 
        # epsilon for ZCA whitening 
        zca_epsilon = 1e-06, 
        # randomly rotate images in the range (deg 0 to 180) 
        rotation_range = 0, 
        # randomly shift images horizontally 
        width_shift_range = 0.1, 
        # randomly shift images vertically 
        height_shift_range = 0.1, 
        # set range for random shear 
        shear_range = 0., 
        # set range for random zoom 
        zoom_range = 0., 
        # set range for random channel shifts 
        channel_shift_range = 0., 
        # set mode for filling points outside the input boundaries 
        fill_mode ='nearest', 
        # value used for fill_mode = "constant" 
        cval = 0., 
        # randomly flip images 
        horizontal_flip = True, 
        # randomly flip images 
        vertical_flip = False, 
        # set rescaling factor (applied before any other transformation) 
        rescale = None, 
        # set function that will be applied on each input 
        preprocessing_function = None, 
        # image data format, either "channels_first" or "channels_last" 
        data_format = None, 
        # fraction of images reserved for validation (strictly between 0 and 1) 
        validation_split = 0.0) 

    # Compute quantities required for featurewise normalization 
    # (std, mean, and principal components if ZCA whitening is applied). 
    datagen.fit(x_train) 

    # Fit the model on the batches generated by datagen.flow(). 
    model.fit_generator(datagen.flow(x_train, y_train, batch_size = batch_size), 
                        validation_data =(x_test, y_test), 
                        epochs = epochs, verbose = 1, workers = 4, 
                        callbacks = callbacks) 

# Score trained model. 
scores = model.evaluate(x_test, y_test, verbose = 1) 
print('Test loss:', scores[0]) 
print('Test accuracy:', scores[1])

python3

# Main function  
if version == 2: 
    model = resnet_v2(input_shape = input_shape, depth = depth) 
else: 
    model = resnet_v1(input_shape = input_shape, depth = depth) 

model.compile(loss ='categorical_crossentropy', 
              optimizer = Adam(learning_rate = lr_schedule(0)), 
              metrics =['accuracy']) 
model.summary() 
print(model_type) 

# Prepare model saving directory. 
save_dir = os.path.join(os.getcwd(), 'saved_models') 
model_name = 'cifar10_% s_model.{epoch:03d}.h5' % model_type 
if not os.path.isdir(save_dir): 
    os.makedirs(save_dir) 
filepath = os.path.join(save_dir, model_name) 

# Prepare callbacks for model saving and for learning rate adjustment. 
checkpoint = ModelCheckpoint(filepath = filepath, 
                             monitor ='val_acc', 
                             verbose = 1, 
                             save_best_only = True) 

lr_scheduler = LearningRateScheduler(lr_schedule) 

lr_reducer = ReduceLROnPlateau(factor = np.sqrt(0.1), 
                               cooldown = 0, 
                               patience = 5, 
                               min_lr = 0.5e-6) 

callbacks = [checkpoint, lr_reducer, lr_scheduler] 

# Run training, with or without data augmentation. 
if not data_augmentation: 
    print('Not using data augmentation.') 
    model.fit(x_train, y_train, 
              batch_size = batch_size, 
              epochs = epochs, 
              validation_data =(x_test, y_test), 
              shuffle = True, 
              callbacks = callbacks) 
else: 
    print('Using real-time data augmentation.') 
    # This will do preprocessing and realtime data augmentation: 
    datagen = ImageDataGenerator( 
        # set input mean to 0 over the dataset 
        featurewise_center = False, 
        # set each sample mean to 0 
        samplewise_center = False, 
        # divide inputs by std of dataset 
        featurewise_std_normalization = False, 
        # divide each input by its std 
        samplewise_std_normalization = False, 
        # apply ZCA whitening 
        zca_whitening = False, 
        # epsilon for ZCA whitening 
        zca_epsilon = 1e-06, 
        # randomly rotate images in the range (deg 0 to 180) 
        rotation_range = 0, 
        # randomly shift images horizontally 
        width_shift_range = 0.1, 
        # randomly shift images vertically 
        height_shift_range = 0.1, 
        # set range for random shear 
        shear_range = 0., 
        # set range for random zoom 
        zoom_range = 0., 
        # set range for random channel shifts 
        channel_shift_range = 0., 
        # set mode for filling points outside the input boundaries 
        fill_mode ='nearest', 
        # value used for fill_mode = "constant" 
        cval = 0., 
        # randomly flip images 
        horizontal_flip = True, 
        # randomly flip images 
        vertical_flip = False, 
        # set rescaling factor (applied before any other transformation) 
        rescale = None, 
        # set function that will be applied on each input 
        preprocessing_function = None, 
        # image data format, either "channels_first" or "channels_last" 
        data_format = None, 
        # fraction of images reserved for validation (strictly between 0 and 1) 
        validation_split = 0.0) 

    # Compute quantities required for featurewise normalization 
    # (std, mean, and principal components if ZCA whitening is applied). 
    datagen.fit(x_train) 

    # Fit the model on the batches generated by datagen.flow(). 
    model.fit_generator(datagen.flow(x_train, y_train, batch_size = batch_size), 
                        validation_data =(x_test, y_test), 
                        epochs = epochs, verbose = 1, workers = 4, 
                        callbacks = callbacks) 

# Score trained model. 
scores = model.evaluate(x_test, y_test, verbose = 1) 
print('Test loss:', scores[0]) 
print('Test accuracy:', scores[1])

python3

# Main function  
if version == 2: 
    model = resnet_v2(input_shape = input_shape, depth = depth) 
else: 
    model = resnet_v1(input_shape = input_shape, depth = depth) 

model.compile(loss ='categorical_crossentropy', 
              optimizer = Adam(learning_rate = lr_schedule(0)), 
              metrics =['accuracy']) 
model.summary() 
print(model_type) 

# Prepare model saving directory. 
save_dir = os.path.join(os.getcwd(), 'saved_models') 
model_name = 'cifar10_% s_model.{epoch:03d}.h5' % model_type 
if not os.path.isdir(save_dir): 
    os.makedirs(save_dir) 
filepath = os.path.join(save_dir, model_name) 

# Prepare callbacks for model saving and for learning rate adjustment. 
checkpoint = ModelCheckpoint(filepath = filepath, 
                             monitor ='val_acc', 
                             verbose = 1, 
                             save_best_only = True) 

lr_scheduler = LearningRateScheduler(lr_schedule) 

lr_reducer = ReduceLROnPlateau(factor = np.sqrt(0.1), 
                               cooldown = 0, 
                               patience = 5, 
                               min_lr = 0.5e-6) 

callbacks = [checkpoint, lr_reducer, lr_scheduler] 

# Run training, with or without data augmentation. 
if not data_augmentation: 
    print('Not using data augmentation.') 
    model.fit(x_train, y_train, 
              batch_size = batch_size, 
              epochs = epochs, 
              validation_data =(x_test, y_test), 
              shuffle = True, 
              callbacks = callbacks) 
else: 
    print('Using real-time data augmentation.') 
    # This will do preprocessing and realtime data augmentation: 
    datagen = ImageDataGenerator( 
        # set input mean to 0 over the dataset 
        featurewise_center = False, 
        # set each sample mean to 0 
        samplewise_center = False, 
        # divide inputs by std of dataset 
        featurewise_std_normalization = False, 
        # divide each input by its std 
        samplewise_std_normalization = False, 
        # apply ZCA whitening 
        zca_whitening = False, 
        # epsilon for ZCA whitening 
        zca_epsilon = 1e-06, 
        # randomly rotate images in the range (deg 0 to 180) 
        rotation_range = 0, 
        # randomly shift images horizontally 
        width_shift_range = 0.1, 
        # randomly shift images vertically 
        height_shift_range = 0.1, 
        # set range for random shear 
        shear_range = 0., 
        # set range for random zoom 
        zoom_range = 0., 
        # set range for random channel shifts 
        channel_shift_range = 0., 
        # set mode for filling points outside the input boundaries 
        fill_mode ='nearest', 
        # value used for fill_mode = "constant" 
        cval = 0., 
        # randomly flip images 
        horizontal_flip = True, 
        # randomly flip images 
        vertical_flip = False, 
        # set rescaling factor (applied before any other transformation) 
        rescale = None, 
        # set function that will be applied on each input 
        preprocessing_function = None, 
        # image data format, either "channels_first" or "channels_last" 
        data_format = None, 
        # fraction of images reserved for validation (strictly between 0 and 1) 
        validation_split = 0.0) 

    # Compute quantities required for featurewise normalization 
    # (std, mean, and principal components if ZCA whitening is applied). 
    datagen.fit(x_train) 

    # Fit the model on the batches generated by datagen.flow(). 
    model.fit_generator(datagen.flow(x_train, y_train, batch_size = batch_size), 
                        validation_data =(x_test, y_test), 
                        epochs = epochs, verbose = 1, workers = 4, 
                        callbacks = callbacks) 

# Score trained model. 
scores = model.evaluate(x_test, y_test, verbose = 1) 
print('Test loss:', scores[0]) 
print('Test accuracy:', scores[1])

# Main function  
if version == 2: 
    model = resnet_v2(input_shape = input_shape, depth = depth) 
else: 
    model = resnet_v1(input_shape = input_shape, depth = depth) 

model.compile(loss ='categorical_crossentropy', 
              optimizer = Adam(learning_rate = lr_schedule(0)), 
              metrics =['accuracy']) 
model.summary() 
print(model_type) 

# Prepare model saving directory. 
save_dir = os.path.join(os.getcwd(), 'saved_models') 
model_name = 'cifar10_% s_model.{epoch:03d}.h5' % model_type 
if not os.path.isdir(save_dir): 
    os.makedirs(save_dir) 
filepath = os.path.join(save_dir, model_name) 

# Prepare callbacks for model saving and for learning rate adjustment. 
checkpoint = ModelCheckpoint(filepath = filepath, 
                             monitor ='val_acc', 
                             verbose = 1, 
                             save_best_only = True) 

lr_scheduler = LearningRateScheduler(lr_schedule) 

lr_reducer = ReduceLROnPlateau(factor = np.sqrt(0.1), 
                               cooldown = 0, 
                               patience = 5, 
                               min_lr = 0.5e-6) 

callbacks = [checkpoint, lr_reducer, lr_scheduler] 

# Run training, with or without data augmentation. 
if not data_augmentation: 
    print('Not using data augmentation.') 
    model.fit(x_train, y_train, 
              batch_size = batch_size, 
              epochs = epochs, 
              validation_data =(x_test, y_test), 
              shuffle = True, 
              callbacks = callbacks) 
else: 
    print('Using real-time data augmentation.') 
    # This will do preprocessing and realtime data augmentation: 
    datagen = ImageDataGenerator( 
        # set input mean to 0 over the dataset 
        featurewise_center = False, 
        # set each sample mean to 0 
        samplewise_center = False, 
        # divide inputs by std of dataset 
        featurewise_std_normalization = False, 
        # divide each input by its std 
        samplewise_std_normalization = False, 
        # apply ZCA whitening 
        zca_whitening = False, 
        # epsilon for ZCA whitening 
        zca_epsilon = 1e-06, 
        # randomly rotate images in the range (deg 0 to 180) 
        rotation_range = 0, 
        # randomly shift images horizontally 
        width_shift_range = 0.1, 
        # randomly shift images vertically 
        height_shift_range = 0.1, 
        # set range for random shear 
        shear_range = 0., 
        # set range for random zoom 
        zoom_range = 0., 
        # set range for random channel shifts 
        channel_shift_range = 0., 
        # set mode for filling points outside the input boundaries 
        fill_mode ='nearest', 
        # value used for fill_mode = "constant" 
        cval = 0., 
        # randomly flip images 
        horizontal_flip = True, 
        # randomly flip images 
        vertical_flip = False, 
        # set rescaling factor (applied before any other transformation) 
        rescale = None, 
        # set function that will be applied on each input 
        preprocessing_function = None, 
        # image data format, either "channels_first" or "channels_last" 
        data_format = None, 
        # fraction of images reserved for validation (strictly between 0 and 1) 
        validation_split = 0.0) 

    # Compute quantities required for featurewise normalization 
    # (std, mean, and principal components if ZCA whitening is applied). 
    datagen.fit(x_train) 

    # Fit the model on the batches generated by datagen.flow(). 
    model.fit_generator(datagen.flow(x_train, y_train, batch_size = batch_size), 
                        validation_data =(x_test, y_test), 
                        epochs = epochs, verbose = 1, workers = 4, 
                        callbacks = callbacks) 

# Score trained model. 
scores = model.evaluate(x_test, y_test, verbose = 1) 
print('Test loss:', scores[0]) 
print('Test accuracy:', scores[1])

# Main function  
if version == 2: 
    model = resnet_v2(input_shape = input_shape, depth = depth) 
else: 
    model = resnet_v1(input_shape = input_shape, depth = depth) 

model.compile(loss ='categorical_crossentropy', 
              optimizer = Adam(learning_rate = lr_schedule(0)), 
              metrics =['accuracy']) 
model.summary() 
print(model_type) 

# Prepare model saving directory. 
save_dir = os.path.join(os.getcwd(), 'saved_models') 
model_name = 'cifar10_% s_model.{epoch:03d}.h5' % model_type 
if not os.path.isdir(save_dir): 
    os.makedirs(save_dir) 
filepath = os.path.join(save_dir, model_name) 

# Prepare callbacks for model saving and for learning rate adjustment. 
checkpoint = ModelCheckpoint(filepath = filepath, 
                             monitor ='val_acc', 
                             verbose = 1, 
                             save_best_only = True) 

lr_scheduler = LearningRateScheduler(lr_schedule) 

lr_reducer = ReduceLROnPlateau(factor = np.sqrt(0.1), 
                               cooldown = 0, 
                               patience = 5, 
                               min_lr = 0.5e-6) 

callbacks = [checkpoint, lr_reducer, lr_scheduler] 

# Run training, with or without data augmentation. 
if not data_augmentation: 
    print('Not using data augmentation.') 
    model.fit(x_train, y_train, 
              batch_size = batch_size, 
              epochs = epochs, 
              validation_data =(x_test, y_test), 
              shuffle = True, 
              callbacks = callbacks) 
else: 
    print('Using real-time data augmentation.') 
    # This will do preprocessing and realtime data augmentation: 
    datagen = ImageDataGenerator( 
        # set input mean to 0 over the dataset 
        featurewise_center = False, 
        # set each sample mean to 0 
        samplewise_center = False, 
        # divide inputs by std of dataset 
        featurewise_std_normalization = False, 
        # divide each input by its std 
        samplewise_std_normalization = False, 
        # apply ZCA whitening 
        zca_whitening = False, 
        # epsilon for ZCA whitening 
        zca_epsilon = 1e-06, 
        # randomly rotate images in the range (deg 0 to 180) 
        rotation_range = 0, 
        # randomly shift images horizontally 
        width_shift_range = 0.1, 
        # randomly shift images vertically 
        height_shift_range = 0.1, 
        # set range for random shear 
        shear_range = 0., 
        # set range for random zoom 
        zoom_range = 0., 
        # set range for random channel shifts 
        channel_shift_range = 0., 
        # set mode for filling points outside the input boundaries 
        fill_mode ='nearest', 
        # value used for fill_mode = "constant" 
        cval = 0., 
        # randomly flip images 
        horizontal_flip = True, 
        # randomly flip images 
        vertical_flip = False, 
        # set rescaling factor (applied before any other transformation) 
        rescale = None, 
        # set function that will be applied on each input 
        preprocessing_function = None, 
        # image data format, either "channels_first" or "channels_last" 
        data_format = None, 
        # fraction of images reserved for validation (strictly between 0 and 1) 
        validation_split = 0.0) 

    # Compute quantities required for featurewise normalization 
    # (std, mean, and principal components if ZCA whitening is applied). 
    datagen.fit(x_train) 

    # Fit the model on the batches generated by datagen.flow(). 
    model.fit_generator(datagen.flow(x_train, y_train, batch_size = batch_size), 
                        validation_data =(x_test, y_test), 
                        epochs = epochs, verbose = 1, workers = 4, 
                        callbacks = callbacks) 

# Score trained model. 
scores = model.evaluate(x_test, y_test, verbose = 1) 
print('Test loss:', scores[0]) 
print('Test accuracy:', scores[1])

# Main function  
if version == 2: 
    model = resnet_v2(input_shape = input_shape, depth = depth) 
else: 
    model = resnet_v1(input_shape = input_shape, depth = depth) 

model.compile(loss ='categorical_crossentropy', 
              optimizer = Adam(learning_rate = lr_schedule(0)), 
              metrics =['accuracy']) 
model.summary() 
print(model_type) 

# Prepare model saving directory. 
save_dir = os.path.join(os.getcwd(), 'saved_models') 
model_name = 'cifar10_% s_model.{epoch:03d}.h5' % model_type 
if not os.path.isdir(save_dir): 
    os.makedirs(save_dir) 
filepath = os.path.join(save_dir, model_name) 

# Prepare callbacks for model saving and for learning rate adjustment. 
checkpoint = ModelCheckpoint(filepath = filepath, 
                             monitor ='val_acc', 
                             verbose = 1, 
                             save_best_only = True) 

lr_scheduler = LearningRateScheduler(lr_schedule) 

lr_reducer = ReduceLROnPlateau(factor = np.sqrt(0.1), 
                               cooldown = 0, 
                               patience = 5, 
                               min_lr = 0.5e-6) 

callbacks = [checkpoint, lr_reducer, lr_scheduler] 

# Run training, with or without data augmentation. 
if not data_augmentation: 
    print('Not using data augmentation.') 
    model.fit(x_train, y_train, 
              batch_size = batch_size, 
              epochs = epochs, 
              validation_data =(x_test, y_test), 
              shuffle = True, 
              callbacks = callbacks) 
else: 
    print('Using real-time data augmentation.') 
    # This will do preprocessing and realtime data augmentation: 
    datagen = ImageDataGenerator( 
        # set input mean to 0 over the dataset 
        featurewise_center = False, 
        # set each sample mean to 0 
        samplewise_center = False, 
        # divide inputs by std of dataset 
        featurewise_std_normalization = False, 
        # divide each input by its std 
        samplewise_std_normalization = False, 
        # apply ZCA whitening 
        zca_whitening = False, 
        # epsilon for ZCA whitening 
        zca_epsilon = 1e-06, 
        # randomly rotate images in the range (deg 0 to 180) 
        rotation_range = 0, 
        # randomly shift images horizontally 
        width_shift_range = 0.1, 
        # randomly shift images vertically 
        height_shift_range = 0.1, 
        # set range for random shear 
        shear_range = 0., 
        # set range for random zoom 
        zoom_range = 0., 
        # set range for random channel shifts 
        channel_shift_range = 0., 
        # set mode for filling points outside the input boundaries 
        fill_mode ='nearest', 
        # value used for fill_mode = "constant" 
        cval = 0., 
        # randomly flip images 
        horizontal_flip = True, 
        # randomly flip images 
        vertical_flip = False, 
        # set rescaling factor (applied before any other transformation) 
        rescale = None, 
        # set function that will be applied on each input 
        preprocessing_function = None, 
        # image data format, either "channels_first" or "channels_last" 
        data_format = None, 
        # fraction of images reserved for validation (strictly between 0 and 1) 
        validation_split = 0.0) 

    # Compute quantities required for featurewise normalization 
    # (std, mean, and principal components if ZCA whitening is applied). 
    datagen.fit(x_train) 

    # Fit the model on the batches generated by datagen.flow(). 
    model.fit_generator(datagen.flow(x_train, y_train, batch_size = batch_size), 
                        validation_data =(x_test, y_test), 
                        epochs = epochs, verbose = 1, workers = 4, 
                        callbacks = callbacks) 

# Score trained model. 
scores = model.evaluate(x_test, y_test, verbose = 1) 
print('Test loss:', scores[0]) 
print('Test accuracy:', scores[1])

# Main function  
if version == 2: 
    model = resnet_v2(input_shape = input_shape, depth = depth) 
else: 
    model = resnet_v1(input_shape = input_shape, depth = depth) 

model.compile(loss ='categorical_crossentropy', 
              optimizer = Adam(learning_rate = lr_schedule(0)), 
              metrics =['accuracy']) 
model.summary() 
print(model_type) 

# Prepare model saving directory. 
save_dir = os.path.join(os.getcwd(), 'saved_models') 
model_name = 'cifar10_% s_model.{epoch:03d}.h5' % model_type 
if not os.path.isdir(save_dir): 
    os.makedirs(save_dir) 
filepath = os.path.join(save_dir, model_name) 

# Prepare callbacks for model saving and for learning rate adjustment. 
checkpoint = ModelCheckpoint(filepath = filepath, 
                             monitor ='val_acc', 
                             verbose = 1, 
                             save_best_only = True) 

lr_scheduler = LearningRateScheduler(lr_schedule) 

lr_reducer = ReduceLROnPlateau(factor = np.sqrt(0.1), 
                               cooldown = 0, 
                               patience = 5, 
                               min_lr = 0.5e-6) 

callbacks = [checkpoint, lr_reducer, lr_scheduler] 

# Run training, with or without data augmentation. 
if not data_augmentation: 
    print('Not using data augmentation.') 
    model.fit(x_train, y_train, 
              batch_size = batch_size, 
              epochs = epochs, 
              validation_data =(x_test, y_test), 
              shuffle = True, 
              callbacks = callbacks) 
else: 
    print('Using real-time data augmentation.') 
    # This will do preprocessing and realtime data augmentation: 
    datagen = ImageDataGenerator( 
        # set input mean to 0 over the dataset 
        featurewise_center = False, 
        # set each sample mean to 0 
        samplewise_center = False, 
        # divide inputs by std of dataset 
        featurewise_std_normalization = False, 
        # divide each input by its std 
        samplewise_std_normalization = False, 
        # apply ZCA whitening 
        zca_whitening = False, 
        # epsilon for ZCA whitening 
        zca_epsilon = 1e-06, 
        # randomly rotate images in the range (deg 0 to 180) 
        rotation_range = 0, 
        # randomly shift images horizontally 
        width_shift_range = 0.1, 
        # randomly shift images vertically 
        height_shift_range = 0.1, 
        # set range for random shear 
        shear_range = 0., 
        # set range for random zoom 
        zoom_range = 0., 
        # set range for random channel shifts 
        channel_shift_range = 0., 
        # set mode for filling points outside the input boundaries 
        fill_mode ='nearest', 
        # value used for fill_mode = "constant" 
        cval = 0., 
        # randomly flip images 
        horizontal_flip = True, 
        # randomly flip images 
        vertical_flip = False, 
        # set rescaling factor (applied before any other transformation) 
        rescale = None, 
        # set function that will be applied on each input 
        preprocessing_function = None, 
        # image data format, either "channels_first" or "channels_last" 
        data_format = None, 
        # fraction of images reserved for validation (strictly between 0 and 1) 
        validation_split = 0.0) 

    # Compute quantities required for featurewise normalization 
    # (std, mean, and principal components if ZCA whitening is applied). 
    datagen.fit(x_train) 

    # Fit the model on the batches generated by datagen.flow(). 
    model.fit_generator(datagen.flow(x_train, y_train, batch_size = batch_size), 
                        validation_data =(x_test, y_test), 
                        epochs = epochs, verbose = 1, workers = 4, 
                        callbacks = callbacks) 

# Score trained model. 
scores = model.evaluate(x_test, y_test, verbose = 1) 
print('Test loss:', scores[0]) 
print('Test accuracy:', scores[1])

# Main function

if version == 2:

model = resnet_v2(input_shape = input_shape, depth = depth)

else:

model = resnet_v1(input_shape = input_shape, depth = depth)

model.compile(loss ='categorical_crossentropy',

optimizer = Adam(learning_rate = lr_schedule(0)),

metrics =['accuracy'])

model.summary()

print(model_type)

# Prepare model saving directory.

save_dir = os.path.join(os.getcwd(), 'saved_models')

model_name = 'cifar10_% s_model.{epoch:03d}.h5' % model_type

if not os.path.isdir(save_dir):

os.makedirs(save_dir)

filepath = os.path.join(save_dir, model_name)

# Prepare callbacks for model saving and for learning rate adjustment.

checkpoint = ModelCheckpoint(filepath = filepath,

monitor ='val_acc',

verbose = 1,

save_best_only = True)

lr_scheduler = LearningRateScheduler(lr_schedule)

lr_reducer = ReduceLROnPlateau(factor = np.sqrt(0.1),

cooldown = 0,

patience = 5,

min_lr = 0.5e-6)

callbacks = [checkpoint, lr_reducer, lr_scheduler]

# Run training, with or without data augmentation.

if not data_augmentation:

print('Not using data augmentation.')

model.fit(x_train, y_train,

batch_size = batch_size,

epochs = epochs,

validation_data =(x_test, y_test),

shuffle = True,

callbacks = callbacks)

else:

print('Using real-time data augmentation.')

# This will do preprocessing and realtime data augmentation:

datagen = ImageDataGenerator(

# set input mean to 0 over the dataset

featurewise_center = False,

# set each sample mean to 0

samplewise_center = False,

# divide inputs by std of dataset

featurewise_std_normalization = False,

# divide each input by its std

samplewise_std_normalization = False,

# apply ZCA whitening

zca_whitening = False,

# epsilon for ZCA whitening

zca_epsilon = 1e-06,

# randomly rotate images in the range (deg 0 to 180)

rotation_range = 0,

# randomly shift images horizontally

width_shift_range = 0.1,

# randomly shift images vertically

height_shift_range = 0.1,

# set range for random shear

shear_range = 0.,

# set range for random zoom

zoom_range = 0.,

# set range for random channel shifts

channel_shift_range = 0.,

# set mode for filling points outside the input boundaries

fill_mode ='nearest',

# value used for fill_mode = "constant"

cval = 0.,

# randomly flip images

horizontal_flip = True,

# randomly flip images

vertical_flip = False,

# set rescaling factor (applied before any other transformation)

rescale = None,

# set function that will be applied on each input

preprocessing_function = None,

# image data format, either "channels_first" or "channels_last"

data_format = None,

# fraction of images reserved for validation (strictly between 0 and 1)

validation_split = 0.0)

# Compute quantities required for featurewise normalization

# (std, mean, and principal components if ZCA whitening is applied).

datagen.fit(x_train)

# Fit the model on the batches generated by datagen.flow().

model.fit_generator(datagen.flow(x_train, y_train, batch_size = batch_size),

validation_data =(x_test, y_test),

epochs = epochs, verbose = 1, workers = 4,

callbacks = callbacks)

# Score trained model.

scores = model.evaluate(x_test, y_test, verbose = 1)

print('Test loss:', scores[0])

print('Test accuracy:', scores[1])

Results & Conclusion: 
On the ImageNet dataset,  the authors uses a 152-layers ResNet, which is 8 times more deep than VGG19 but still have less parameters. An ensemble of these ResNets generated an error of only 3.7% on ImageNet test set, the result which won ILSVRC 2015 competition. On COCO object detection dataset, it also generates a 28% relative improvement due to its very deep representation.

Error-rate on ResNet Architecture

Error-rate on ResNet Architecture

top-1 and top-5 Error rate on ImageNet Validation Set.

top-1 and top-5 Error rate on ImageNet Validation Set.

Are you passionate about data and looking to make one giant leap into your career? Our Data Science Course will help you change your game and, most importantly, allow students, professionals, and working adults to tide over into the data science immersion. Master state-of-the-art methodologies, powerful tools, and industry best practices, hands-on projects, and real-world applications. Become the executive head of industries related to Data Analysis, Machine Learning, and Data Visualization with these growing skills. Ready to Transform Your Future? Enroll Now to Be a Data Science Expert!

Are you passionate about data and looking to make one giant leap into your career? Our Data Science Course will help you change your game and, most importantly, allow students, professionals, and working adults to tide over into the data science immersion. Master state-of-the-art methodologies, powerful tools, and industry best practices, hands-on projects, and real-world applications. Become the executive head of industries related to Data Analysis, Machine Learning, and Data Visualization with these growing skills. Ready to Transform Your Future? Enroll Now to Be a Data Science Expert!

P

pawangfg
12

P

pawangfg

P

pawangfg

P

P

P

pawangfg

Follow

12

12

Previous Article
Detect and Recognize Car License Plate from a video in real time
Next Article
Twitter Sentiment Analysis using Python

Previous Article
Detect and Recognize Car License Plate from a video in real time

Detect and Recognize Car License Plate from a video in real time

Next Article
Twitter Sentiment Analysis using Python

Twitter Sentiment Analysis using Python

Please Login to comment...

Please Login to comment...

Please Login to comment...

Please Login to comment...

Please Login to comment...

Read More

Video | Residual Networks (ResNet) - Deep Learning

Video | Residual Networks (ResNet) - Deep Learning

Video | Residual Networks (ResNet) - Deep Learning

Video | Residual Networks (ResNet) - Deep Learning

Video | Residual Networks (ResNet) - Deep Learning

Similar Reads
Introduction to Residual Networks
Recent years have seen tremendous progress in the field of Image Processing and Recognition. Deep Neural Networks are becoming deeper and more complex. It has been proved that adding more layers to a Neural Network can make it more robust for image-related tasks. But it can also cause them to lose accuracy. That's where Residual Networks come into
3 min read
Deep Belief Network (DBN) in Deep Learning
Discover data creation with Deep Belief Networks (DBNs), cutting-edge generative models that make use of deep architecture. This article walks you through the concepts of DBNs, how they work, and how to implement them using practical coding. What is a Deep Belief Network?Deep Belief Networks (DBNs) are sophisticated artificial neural networks used
9 min read
Deep Boltzmann Machines (DBMs) in Deep Learning
In this article, we will discuss the Deep Boltzmann Machines concepts and their applications in the real-world scenario. What are Deep Boltzmann Machines (DBMs)?Deep Boltzmann Machines (DBMs) are a kind of artificial neural network that belongs to the family of generative models. They are designed to discover intricate structures within large datas
10 min read
Unveiling the Power of Fastai: A Deep Dive into the Versatile Deep Learning Library
Fastai is a powerful deep-learning library designed for researchers and practitioners. It offers high-level abstractions, PyTorch integration, and application-specific APIs, making it both adaptable and accessible for a wide range of deep learning tasks. In this article, we'll delve into the intricacies of Fastai, a powerful deep-learning library.
9 min read
Spiking Neural Networks in Deep Learning
Spiking Neural Networks (SNNs) represent a novel approach in artificial neural networks, inspired by the biological processes of the human brain. Unlike traditional artificial neural networks (ANNs) that rely on continuous signal processing, SNNs operate on discrete events called "spikes." The aim of this article is to provide an in-depth understan
10 min read
Introduction to Multi-Task Learning(MTL) for Deep Learning
Multi-Task Learning (MTL) is a type of machine learning technique where a model is trained to perform multiple tasks simultaneously. In deep learning, MTL refers to training a neural network to perform multiple tasks by sharing some of the network's layers and parameters across tasks. In MTL, the goal is to improve the generalization performance of
6 min read
Artificial intelligence vs Machine Learning vs Deep Learning
Nowadays many misconceptions are there related to the words machine learning, deep learning, and artificial intelligence (AI), most people think all these things are the same whenever they hear the word AI, they directly relate that word to machine learning or vice versa, well yes, these things are related to each other but not the same. Let's see
4 min read
Need of Data Structures and Algorithms for Deep Learning and Machine Learning
Deep Learning is a field that is heavily based on Mathematics and you need to have a good understanding of Data Structures and Algorithms to solve the mathematical problems optimally. Data Structures and Algorithms can be used to determine how a problem is represented internally or how the actual storage pattern works &amp; what is happening under
6 min read
Difference Between Artificial Intelligence vs Machine Learning vs Deep Learning
Artificial Intelligence is basically the mechanism to incorporate human intelligence into machines through a set of rules(algorithm). AI is a combination of two words: "Artificial" meaning something made by humans or non-natural things and "Intelligence" meaning the ability to understand or think accordingly. Another definition could be that "AI is
14 min read
Difference Between Machine Learning and Deep Learning
If you are interested in building your career in the IT industry then you must have come across the term Data Science which is a booming field in terms of technologies and job availability as well. In this article, we will explore the Difference between Machine Learning and Deep Learning, two major fields within Data Science. Understanding these di
8 min read

Similar Reads

Introduction to Residual Networks
Recent years have seen tremendous progress in the field of Image Processing and Recognition. Deep Neural Networks are becoming deeper and more complex. It has been proved that adding more layers to a Neural Network can make it more robust for image-related tasks. But it can also cause them to lose accuracy. That's where Residual Networks come into
3 min read
Deep Belief Network (DBN) in Deep Learning
Discover data creation with Deep Belief Networks (DBNs), cutting-edge generative models that make use of deep architecture. This article walks you through the concepts of DBNs, how they work, and how to implement them using practical coding. What is a Deep Belief Network?Deep Belief Networks (DBNs) are sophisticated artificial neural networks used
9 min read
Deep Boltzmann Machines (DBMs) in Deep Learning
In this article, we will discuss the Deep Boltzmann Machines concepts and their applications in the real-world scenario. What are Deep Boltzmann Machines (DBMs)?Deep Boltzmann Machines (DBMs) are a kind of artificial neural network that belongs to the family of generative models. They are designed to discover intricate structures within large datas
10 min read
Unveiling the Power of Fastai: A Deep Dive into the Versatile Deep Learning Library
Fastai is a powerful deep-learning library designed for researchers and practitioners. It offers high-level abstractions, PyTorch integration, and application-specific APIs, making it both adaptable and accessible for a wide range of deep learning tasks. In this article, we'll delve into the intricacies of Fastai, a powerful deep-learning library.
9 min read
Spiking Neural Networks in Deep Learning
Spiking Neural Networks (SNNs) represent a novel approach in artificial neural networks, inspired by the biological processes of the human brain. Unlike traditional artificial neural networks (ANNs) that rely on continuous signal processing, SNNs operate on discrete events called "spikes." The aim of this article is to provide an in-depth understan
10 min read
Introduction to Multi-Task Learning(MTL) for Deep Learning
Multi-Task Learning (MTL) is a type of machine learning technique where a model is trained to perform multiple tasks simultaneously. In deep learning, MTL refers to training a neural network to perform multiple tasks by sharing some of the network's layers and parameters across tasks. In MTL, the goal is to improve the generalization performance of
6 min read
Artificial intelligence vs Machine Learning vs Deep Learning
Nowadays many misconceptions are there related to the words machine learning, deep learning, and artificial intelligence (AI), most people think all these things are the same whenever they hear the word AI, they directly relate that word to machine learning or vice versa, well yes, these things are related to each other but not the same. Let's see
4 min read
Need of Data Structures and Algorithms for Deep Learning and Machine Learning
Deep Learning is a field that is heavily based on Mathematics and you need to have a good understanding of Data Structures and Algorithms to solve the mathematical problems optimally. Data Structures and Algorithms can be used to determine how a problem is represented internally or how the actual storage pattern works &amp; what is happening under
6 min read
Difference Between Artificial Intelligence vs Machine Learning vs Deep Learning
Artificial Intelligence is basically the mechanism to incorporate human intelligence into machines through a set of rules(algorithm). AI is a combination of two words: "Artificial" meaning something made by humans or non-natural things and "Intelligence" meaning the ability to understand or think accordingly. Another definition could be that "AI is
14 min read
Difference Between Machine Learning and Deep Learning
If you are interested in building your career in the IT industry then you must have come across the term Data Science which is a booming field in terms of technologies and job availability as well. In this article, we will explore the Difference between Machine Learning and Deep Learning, two major fields within Data Science. Understanding these di
8 min read

Introduction to Residual Networks
Recent years have seen tremendous progress in the field of Image Processing and Recognition. Deep Neural Networks are becoming deeper and more complex. It has been proved that adding more layers to a Neural Network can make it more robust for image-related tasks. But it can also cause them to lose accuracy. That's where Residual Networks come into

Introduction to Residual Networks

Recent years have seen tremendous progress in the field of Image Processing and Recognition. Deep Neural Networks are becoming deeper and more complex. It has been proved that adding more layers to a Neural Network can make it more robust for image-related tasks. But it can also cause them to lose accuracy. That's where Residual Networks come into

3 min read

Deep Belief Network (DBN) in Deep Learning
Discover data creation with Deep Belief Networks (DBNs), cutting-edge generative models that make use of deep architecture. This article walks you through the concepts of DBNs, how they work, and how to implement them using practical coding. What is a Deep Belief Network?Deep Belief Networks (DBNs) are sophisticated artificial neural networks used

Deep Belief Network (DBN) in Deep Learning

Discover data creation with Deep Belief Networks (DBNs), cutting-edge generative models that make use of deep architecture. This article walks you through the concepts of DBNs, how they work, and how to implement them using practical coding. What is a Deep Belief Network?Deep Belief Networks (DBNs) are sophisticated artificial neural networks used

9 min read

Deep Boltzmann Machines (DBMs) in Deep Learning
In this article, we will discuss the Deep Boltzmann Machines concepts and their applications in the real-world scenario. What are Deep Boltzmann Machines (DBMs)?Deep Boltzmann Machines (DBMs) are a kind of artificial neural network that belongs to the family of generative models. They are designed to discover intricate structures within large datas

Deep Boltzmann Machines (DBMs) in Deep Learning

In this article, we will discuss the Deep Boltzmann Machines concepts and their applications in the real-world scenario. What are Deep Boltzmann Machines (DBMs)?Deep Boltzmann Machines (DBMs) are a kind of artificial neural network that belongs to the family of generative models. They are designed to discover intricate structures within large datas

10 min read

Unveiling the Power of Fastai: A Deep Dive into the Versatile Deep Learning Library
Fastai is a powerful deep-learning library designed for researchers and practitioners. It offers high-level abstractions, PyTorch integration, and application-specific APIs, making it both adaptable and accessible for a wide range of deep learning tasks. In this article, we'll delve into the intricacies of Fastai, a powerful deep-learning library.

Unveiling the Power of Fastai: A Deep Dive into the Versatile Deep Learning Library

Fastai is a powerful deep-learning library designed for researchers and practitioners. It offers high-level abstractions, PyTorch integration, and application-specific APIs, making it both adaptable and accessible for a wide range of deep learning tasks. In this article, we'll delve into the intricacies of Fastai, a powerful deep-learning library.

9 min read

Spiking Neural Networks in Deep Learning
Spiking Neural Networks (SNNs) represent a novel approach in artificial neural networks, inspired by the biological processes of the human brain. Unlike traditional artificial neural networks (ANNs) that rely on continuous signal processing, SNNs operate on discrete events called "spikes." The aim of this article is to provide an in-depth understan

Spiking Neural Networks in Deep Learning

Spiking Neural Networks (SNNs) represent a novel approach in artificial neural networks, inspired by the biological processes of the human brain. Unlike traditional artificial neural networks (ANNs) that rely on continuous signal processing, SNNs operate on discrete events called "spikes." The aim of this article is to provide an in-depth understan

10 min read

Introduction to Multi-Task Learning(MTL) for Deep Learning
Multi-Task Learning (MTL) is a type of machine learning technique where a model is trained to perform multiple tasks simultaneously. In deep learning, MTL refers to training a neural network to perform multiple tasks by sharing some of the network's layers and parameters across tasks. In MTL, the goal is to improve the generalization performance of

Introduction to Multi-Task Learning(MTL) for Deep Learning

Multi-Task Learning (MTL) is a type of machine learning technique where a model is trained to perform multiple tasks simultaneously. In deep learning, MTL refers to training a neural network to perform multiple tasks by sharing some of the network's layers and parameters across tasks. In MTL, the goal is to improve the generalization performance of

6 min read

Artificial intelligence vs Machine Learning vs Deep Learning
Nowadays many misconceptions are there related to the words machine learning, deep learning, and artificial intelligence (AI), most people think all these things are the same whenever they hear the word AI, they directly relate that word to machine learning or vice versa, well yes, these things are related to each other but not the same. Let's see

Artificial intelligence vs Machine Learning vs Deep Learning

Nowadays many misconceptions are there related to the words machine learning, deep learning, and artificial intelligence (AI), most people think all these things are the same whenever they hear the word AI, they directly relate that word to machine learning or vice versa, well yes, these things are related to each other but not the same. Let's see

4 min read

Need of Data Structures and Algorithms for Deep Learning and Machine Learning
Deep Learning is a field that is heavily based on Mathematics and you need to have a good understanding of Data Structures and Algorithms to solve the mathematical problems optimally. Data Structures and Algorithms can be used to determine how a problem is represented internally or how the actual storage pattern works &amp; what is happening under

Need of Data Structures and Algorithms for Deep Learning and Machine Learning

Deep Learning is a field that is heavily based on Mathematics and you need to have a good understanding of Data Structures and Algorithms to solve the mathematical problems optimally. Data Structures and Algorithms can be used to determine how a problem is represented internally or how the actual storage pattern works &amp; what is happening under

6 min read

Difference Between Artificial Intelligence vs Machine Learning vs Deep Learning
Artificial Intelligence is basically the mechanism to incorporate human intelligence into machines through a set of rules(algorithm). AI is a combination of two words: "Artificial" meaning something made by humans or non-natural things and "Intelligence" meaning the ability to understand or think accordingly. Another definition could be that "AI is

Difference Between Artificial Intelligence vs Machine Learning vs Deep Learning

Artificial Intelligence is basically the mechanism to incorporate human intelligence into machines through a set of rules(algorithm). AI is a combination of two words: "Artificial" meaning something made by humans or non-natural things and "Intelligence" meaning the ability to understand or think accordingly. Another definition could be that "AI is

14 min read

Difference Between Machine Learning and Deep Learning
If you are interested in building your career in the IT industry then you must have come across the term Data Science which is a booming field in terms of technologies and job availability as well. In this article, we will explore the Difference between Machine Learning and Deep Learning, two major fields within Data Science. Understanding these di

Difference Between Machine Learning and Deep Learning

If you are interested in building your career in the IT industry then you must have come across the term Data Science which is a booming field in terms of technologies and job availability as well. In this article, we will explore the Difference between Machine Learning and Deep Learning, two major fields within Data Science. Understanding these di

8 min read

Residual Leverage Plot (Regression Diagnostic)
                In linear or multiple regression, it is not enough to just fit the model into the dataset. But, it may not give the desired result. To apply the linear or multiple regression efficiently to the dataset. There are some assumptions that we need to check on the dataset that made linear/multiple regression efficient and generate better accuracy. Assump

Residual Leverage Plot (Regression Diagnostic)

In linear or multiple regression, it is not enough to just fit the model into the dataset. But, it may not give the desired result. To apply the linear or multiple regression efficiently to the dataset. There are some assumptions that we need to check on the dataset that made linear/multiple regression efficient and generate better accuracy. Assump

5 min read

Residual plots for Nonlinear Regression
                Nonlinear regression is a form of regression analysis where data is fit to a model expressed as a nonlinear function. Unlike linear regression, where the relationship between the independent and dependent variables is linear, nonlinear regression involves more complex relationships. One of the critical tools in evaluating the fit of a nonlinear reg

Residual plots for Nonlinear Regression

Nonlinear regression is a form of regression analysis where data is fit to a model expressed as a nonlinear function. Unlike linear regression, where the relationship between the independent and dependent variables is linear, nonlinear regression involves more complex relationships. One of the critical tools in evaluating the fit of a nonlinear reg

4 min read

How to Calculate Residual Sum of Squares in Python
                The residual sum of squares (RSS) calculates the degree of variance in a regression model. It estimates the level of error in the model's prediction. The smaller the residual sum of squares, the better your model fits your data; the larger the residual sum of squares, the worse. It is the sum of squares of the observed data minus the predicted data

How to Calculate Residual Sum of Squares in Python

The residual sum of squares (RSS) calculates the degree of variance in a regression model. It estimates the level of error in the model's prediction. The smaller the residual sum of squares, the better your model fits your data; the larger the residual sum of squares, the worse. It is the sum of squares of the observed data minus the predicted data

2 min read

DeepPose: Human Pose Estimation via Deep Neural Networks
                DeepPose was proposed by researchers at Google for Pose Estimation in the 2014 Computer Vision and Pattern Recognition conference. They work on formulating the pose Estimation problem as a DNN-based regression problem towards body joints. They present a cascade of DNN-regressors which resulted in high precision pose estimates.. Architecture: Pose V

DeepPose: Human Pose Estimation via Deep Neural Networks

DeepPose was proposed by researchers at Google for Pose Estimation in the 2014 Computer Vision and Pattern Recognition conference. They work on formulating the pose Estimation problem as a DNN-based regression problem towards body joints. They present a cascade of DNN-regressors which resulted in high precision pose estimates.. Architecture: Pose V

5 min read

Episodic Memory and Deep Q-Networks
                Episodic Memory: Episodic Memory is a category of long-term memory that involves recent recollection of specific events, situations, and experiences. For Example Your first day at college. There are two important aspects of episodic memory are Pattern Separation and Pattern Completion. Semantic Memory is used in many ways in machine learning such a

Episodic Memory and Deep Q-Networks

Episodic Memory: Episodic Memory is a category of long-term memory that involves recent recollection of specific events, situations, and experiences. For Example Your first day at college. There are two important aspects of episodic memory are Pattern Separation and Pattern Completion. Semantic Memory is used in many ways in machine learning such a

7 min read

Weight Initialization Techniques for Deep Neural Networks
                While building and training neural networks, it is crucial to initialize the weights appropriately to ensure a model with high accuracy. If the weights are not correctly initialized, it may give rise to the Vanishing Gradient problem or the Exploding Gradient problem. Hence, selecting an appropriate weight initialization strategy is critical when t

Weight Initialization Techniques for Deep Neural Networks

While building and training neural networks, it is crucial to initialize the weights appropriately to ensure a model with high accuracy. If the weights are not correctly initialized, it may give rise to the Vanishing Gradient problem or the Exploding Gradient problem. Hence, selecting an appropriate weight initialization strategy is critical when t

5 min read

Optimization Rule in Deep Neural Networks
                In machine learning, optimizers and loss functions are two components that help improve the performance of the model. By calculating the difference between the expected and actual outputs of a model, a loss function evaluates the effectiveness of a model. Among the loss functions are log loss, hinge loss, and mean square loss. By modifying the mode

Optimization Rule in Deep Neural Networks

In machine learning, optimizers and loss functions are two components that help improve the performance of the model. By calculating the difference between the expected and actual outputs of a model, a loss function evaluates the effectiveness of a model. Among the loss functions are log loss, hinge loss, and mean square loss. By modifying the mode

13 min read

Bagging vs Dropout in Deep Neural Networks
                Answer: Bagging involves training multiple models on different subsets of the training data, while dropout randomly drops units (along with their connections) from the neural network during training.Bagging (Bootstrap Aggregating):Bagging is an ensemble learning technique that involves training multiple models independently on different subsets of

Bagging vs Dropout in Deep Neural Networks

Answer: Bagging involves training multiple models on different subsets of the training data, while dropout randomly drops units (along with their connections) from the neural network during training.Bagging (Bootstrap Aggregating):Bagging is an ensemble learning technique that involves training multiple models independently on different subsets of

3 min read

Difference between Shallow and Deep Neural Networks
                Neural networks have become a cornerstone of modern machine learning, with their ability to model complex patterns and relationships in data. They are inspired by the human brain and consist of interconnected nodes or neurons arranged in layers. Neural networks can be broadly categorized into two types: shallow neural networks (SNNs) and deep neura

Difference between Shallow and Deep Neural Networks

Neural networks have become a cornerstone of modern machine learning, with their ability to model complex patterns and relationships in data. They are inspired by the human brain and consist of interconnected nodes or neurons arranged in layers. Neural networks can be broadly categorized into two types: shallow neural networks (SNNs) and deep neura

6 min read

The Role of Neural Networks in DeepMind’s Success: A Technical Deep Dive
                DeepMind, a trailblazer in artificial intelligence research, has achieved remarkable success in a range of domains, from mastering complex games to advancing healthcare. At the core of DeepMind’s achievements lies the strategic use of neural networks. These computational models, inspired by the human brain’s structure and function, have been pivota

The Role of Neural Networks in DeepMind’s Success: A Technical Deep Dive

DeepMind, a trailblazer in artificial intelligence research, has achieved remarkable success in a range of domains, from mastering complex games to advancing healthcare. At the core of DeepMind’s achievements lies the strategic use of neural networks. These computational models, inspired by the human brain’s structure and function, have been pivota

6 min read

Signed Networks in Social Networks
                Prerequisite: Introduction to Social Networks In Social Networks, Network is of 2 types- Unsigned Network and Signed Network. In the unsigned network, there are no signs between any nodes, and in the signed network, there is always a sign between 2 nodes either + or -. The '+' sign indicates friendship between 2 nodes and the '-' sign indicates enm

Signed Networks in Social Networks

Prerequisite: Introduction to Social Networks In Social Networks, Network is of 2 types- Unsigned Network and Signed Network. In the unsigned network, there are no signs between any nodes, and in the signed network, there is always a sign between 2 nodes either + or -. The '+' sign indicates friendship between 2 nodes and the '-' sign indicates enm

4 min read

Differences Between Bayesian Networks and Neural Networks
                Bayesian networks and neural networks are two distinct types of graphical models used in machine learning and artificial intelligence. While both models are designed to handle complex data and make predictions, they differ significantly in their theoretical foundations, operational mechanisms, and applications. This article will delve into the diff

Differences Between Bayesian Networks and Neural Networks

Bayesian networks and neural networks are two distinct types of graphical models used in machine learning and artificial intelligence. While both models are designed to handle complex data and make predictions, they differ significantly in their theoretical foundations, operational mechanisms, and applications. This article will delve into the diff

9 min read

ML | Natural Language Processing using Deep Learning
                Machine Comprehension is a very interesting but challenging task in both Natural Language Processing (NLP) and artificial intelligence (AI) research. There are several approaches to natural language processing tasks. With recent breakthroughs in deep learning algorithms, hardware, and user-friendly APIs like TensorFlow, some tasks have become feasi

ML | Natural Language Processing using Deep Learning

Machine Comprehension is a very interesting but challenging task in both Natural Language Processing (NLP) and artificial intelligence (AI) research. There are several approaches to natural language processing tasks. With recent breakthroughs in deep learning algorithms, hardware, and user-friendly APIs like TensorFlow, some tasks have become feasi

9 min read

Deep Learning with PyTorch | An Introduction
                PyTorch in a lot of ways behaves like the arrays we love from Numpy. These Numpy arrays, after all, are just tensors. PyTorch takes these tensors and makes it simple to move them to GPUs for the faster processing needed when training neural networks. It also provides a module that automatically calculates gradients (for backpropagation) and another

Deep Learning with PyTorch | An Introduction

PyTorch in a lot of ways behaves like the arrays we love from Numpy. These Numpy arrays, after all, are just tensors. PyTorch takes these tensors and makes it simple to move them to GPUs for the faster processing needed when training neural networks. It also provides a module that automatically calculates gradients (for backpropagation) and another

7 min read

Avengers Endgame and Deep learning | Image Caption Generation using the Avengers EndGames Characters
                Behold, Marvel Fans. Avengers are out there to save the Multiverse, so are we, ready to do whatever it takes to support them. In this article, we will use Deep Learning and computer vision for the caption generation of Avengers Endgame characters. We will start will the basics, explaining concepts and use a pre-trained model to implement the projec

Avengers Endgame and Deep learning | Image Caption Generation using the Avengers EndGames Characters

Behold, Marvel Fans. Avengers are out there to save the Multiverse, so are we, ready to do whatever it takes to support them. In this article, we will use Deep Learning and computer vision for the caption generation of Avengers Endgame characters. We will start will the basics, explaining concepts and use a pre-trained model to implement the projec

14 min read

Deep Q-Learning
                Q-Learning is required as a pre-requisite as it is a process of Q-Learning creates an exact matrix for the working agent which it can "refer to" to maximize its reward in the long run. Although this approach is not wrong in itself, this is only practical for very small environments and quickly loses it's feasibility when the number of states and ac

Deep Q-Learning

Q-Learning is required as a pre-requisite as it is a process of Q-Learning creates an exact matrix for the working agent which it can "refer to" to maximize its reward in the long run. Although this approach is not wrong in itself, this is only practical for very small environments and quickly loses it's feasibility when the number of states and ac

4 min read

Implementing Deep Q-Learning using Tensorflow
                Prerequisites: Deep Q-Learning This article will demonstrate how to do reinforcement learning on a larger environment than previously demonstrated. We will be implementing Deep Q-Learning technique using Tensorflow. Note: A graphics rendering library is required for the following demonstration. For Windows operating system, PyOpenGl is suggested wh

Implementing Deep Q-Learning using Tensorflow

Prerequisites: Deep Q-Learning This article will demonstrate how to do reinforcement learning on a larger environment than previously demonstrated. We will be implementing Deep Q-Learning technique using Tensorflow. Note: A graphics rendering library is required for the following demonstration. For Windows operating system, PyOpenGl is suggested wh

4 min read

Differential Privacy and Deep Learning
                Differential privacy is a new topic in the field of deep learning. It is about ensuring that when our neural networks are learning from sensitive data, they're only learning what they're supposed to learn from the data. Differential privacy is a concept in privacy-preserving data analysis that aims to protect the privacy of individuals while still

Differential Privacy and Deep Learning

Differential privacy is a new topic in the field of deep learning. It is about ensuring that when our neural networks are learning from sensitive data, they're only learning what they're supposed to learn from the data. Differential privacy is a concept in privacy-preserving data analysis that aims to protect the privacy of individuals while still

6 min read

Human Activity Recognition - Using Deep Learning Model
                Human activity recognition using smartphone sensors like accelerometer is one of the hectic topics of research. HAR is one of the time series classification problem. In this project various machine learning and deep learning models have been worked out to get the best final result. In the same sequence, we can use LSTM (long short term memory) mode

Human Activity Recognition - Using Deep Learning Model

Human activity recognition using smartphone sensors like accelerometer is one of the hectic topics of research. HAR is one of the time series classification problem. In this project various machine learning and deep learning models have been worked out to get the best final result. In the same sequence, we can use LSTM (long short term memory) mode

6 min read

ML - Saving a Deep Learning model in Keras
                Training a neural network/deep learning model usually takes a lot of time, particularly if the hardware capacity of the system doesn't match up to the requirement. Once the training is done, we save the model to a file. To reuse the model at a later point of time to make predictions, we load the saved model. Through Keras, models can be saved in th

ML - Saving a Deep Learning model in Keras

Training a neural network/deep learning model usually takes a lot of time, particularly if the hardware capacity of the system doesn't match up to the requirement. Once the training is done, we save the model to a file. To reuse the model at a later point of time to make predictions, we load the saved model. Through Keras, models can be saved in th

2 min read

Article Tags :
AI-ML-DS
Deep Learning
Machine Learning
AI-ML-DS With Python
+1 More
Practice Tags :
Machine Learning
python

Article Tags :
AI-ML-DS
Deep Learning
Machine Learning
AI-ML-DS With Python
+1 More

Article Tags :

Practice Tags :
Machine Learning
python

Practice Tags :

Like
                                        12

288k+ interested Geeks
Data Structures & Algorithms in Python - Self Paced
Explore
203k+ interested Geeks
Python Full Course Online - Complete Beginner to Advanced
Explore
312k+ interested Geeks
Complete Machine Learning & Data Science Program
Explore

288k+ interested Geeks
Data Structures & Algorithms in Python - Self Paced
Explore
203k+ interested Geeks
Python Full Course Online - Complete Beginner to Advanced
Explore
312k+ interested Geeks
Complete Machine Learning & Data Science Program
Explore

288k+ interested Geeks
Data Structures & Algorithms in Python - Self Paced
Explore
203k+ interested Geeks
Python Full Course Online - Complete Beginner to Advanced
Explore
312k+ interested Geeks
Complete Machine Learning & Data Science Program
Explore

288k+ interested Geeks
Data Structures & Algorithms in Python - Self Paced
Explore
203k+ interested Geeks
Python Full Course Online - Complete Beginner to Advanced
Explore
312k+ interested Geeks
Complete Machine Learning & Data Science Program
Explore

288k+ interested Geeks
Data Structures & Algorithms in Python - Self Paced
Explore
203k+ interested Geeks
Python Full Course Online - Complete Beginner to Advanced
Explore
312k+ interested Geeks
Complete Machine Learning & Data Science Program
Explore

288k+ interested Geeks
Data Structures & Algorithms in Python - Self Paced
Explore
203k+ interested Geeks
Python Full Course Online - Complete Beginner to Advanced
Explore
312k+ interested Geeks
Complete Machine Learning & Data Science Program
Explore

288k+ interested Geeks
Data Structures & Algorithms in Python - Self Paced
Explore
203k+ interested Geeks
Python Full Course Online - Complete Beginner to Advanced
Explore
312k+ interested Geeks
Complete Machine Learning & Data Science Program
Explore

288k+ interested Geeks
Data Structures & Algorithms in Python - Self Paced
Explore
203k+ interested Geeks
Python Full Course Online - Complete Beginner to Advanced
Explore
312k+ interested Geeks
Complete Machine Learning & Data Science Program
Explore

288k+ interested Geeks
Data Structures & Algorithms in Python - Self Paced
Explore

288k+ interested Geeks
Data Structures & Algorithms in Python - Self Paced
Explore

288k+ interested Geeks
Data Structures & Algorithms in Python - Self Paced
Explore

288k+ interested Geeks
Data Structures & Algorithms in Python - Self Paced
Explore

288k+ interested Geeks

288k+ interested Geeks

Data Structures & Algorithms in Python - Self Paced

Explore

Explore

203k+ interested Geeks
Python Full Course Online - Complete Beginner to Advanced
Explore

203k+ interested Geeks
Python Full Course Online - Complete Beginner to Advanced
Explore

203k+ interested Geeks
Python Full Course Online - Complete Beginner to Advanced
Explore

203k+ interested Geeks
Python Full Course Online - Complete Beginner to Advanced
Explore

203k+ interested Geeks

203k+ interested Geeks

Python Full Course Online - Complete Beginner to Advanced

Explore

Explore

312k+ interested Geeks
Complete Machine Learning & Data Science Program
Explore

312k+ interested Geeks
Complete Machine Learning & Data Science Program
Explore

312k+ interested Geeks
Complete Machine Learning & Data Science Program
Explore

312k+ interested Geeks
Complete Machine Learning & Data Science Program
Explore

312k+ interested Geeks

312k+ interested Geeks

Complete Machine Learning & Data Science Program

Explore

Explore

Explore More

Explore More

Corporate & Communications Address:- A-143, 9th Floor, Sovereign Corporate Tower, Sector- 136, Noida, Uttar Pradesh (201305) | Registered Address:- K 061, Tower K, Gulshan Vivante Apartment, Sector 137, Noida, Gautam Buddh Nagar, Uttar Pradesh, 201305
Company
About Us
Legal
Careers
In Media
Contact Us
Advertise with us
GFG Corporate Solution
Placement Training Program
Explore
Job-A-Thon Hiring Challenge
Hack-A-Thon
GfG Weekly Contest
Offline Classes (Delhi/NCR)
DSA in JAVA/C++
Master System Design
Master CP
GeeksforGeeks Videos
Geeks Community
Languages
Python
Java
C++
PHP
GoLang
SQL
R Language
Android Tutorial
DSA
Data Structures
Algorithms
DSA for Beginners
Basic DSA Problems
DSA Roadmap
DSA Interview Questions
Competitive Programming
Data Science & ML
Data Science With Python
Data Science For Beginner
Machine Learning
ML Maths
Data Visualisation
Pandas
NumPy
NLP
Deep Learning
Web Technologies
HTML
CSS
JavaScript
TypeScript
ReactJS
NextJS
NodeJs
Bootstrap
Tailwind CSS
Python Tutorial
Python Programming Examples
Django Tutorial
Python Projects
Python Tkinter
Web Scraping
OpenCV Tutorial
Python Interview Question
Computer Science
GATE CS Notes
Operating Systems
Computer Network
Database Management System
Software Engineering
Digital Logic Design
Engineering Maths
DevOps
Git
AWS
Docker
Kubernetes
Azure
GCP
DevOps Roadmap
System Design
High Level Design
Low Level Design
UML Diagrams
Interview Guide
Design Patterns
OOAD
System Design Bootcamp
Interview Questions
School Subjects
Mathematics
Physics
Chemistry
Biology
Social Science
English Grammar
Commerce
Accountancy
Business Studies
Economics
Management
HR Management
Finance
Income Tax
Databases
SQL
MYSQL
PostgreSQL
PL/SQL
MongoDB
Preparation Corner
Company-Wise Recruitment Process
Resume Templates
Aptitude Preparation
Puzzles
Company-Wise Preparation
Companies
Colleges
Competitive Exams
JEE Advanced
UGC NET
UPSC
SSC CGL
SBI PO
SBI Clerk
IBPS PO
IBPS Clerk
More Tutorials
Software Development
Software Testing
Product Management
Project Management
Linux
Excel
All Cheat Sheets
Recent Articles
Free Online Tools
Typing Test
Image Editor
Code Formatters
Code Converters
Currency Converter
Random Number Generator
Random Password Generator
Write & Earn
Write an Article
Improve an Article
Pick Topics to Write
Share your Experiences
Internships

Corporate & Communications Address:- A-143, 9th Floor, Sovereign Corporate Tower, Sector- 136, Noida, Uttar Pradesh (201305) | Registered Address:- K 061, Tower K, Gulshan Vivante Apartment, Sector 137, Noida, Gautam Buddh Nagar, Uttar Pradesh, 201305

Corporate & Communications Address:- A-143, 9th Floor, Sovereign Corporate Tower, Sector- 136, Noida, Uttar Pradesh (201305) | Registered Address:- K 061, Tower K, Gulshan Vivante Apartment, Sector 137, Noida, Gautam Buddh Nagar, Uttar Pradesh, 201305

Company
About Us
Legal
Careers
In Media
Contact Us
Advertise with us
GFG Corporate Solution
Placement Training Program
Explore
Job-A-Thon Hiring Challenge
Hack-A-Thon
GfG Weekly Contest
Offline Classes (Delhi/NCR)
DSA in JAVA/C++
Master System Design
Master CP
GeeksforGeeks Videos
Geeks Community
Languages
Python
Java
C++
PHP
GoLang
SQL
R Language
Android Tutorial
DSA
Data Structures
Algorithms
DSA for Beginners
Basic DSA Problems
DSA Roadmap
DSA Interview Questions
Competitive Programming
Data Science & ML
Data Science With Python
Data Science For Beginner
Machine Learning
ML Maths
Data Visualisation
Pandas
NumPy
NLP
Deep Learning
Web Technologies
HTML
CSS
JavaScript
TypeScript
ReactJS
NextJS
NodeJs
Bootstrap
Tailwind CSS
Python Tutorial
Python Programming Examples
Django Tutorial
Python Projects
Python Tkinter
Web Scraping
OpenCV Tutorial
Python Interview Question
Computer Science
GATE CS Notes
Operating Systems
Computer Network
Database Management System
Software Engineering
Digital Logic Design
Engineering Maths
DevOps
Git
AWS
Docker
Kubernetes
Azure
GCP
DevOps Roadmap
System Design
High Level Design
Low Level Design
UML Diagrams
Interview Guide
Design Patterns
OOAD
System Design Bootcamp
Interview Questions
School Subjects
Mathematics
Physics
Chemistry
Biology
Social Science
English Grammar
Commerce
Accountancy
Business Studies
Economics
Management
HR Management
Finance
Income Tax
Databases
SQL
MYSQL
PostgreSQL
PL/SQL
MongoDB
Preparation Corner
Company-Wise Recruitment Process
Resume Templates
Aptitude Preparation
Puzzles
Company-Wise Preparation
Companies
Colleges
Competitive Exams
JEE Advanced
UGC NET
UPSC
SSC CGL
SBI PO
SBI Clerk
IBPS PO
IBPS Clerk
More Tutorials
Software Development
Software Testing
Product Management
Project Management
Linux
Excel
All Cheat Sheets
Recent Articles
Free Online Tools
Typing Test
Image Editor
Code Formatters
Code Converters
Currency Converter
Random Number Generator
Random Password Generator
Write & Earn
Write an Article
Improve an Article
Pick Topics to Write
Share your Experiences
Internships

Company
About Us
Legal
Careers
In Media
Contact Us
Advertise with us
GFG Corporate Solution
Placement Training Program
Explore
Job-A-Thon Hiring Challenge
Hack-A-Thon
GfG Weekly Contest
Offline Classes (Delhi/NCR)
DSA in JAVA/C++
Master System Design
Master CP
GeeksforGeeks Videos
Geeks Community
Languages
Python
Java
C++
PHP
GoLang
SQL
R Language
Android Tutorial
DSA
Data Structures
Algorithms
DSA for Beginners
Basic DSA Problems
DSA Roadmap
DSA Interview Questions
Competitive Programming
Data Science & ML
Data Science With Python
Data Science For Beginner
Machine Learning
ML Maths
Data Visualisation
Pandas
NumPy
NLP
Deep Learning
Web Technologies
HTML
CSS
JavaScript
TypeScript
ReactJS
NextJS
NodeJs
Bootstrap
Tailwind CSS

Python Tutorial
Python Programming Examples
Django Tutorial
Python Projects
Python Tkinter
Web Scraping
OpenCV Tutorial
Python Interview Question
Computer Science
GATE CS Notes
Operating Systems
Computer Network
Database Management System
Software Engineering
Digital Logic Design
Engineering Maths
DevOps
Git
AWS
Docker
Kubernetes
Azure
GCP
DevOps Roadmap
System Design
High Level Design
Low Level Design
UML Diagrams
Interview Guide
Design Patterns
OOAD
System Design Bootcamp
Interview Questions
School Subjects
Mathematics
Physics
Chemistry
Biology
Social Science
English Grammar
Commerce
Accountancy
Business Studies
Economics
Management
HR Management
Finance
Income Tax

Databases
SQL
MYSQL
PostgreSQL
PL/SQL
MongoDB
Preparation Corner
Company-Wise Recruitment Process
Resume Templates
Aptitude Preparation
Puzzles
Company-Wise Preparation
Companies
Colleges
Competitive Exams
JEE Advanced
UGC NET
UPSC
SSC CGL
SBI PO
SBI Clerk
IBPS PO
IBPS Clerk
More Tutorials
Software Development
Software Testing
Product Management
Project Management
Linux
Excel
All Cheat Sheets
Recent Articles
Free Online Tools
Typing Test
Image Editor
Code Formatters
Code Converters
Currency Converter
Random Number Generator
Random Password Generator
Write & Earn
Write an Article
Improve an Article
Pick Topics to Write
Share your Experiences
Internships

@GeeksforGeeks, Sanchhaya Education Private Limited, All rights reserved

@GeeksforGeeks, Sanchhaya Education Private Limited, All rights reserved

We use cookies to ensure you have the best browsing experience on our website. By using our site, you acknowledge that you have read and understood our Cookie Policy & Privacy Policy
Got It !

Improvement

                    Please go through our recently updated Improvement Guidelines before submitting any improvements.

                    This improvement is locked by another user right now. You can suggest the changes for now and it will be under 'My Suggestions' Tab on Write.
                    You will be notified via email once the article is available for improvement.
                        Thank you for your valuable feedback!

                        Suggest changes

                  Please go through our recently updated Improvement Guidelines before submitting any improvements.

                      Suggest Changes
                      Help us improve. Share your suggestions to enhance the article. Contribute your expertise and make a difference in the GeeksforGeeks portal.

                      Create Improvement
                      Enhance the article with your expertise. Contribute to the GeeksforGeeks community and help create better learning resources for all.

                    Suggest Changes

                        min 4 words, max CharLimit:2000

                    Create Improvement

Improvement

                    Please go through our recently updated Improvement Guidelines before submitting any improvements.

                    This improvement is locked by another user right now. You can suggest the changes for now and it will be under 'My Suggestions' Tab on Write.
                    You will be notified via email once the article is available for improvement.
                        Thank you for your valuable feedback!

                        Suggest changes

                  Please go through our recently updated Improvement Guidelines before submitting any improvements.

                      Suggest Changes
                      Help us improve. Share your suggestions to enhance the article. Contribute your expertise and make a difference in the GeeksforGeeks portal.

                      Create Improvement
                      Enhance the article with your expertise. Contribute to the GeeksforGeeks community and help create better learning resources for all.

Improvement

Improvement

Please go through our recently updated Improvement Guidelines before submitting any improvements.

                    This improvement is locked by another user right now. You can suggest the changes for now and it will be under 'My Suggestions' Tab on Write.
                    You will be notified via email once the article is available for improvement.
                        Thank you for your valuable feedback!

                        Suggest changes

Please go through our recently updated Improvement Guidelines before submitting any improvements.

This improvement is locked by another user right now. You can suggest the changes for now and it will be under 'My Suggestions' Tab on Write.

You will be notified via email once the article is available for improvement.
                        Thank you for your valuable feedback!

Suggest changes

Please go through our recently updated Improvement Guidelines before submitting any improvements.

                      Suggest Changes
                      Help us improve. Share your suggestions to enhance the article. Contribute your expertise and make a difference in the GeeksforGeeks portal.

                      Create Improvement
                      Enhance the article with your expertise. Contribute to the GeeksforGeeks community and help create better learning resources for all.

Please go through our recently updated Improvement Guidelines before submitting any improvements.

Suggest Changes
                      Help us improve. Share your suggestions to enhance the article. Contribute your expertise and make a difference in the GeeksforGeeks portal.

Suggest Changes
                      Help us improve. Share your suggestions to enhance the article. Contribute your expertise and make a difference in the GeeksforGeeks portal.

Suggest Changes

Help us improve. Share your suggestions to enhance the article. Contribute your expertise and make a difference in the GeeksforGeeks portal.

Create Improvement
                      Enhance the article with your expertise. Contribute to the GeeksforGeeks community and help create better learning resources for all.

Create Improvement
                      Enhance the article with your expertise. Contribute to the GeeksforGeeks community and help create better learning resources for all.

Create Improvement

Enhance the article with your expertise. Contribute to the GeeksforGeeks community and help create better learning resources for all.

Suggest Changes

                        min 4 words, max CharLimit:2000

Suggest Changes

Suggest Changes

Suggest Changes

min 4 words, max CharLimit:2000

Create Improvement

Create Improvement

Create Improvement

Create Improvement

What kind of Experience do you want to share?

                        Interview Experiences

                        Admission Experiences

                        Career Journeys

                        Work Experiences

                        Campus Experiences

                        Competitive Exam Experiences

                        Can't choose a topic to write? click here for suggested topics

                       Write and publish your own Article

What kind of Experience do you want to share?

What kind of Experience do you want to share?

Interview Experiences

                        Admission Experiences

                        Career Journeys

                        Work Experiences

                        Campus Experiences

                        Competitive Exam Experiences

Interview Experiences

Admission Experiences

Career Journeys

Work Experiences

Campus Experiences

Competitive Exam Experiences

Can't choose a topic to write? click here for suggested topics

                       Write and publish your own Article

Can't choose a topic to write? click here for suggested topics

Write and publish your own Article

